<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>力扣周赛碎碎念</title>
    <link href="/post/20250413140100.html"/>
    <url>/post/20250413140100.html</url>
    
    <content type="html"><![CDATA[<h2 id="感受"><a href="#感受" class="headerlink" title="感受"></a>感受</h2><p>第一次参加周赛，规则是AC才给分，错误提交会罚时，一次5min。<br>没搞清楚，第二题写了个大概就交了，错了三次才AC。<br>第一次AC 2题，第三题超时，查不出来（T.T）</p><h2 id="第一题签到题性质，不说了"><a href="#第一题签到题性质，不说了" class="headerlink" title="第一题签到题性质，不说了"></a>第一题签到题性质，不说了</h2><h2 id="第二题"><a href="#第二题" class="headerlink" title="第二题"></a>第二题</h2><p>求回文串的第一个全排列<br>给个回文字符串s，求它的字典序最小的回文串</p><h3 id="第一遍思路："><a href="#第一遍思路：" class="headerlink" title="第一遍思路："></a>第一遍思路：</h3><ul><li>直接排序，然后next_permutation()，然后判断是否是回文串，是就输出<div class="note note-danger">            <p>喜提超时</p>          </div></li></ul><h3 id="第二遍思路："><a href="#第二遍思路：" class="headerlink" title="第二遍思路："></a>第二遍思路：</h3><ul><li>统计了下各个字母出现的次数，写到数组里，然后从小到大遍历数组，不为1直接写到ans字符串里，然后left++，right–，最后到中间那个，相等的话写剩下一个就行。</li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function">string <span class="hljs-title">smallestPalindrome</span><span class="hljs-params">(string s)</span> </span>&#123;<br>        <span class="hljs-type">long</span> <span class="hljs-type">long</span> n = s.<span class="hljs-built_in">size</span>();<br>        string ans;<br>        ans.<span class="hljs-built_in">resize</span>(n);<br>        <span class="hljs-type">long</span> <span class="hljs-type">long</span> cr[<span class="hljs-number">28</span>];<br>        <span class="hljs-keyword">for</span>(<span class="hljs-keyword">auto</span> c:s)<br>            cr[c-<span class="hljs-string">&#x27;a&#x27;</span>]++;<br>        <span class="hljs-type">long</span> <span class="hljs-type">long</span> left = <span class="hljs-number">0</span>,right = n<span class="hljs-number">-1</span>;<br>        <span class="hljs-keyword">while</span>(left&lt;= right)<br>        &#123;<br>            <span class="hljs-type">int</span> i = <span class="hljs-number">0</span>;<br>            <span class="hljs-keyword">while</span>(cr[i]==<span class="hljs-number">0</span>&amp;&amp;i&lt;<span class="hljs-number">26</span>)<br>                i++;<br>            <span class="hljs-keyword">if</span>(cr[i] == <span class="hljs-number">1</span> &amp;&amp; left!=right)<br>            &#123;   <br>                i++;<br>                <span class="hljs-keyword">while</span>(cr[i]==<span class="hljs-number">0</span>&amp;&amp;i&lt;<span class="hljs-number">26</span>)<br>                    i++;<br>            &#125;<br>            ans[left] = i+<span class="hljs-string">&#x27;a&#x27;</span>;<br>            ans[right] = i+<span class="hljs-string">&#x27;a&#x27;</span>;<br>            cr[i]-=<span class="hljs-number">2</span>;<br>            left++;right--;<br>        &#125;<br>        <span class="hljs-keyword">return</span> ans;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><div class="note note-danger">            <p>笨笨的做法。没注意条件，给的就是个回文串。<br>其实直接把给的除2写到ans里，再给ans排个序，中间字符单独处理下，最后输出<code>ans+mid+ans.reverse()</code>就好了。。</p>          </div><h2 id="第三题"><a href="#第三题" class="headerlink" title="第三题"></a>第三题</h2><p>上题的加强版，让求第k个回文串<br>本来按照上题第2种做法做的，爆解第k个，喜提超时。。(O…O)<br>然后按照改进思路做的，原字符串砍一半写到temp里，中间单独拎出来，temp排序，然后next_permutation() 走k-1次。如果没next直接输出空字符串就完了。</p><div class="note note-danger">            <p>还是喜提超时 (TwT)<br>    太难了呜呜呜</p>          </div>]]></content>
    
    
    <categories>
      
      <category>日记/leetcode</category>
      
    </categories>
    
    
    <tags>
      
      <tag>leetcode</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title></title>
    <link href="/post/20250413063201.html"/>
    <url>/post/20250413063201.html</url>
    
    <content type="html"><![CDATA[<p><code>SGD</code>随机梯度下降法，利用导数作为线索，使用参数的梯度沿梯度方向更新参数。</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title></title>
    <link href="/post/20250413063201.html"/>
    <url>/post/20250413063201.html</url>
    
    <content type="html"><![CDATA[<p>ChatGPT带来的问题</p><ol><li>如何精确提出需求，如何调教gpt</li><li>如何更正错误</li><li>侦测AI生成的物件</li><li>不小心泄露秘密</li></ol>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title></title>
    <link href="/post/20250413063201.html"/>
    <url>/post/20250413063201.html</url>
    
    <content type="html"><![CDATA[<ol><li>安装CUDA</li><li>根据CUDA，前往Pytorch官网，选择自己合适的平台。</li><li>根据生成的代码，执行</li></ol><p>注意：</p><ol><li>建议使用Anaconda进行环境管理，以简化某个版本不对而导致的重装。</li><li>我的命令:<code>conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia</code></li><li>建议换源后进行操作，以避免网络问题</li><li></li></ol>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title></title>
    <link href="/post/20250413063201.html"/>
    <url>/post/20250413063201.html</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>科目二流程</title>
    <link href="/post/20240121010800.html"/>
    <url>/post/20240121010800.html</url>
    
    <content type="html"><![CDATA[<h1 id="侧方入库"><a href="#侧方入库" class="headerlink" title="侧方入库"></a>侧方入库</h1><div class="note note-danger">            <p>两个翻越 : 延长线翻越，停车线翻越</p>          </div><h2 id="左转弯倒库"><a href="#左转弯倒库" class="headerlink" title="左转弯倒库"></a>左转弯倒库</h2><ol><li><p>开进项目场地，对准水泥缝  </p></li><li><p>肩膀到虚线处停车挂倒挡（R档）</p></li><li><p>倒车到<code>第三条水泥缝</code>前，有一条<code>小白线</code>，<strong>左打死</strong>，看左镜<div align="center"  style="display:inline-block;"> <img width="65%" alt="打方向盘点位" src="https://raw.githubusercontent.com/Destiny-End/images/master/202401232101849.png" style="float: none; margin-right: 10px;"> </div></p></li><li><p>车屁股挨到<code>第三条小黄线</code>，<strong>右一圈</strong>（即竖线朝上）</p></li><li><p>车轮翻越过<code>延长线</code>，<strong>左打死</strong></p></li><li><p>待车身与<code>库线</code>平齐，回正微调</p></li><li><p>后轮翻越<code>停车线</code>，停车踩刹车，挂D档</p></li></ol><h2 id="右转弯倒库"><a href="#右转弯倒库" class="headerlink" title="右转弯倒库"></a>右转弯倒库</h2><ol><li><p>从库里往外开，看后视镜</p></li><li><p>后轮开过<code>库角</code>，<strong>右打死</strong></p></li><li><p>车身与<code>边线</code>平齐时，回正</p></li><li><p>肩膀到<code>虚线</code>时，停车挂倒档</p></li><li><p>肩膀到<code>白色豁口</code>，右打死，看右镜<div align="center"  style="display:inline-block;"> <img width="65%" alt="白色豁口" src="https://raw.githubusercontent.com/Destiny-End/images/master/202401232118025.png" style="float: none; margin-right: 10px;"> </div></p></li><li><p>车屁股挨到<code>第三条小黄线</code>，<strong>回一圈</strong>，继续看右镜</p></li><li><p><code>库角</code>消失的时候，<strong>右打死</strong>，看左镜</p></li><li><p>等到车身正，回正</p></li><li><p>后轮翻过<code>停车线</code>，踩刹车，挂D档，开出库</p></li><li><p>后轮出<code>库角</code>，右打死</p></li><li><p>出去时人，方向盘12点歪的，对准<code>蓝白杆点</code>（为了避让下一辆车）</p></li></ol><div align="center"  style="display:inline-block;"> <img width="65%" alt="右边蓝白杆" src="https://raw.githubusercontent.com/Destiny-End/images/master/202401202225901.png" style="float: none; margin-right: 10px;"> </div><ol start="12"><li>待后轮驶过黄线，语音播报，项目结束。</li></ol><p><em>以下内容到下一个项目不扣分，可略微停车</em></p><ol><li>继续对准蓝白杆，待右肩对准<code>长黄线</code>，<strong>右打死</strong>，人车指向白杆回正，对着杆直开</li></ol><div align="center"  style="display:inline-block;"> <img width="65%" alt="长黄线，白杆" src="https://raw.githubusercontent.com/Destiny-End/images/master/202401202253944.png" style="float: none; margin-right: 10px;"> </div><ol start="2"><li>待发动机前盖遮住<code>杆最底下的螺丝</code>时，<strong>左打死</strong></li></ol><div align="center"  style="display:inline-block;"> <img width="65%" alt="发动机前端盖住螺丝" src="https://raw.githubusercontent.com/Destiny-End/images/master/202401202303715.png" style="float: none; margin-right: 10px;"> </div><ol start="3"><li>人车对准<code>豁口</code>，回正，直开</li></ol><div align="center"  style="display:inline-block;"> <img width="65%" alt="2024-01-20_23-06-04" src="https://raw.githubusercontent.com/Destiny-End/images/master/202401202306674.png" style="float: none; margin-right: 10px;"> </div><p>这时候可以探出头看看离左边线距离。一般是越近越好，但要小心压线  </p><p>离左边越近，越不容易压右边角  </p><h1 id="直角转弯"><a href="#直角转弯" class="headerlink" title="直角转弯"></a>直角转弯</h1><ol><li><p>对着上图<code>豁口</code>往前开，注意左边不要压线</p></li><li><p>前轮过检测线后，打灯，即<code>方向盘左杆</code>上拉</p></li><li><p>待肩膀对准<code>画的线</code>（慢点打方向盘）或者<code>铁杆</code>（快速打方向盘）时，<strong>右打死</strong>。注意，早了会压内角，晚了会压外线。把握好距离</p></li><li><p>待回正后，人车应该对准<code>小树</code>，直开</p></li></ol><p>  </p><div align="center"  style="display:inline-block;"> <img width="65%" alt="2024-01-20_23-22-15" src="https://raw.githubusercontent.com/Destiny-End/images/master/202401202323453.png" style="float: none; margin-right: 10px;"> </div><ol start="4"><li>后轮出黄线，仪器提示项目结束</li></ol><p>以下不扣分</p><ol><li>发动机盖盖住道沿，<strong>右打死</strong></li></ol><div align="center"  style="display:inline-block;"> <img width="65%" alt="发动机盖住道沿" src="https://raw.githubusercontent.com/Destiny-End/images/master/202401202333136.png" style="float: none; margin-right: 10px;"> </div>  <ol start="2"><li><p>车正回正，直开</p></li><li><p>进弯前，人车对准四方灯白杆</p></li></ol><div align="center"  style="display:inline-block;"> <img width="65%" alt="四方灯白杆" src="https://raw.githubusercontent.com/Destiny-End/images/master/202401202340730.png" style="float: none; margin-right: 10px;"> </div><p>目的是稍微靠左一点，进下一个项目</p><h1 id="S形弯道"><a href="#S形弯道" class="headerlink" title="S形弯道"></a>S形弯道</h1><div class="note note-danger">            <p>曲线转弯全是<strong>打一圈</strong>，不要打死</p>          </div><ol><li><p>对准灯直开</p></li><li><p>肩膀快与<code>大树</code>平齐时（可以看旁边<code>灌木边边</code>），右一圈</p></li></ol><div align="center"  style="display:inline-block;"> <img width="65%" alt="转弯点位" src="https://raw.githubusercontent.com/Destiny-End/images/master/202401202343036.png" style="float: none; margin-right: 10px;"> </div><ol start="3"><li><p>人车对准路边<code>豁口右边线</code>，回正<div align="center"  style="display:inline-block;"> <img width="65%" alt="回正豁口" src="https://raw.githubusercontent.com/Destiny-End/images/master/202401202345393.png" style="float: none; margin-right: 10px;"> </div></p></li><li><p>看车盖左前方楞线，楞线尾到<code>黄线外侧</code>的时候，左一圈</p></li><li><p>始终压着外延走，若楞在线外，则内修；若楞在线外，则外修</p></li><li><p>人车对准<code>半截树</code>时，向右回正<div align="center"  style="display:inline-block;"> <img width="65%" alt="image" src="https://raw.githubusercontent.com/Destiny-End/images/master/202401232119837.png" style="float: none; margin-right: 10px;"> </div></p></li><li><p>依旧是看车盖左前楞末端，顶到<code>道沿外侧</code>，<strong>右一圈</strong></p></li></ol><div align="center"  style="display:inline-block;"> <img width="65%" alt="道外沿" src="https://raw.githubusercontent.com/Destiny-End/images/master/202401202351849.png" style="float: none; margin-right: 10px;"> </div><ol start="8"><li>开出道沿后，人车对准<code>豁口</code>，回正</li></ol><div align="center"  style="display:inline-block;"> <img width="65%" alt="S弯回正豁口" src="https://raw.githubusercontent.com/Destiny-End/images/master/202401202356075.png" style="float: none; margin-right: 10px;"> </div><ol start="9"><li>车盖左楞对到道沿底部时，<strong>左一圈</strong></li></ol><div align="center"  style="display:inline-block;"> <img width="65%" alt="楞对到底部回正" src="https://raw.githubusercontent.com/Destiny-End/images/master/202401202358372.png" style="float: none; margin-right: 10px;"> </div><ol start="10"><li>再开一点点，语音播报项目结束</li></ol><h1 id="侧方停车"><a href="#侧方停车" class="headerlink" title="侧方停车"></a>侧方停车</h1><div class="note note-danger">            <p>口诀：右左左，右三平，左一平</p>          </div><h2 id="侧停"><a href="#侧停" class="headerlink" title="侧停"></a>侧停</h2><ol><li><p>人车对准<code>豁豁树</code>，<strong>右二圈</strong>（这时候向右打了一圈）</p></li><li><p>人右腿对准<code>箭头</code>的时候，回正直开</p></li></ol><div align="center"  style="display:inline-block;"> <img width="65%" alt="人对箭头回正" src="https://raw.githubusercontent.com/Destiny-End/images/master/202401210031964.png" style="float: none; margin-right: 10px;"> </div><ol start="3"><li>等到箭头被全部盖住，顶到<code>水泥缝</code>，停车，挂倒档</li></ol><div align="center"  style="display:inline-block;"> <img width="65%" alt="水泥缝" src="https://raw.githubusercontent.com/Destiny-End/images/master/202401210046742.png" style="float: none; margin-right: 10px;"> </div><ol start="4"><li><p>倒车到<code>前库角</code>完全消失，数两秒，<strong>右打死</strong>，看左镜。也就是口诀第一个右。<div align="center"  style="display:inline-block;"> <img width="65%" alt="这个角？好像是" src="https://raw.githubusercontent.com/Destiny-End/images/master/202401210051020.png" style="float: none; margin-right: 10px;"> </div></p></li><li><p>等到左边车身与<code>道沿角</code>对齐，<strong>向左回正</strong>。即口诀第二个左</p></li></ol><div align="center"  style="display:inline-block;"> <img width="65%" alt="对齐角" src="https://raw.githubusercontent.com/Destiny-End/images/master/202401210056389.png" style="float: none; margin-right: 10px;"> </div><ol start="6"><li><p>后轮压到<code>竖的水泥缝</code>上，<strong>左打死</strong>，看右，即口诀第三个左</p></li><li><p>车身平齐，踩刹车，挂D档。方向盘不用回正。</p></li></ol><h2 id="起走"><a href="#起走" class="headerlink" title="起走"></a>起走</h2><div class="note note-danger">            <p>记得要打灯，往下摁灯把  </p><p>刹车踩住了，不要溜，否则没打灯扣分  </p>          </div><ol><li><p><strong>打灯，向下推方向盘左杆，即左转向灯（打错扣10分）</strong></p></li><li><p>（此时左打死）往左开，至<code>道沿</code>盖住车前盖二分之一处，右三平。（即<strong>右打三圈</strong>）</p></li><li><p>待车头正，回一平，（即<strong>左打一圈</strong>）</p></li><li><p>直走。当左肩到<code>铁柱</code>时，右打死 <div align="center"  style="display:inline-block;"> <img width="65%" alt="铁柱子" src="https://raw.githubusercontent.com/Destiny-End/images/master/202401210108161.png" style="float: none; margin-right: 10px;"> </div></p></li><li><p>再开一点，语音播报，考试合格，结束。</p></li></ol><p>开回即可</p>]]></content>
    
    
    
    <tags>
      
      <tag>驾考</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>5.误差反向传播</title>
    <link href="/post/20240120124600.html"/>
    <url>/post/20240120124600.html</url>
    
    <content type="html"><![CDATA[<h2 id="引例"><a href="#引例" class="headerlink" title="引例"></a>引例</h2><p>数值微分计算梯度，虽然简单，但耗时。误差反向传播法可以高效计算权值参数。</p><h3 id="计算图法"><a href="#计算图法" class="headerlink" title="计算图法"></a>计算图法</h3><ol><li><p>可以通过传递”局部计算”来获取最终结果</p></li><li><p>局部计算指只关心与自己相关的数据。</p></li><li><p><code>反向传播</code>即可方便计算出各个导数</p></li><li><p><code>反向传播</code>是基于链式法则的:</p></li></ol><p>   $$\frac{\delta z}{\delta x} &#x3D; \frac{\delta z}{\delta t} \times \frac{\delta t}{\delta x}$$</p><h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><h3 id="乘法层"><a href="#乘法层" class="headerlink" title="乘法层"></a>乘法层</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-comment"># MulLayer</span><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MulLayer</span>:<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br><br>        self.x=<span class="hljs-literal">None</span><br><br>        self.y=<span class="hljs-literal">None</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self,x,y</span>):<br><br>        self.x=x<br><br>        self.y=y<br><br>        out=x*y<br><br>        <span class="hljs-keyword">return</span> out<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">backward</span>(<span class="hljs-params">self,dout</span>):<br><br>        dx=dout*self.y<br><br>        dy=dout*self.x<br><br>  <br><br>        <span class="hljs-keyword">return</span> dx,dy<br><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-comment"># test MulLayer</span><br><br>apple = <span class="hljs-number">100</span><br><br>apple_n=<span class="hljs-number">2</span><br><br>tax=<span class="hljs-number">1.1</span><br><br>  <br><br>mul_apple_layer=MulLayer()<br><br>mul_tax_layer=MulLayer()<br><br>  <br><br>apple_price = mul_apple_layer.forward(apple,apple_n)<br><br>price = mul_tax_layer.forward(apple_price,tax)<br><br>  <br><br><span class="hljs-built_in">print</span>(price)<br><br>  <br><br><span class="hljs-comment"># delta</span><br><br><span class="hljs-comment"># delta 反向传播时，顺序与正向传播调用方法相反</span><br><br>dprice = <span class="hljs-number">1</span><br><br>dapple_price , dtax = mul_tax_layer.backward(dprice) <span class="hljs-comment"># 注意顺序，与上面的`mul_tax_layer`参数输入一致</span><br><br>dapple , dapple_n = mul_apple_layer.backward(dapple_price)<br><br>  <br><br><span class="hljs-built_in">print</span>(dapple,dapple_n,dtax)<br><br>  <br><br></code></pre></td></tr></table></figure><p>    220.00000000000003</p><p>    2.2 110.00000000000001 200</p><h3 id="加法层"><a href="#加法层" class="headerlink" title="加法层"></a>加法层</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-comment"># AddLayer</span><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">AddLayer</span>:<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>) -&gt; <span class="hljs-literal">None</span>:<br><br>        <span class="hljs-keyword">pass</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self,x,y</span>):<br><br>        out=x+y<br><br>        <span class="hljs-keyword">return</span> out<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">backward</span>(<span class="hljs-params">self,dout</span>):<br><br>        dx=dout*<span class="hljs-number">1</span><br><br>        dy=dout*<span class="hljs-number">1</span><br><br>        <span class="hljs-keyword">return</span> dx,dy<br><br></code></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/Destiny-End/images/master/202401201023494.png" alt="例子图示"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-comment"># 买2苹果3橘子</span><br><br>apple=<span class="hljs-number">100</span><br><br>apple_num=<span class="hljs-number">2</span><br><br>orange=<span class="hljs-number">150</span><br><br>orange_num=<span class="hljs-number">3</span><br><br>tax = <span class="hljs-number">1.1</span><br><br>  <br><br><span class="hljs-comment"># layer</span><br><br>mul_apple_layer = MulLayer()<br><br>mul_orange_layer=MulLayer()<br><br>add_fruit_layer = AddLayer()<br><br>mul_tax_layer = MulLayer()<br><br>  <br><br><span class="hljs-comment"># forward</span><br><br>apple_price  = mul_apple_layer.forward(apple,apple_num)<br><br>orange_price = mul_orange_layer.forward(orange,orange_num)<br><br>fruit_price  = add_fruit_layer.forward(apple_price,orange_price)<br><br>price        = mul_tax_layer.forward(fruit_price,tax)<br><br>  <br><br><span class="hljs-comment"># backward</span><br><br>dprice = <span class="hljs-number">1</span><br><br>dfruit_price , dtax = mul_tax_layer.backward(dprice)<br><br>dapple_price , dorange_price = add_fruit_layer.backward(dfruit_price)<br><br>dorange , dorange_num = mul_orange_layer.backward(dorange_price)<br><br>dapple , dapple_num = mul_apple_layer.backward(dapple_price)<br><br>  <br><br><span class="hljs-built_in">print</span>(price)<br><br><span class="hljs-built_in">print</span>(dapple_num,dapple,dorange_num,dorange,dtax)<br><br></code></pre></td></tr></table></figure><p>    715.0000000000001</p><p>    110.00000000000001 2.2 165.0 3.3000000000000003 650</p><h2 id="加入激活函数"><a href="#加入激活函数" class="headerlink" title="加入激活函数"></a>加入激活函数</h2><h3 id="1-ReLU-Rectified-Linear-Unit-层"><a href="#1-ReLU-Rectified-Linear-Unit-层" class="headerlink" title="1. ReLU[^Rectified Linear Unit]层"></a>1. ReLU[^Rectified Linear Unit]层</h3><p><code>ReLU函数</code>导数：</p><p>$$ \frac{\delta y}{\delta x} &#x3D;<br>\begin{cases}<br>    1, &amp; (x &gt; 0), \<br>    0, &amp; (x \leq 0)<br>\end{cases}<br>$$</p><p>故，其在反向传播时，若<code>x&gt;0</code>，则输出前一层<code>delta</code>;否则输出0。</p><p>代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-comment"># ReLU layer</span><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">ReLU</span>:<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>) -&gt; <span class="hljs-literal">None</span>:<br><br>        <span class="hljs-keyword">pass</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self,x</span>):<br><br>        self.mask = (x&lt;=<span class="hljs-number">0</span>)<br><br>        out=x.copy()<br><br>        out[self.mask] = <span class="hljs-number">0</span>  <span class="hljs-comment"># 需要注意，输入是Numpy数组，故输出要保持同样形式</span><br><br>        <span class="hljs-keyword">return</span> out<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">backward</span>(<span class="hljs-params">self , dout</span>):<br><br>        dout[self.mask]=<span class="hljs-number">0</span><br><br>        dx = dout<br><br>        <span class="hljs-keyword">return</span> dx<br><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-comment"># 原理测试</span><br><br>x = np.array([[<span class="hljs-number">1.0</span>,-<span class="hljs-number">0.5</span>],[-<span class="hljs-number">2.0</span>,<span class="hljs-number">3.0</span>]])<br><br><span class="hljs-built_in">print</span>(x)<br><br>mask = (x&lt;=<span class="hljs-number">0</span>)<br><br><span class="hljs-built_in">print</span>(mask)<br><br></code></pre></td></tr></table></figure><p>    [[ 1.  -0.5]</p><p>     [-2.   3. ]]</p><p>    [[False  True]</p><p>     [ True False]]</p><h3 id="Sigmoid-层"><a href="#Sigmoid-层" class="headerlink" title="Sigmoid 层"></a>Sigmoid 层</h3><p>函数：</p><p>$$ y &#x3D; \frac{1}{1+e^{-x}}$$</p><p>正向传播，从输入x开始，依次进行了</p><ol><li><p>x &#x3D; x * -1   乘法层</p></li><li><p>x &#x3D; exp(-x)  幂次层</p></li><li><p>x &#x3D; 1 + x    加法层</p></li><li><p>y &#x3D; 1 &#x2F; x    除法层</p></li></ol><p>逆着逐级求导，可得最终结果为</p><p>$$ \frac{\delta L}{\delta y} \times y^2 \exp{-x} &#x3D; \frac{\delta L}{\delta y} y(1-y) $$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-comment"># Sigmoid layer</span><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Sigmoid</span>:<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br><br>        self.out=<span class="hljs-literal">None</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self,x</span>):<br><br>        out= <span class="hljs-number">1</span>/(<span class="hljs-number">1</span>+np.exp(-x))<br><br>        self.out=out<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">backward</span>(<span class="hljs-params">self,dout</span>):<br><br>        dx=dout*(<span class="hljs-number">1.0</span>-self.out)*self.out<br><br>        <span class="hljs-keyword">return</span> dx<br><br></code></pre></td></tr></table></figure><h3 id="Affine-Softmax-层"><a href="#Affine-Softmax-层" class="headerlink" title="Affine&#x2F;Softmax 层"></a>Affine&#x2F;Softmax 层</h3><h4 id="1-Affine层"><a href="#1-Affine层" class="headerlink" title="1. Affine层"></a>1. Affine层</h4><p>Affine就是矩阵运算中的乘积运算，也可以理解为仿射变换。</p><p>几何中的仿射变换包括一次线性变换和一次平移，对应神经网络的加权运算和加偏置运算。  </p><p><img src="https://raw.githubusercontent.com/Destiny-End/images/master/202401201132774.png" alt="Affine层计算图">  </p><p>对其求导，可以得到  </p><p><img src="https://raw.githubusercontent.com/Destiny-End/images/master/202401201132214.png" alt="求导结果">  </p><p>故它的反向传播为：  </p><p><img src="https://raw.githubusercontent.com/Destiny-End/images/master/202401201134015.png" alt="Affine层反向传播示意图">  </p><p>注意到$X$和$\frac{\delta L}{\delta X}$形状相同;$W$和$\frac{\delta L}{\delta W}$形状相同。</p><p>由该特性，不难推出<code>求导结果</code></p><h4 id="1-1-批版本的Affine层"><a href="#1-1-批版本的Affine层" class="headerlink" title="1.1 批版本的Affine层"></a>1.1 批版本的Affine层</h4><p><img src="https://raw.githubusercontent.com/Destiny-End/images/master/202401201140993.png" alt="批版本示意图"></p><div class="note note-warning">            <p>正向传播的时候，偏置会加到$X \times W$的各个数据上去，故在批版本下，会加到每一个数据里。  </p><p>因此反向传播时，各个数据的反向传播值需要汇总为偏置的元素。</p><p>即</p>          </div><p>代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-comment"># Affine层</span><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Affine</span>:<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,W,b</span>):<br><br>        self.W = W<br><br>        self.b = b<br><br>        self.x = <span class="hljs-literal">None</span><br><br>        self.dW = <span class="hljs-literal">None</span><br><br>        self.db = <span class="hljs-literal">None</span><br><br>  <br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self,x</span>):<br><br>        self.x = x<br><br>        out = np.dot(x,self.W) + self.b<br><br>  <br><br>        <span class="hljs-keyword">return</span> out<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">backward</span>(<span class="hljs-params">self,dout</span>):<br><br>        dx = np.dot(dout,self.W.T)<br><br>        self.dW = np.dot(self.x.T,dout)<br><br>        self.db = np.<span class="hljs-built_in">sum</span>(dout,axis=<span class="hljs-number">0</span>)<br><br>  <br><br>        <span class="hljs-keyword">return</span> dx<br><br></code></pre></td></tr></table></figure><h4 id="2-Softmax-with-Loss-层"><a href="#2-Softmax-with-Loss-层" class="headerlink" title="2. Softmax-with-Loss 层"></a>2. Softmax-with-Loss 层</h4><p><code>softmax</code>会将输出正规化输出。在数字识别中，因为有10个数字，故其输出也有10个。</p><div class="note note-primary">            <p>神经网络的处理有推理和学习两个阶段，推理一般不使用Softmax层。  </p><p>神经网络未被正规化处理的输出结果被称为<code>得分</code>，当推理只需要一个答案的情况下，只对得分最大的值感兴趣，故不需要Softmax层。  </p><p>神经网络的学习阶段需要Softmax层。  </p>          </div><p><img src="https://raw.githubusercontent.com/Destiny-End/images/master/202401201212073.png" alt="softmax传播图">  </p><p>该推导较为复杂，故只看结果。  </p><p><img src="https://raw.githubusercontent.com/Destiny-End/images/master/202401201215655.png" alt="简易softmax传播图">  </p><p>可以看到其反向传播很工整，正好是<code>神经网络Softmax层输出</code>与<code>监督数据</code>的差分。  </p><div class="note note-success">            <p>使用交叉熵误差作为<code>softmax</code>函数的损失函数后，反向传播得到<br><code>（y1 − t1, y2 − t2, y3 − t3）</code>这样“ 漂亮”的结果。实际上，这样“漂亮”<br>的结果并不是偶然的，而是为了得到这样的结果，特意设计了交叉<br>熵误差函数。回归问题中输出层使用“恒等函数”，损失函数使用<br>“平方和误差”，也是出于同样的理由。也就是说，使用“平<br>方和误差”作为“恒等函数”的损失函数，反向传播才能得到<code>（y1 −t1, y2 − t2, y3 − t3）</code>这样“漂亮”的结果。</p>          </div><p>代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-comment"># Softmax-With-Loss 层</span><br><br>  <br><br><span class="hljs-comment"># 预备函数</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">softmax</span>(<span class="hljs-params">a</span>):<br><br>    exp_a=np.exp(a)<br><br>    sum_exp_a=np.<span class="hljs-built_in">sum</span>(exp_a)<br><br>    y=exp_a/sum_exp_a<br><br>    <span class="hljs-keyword">return</span> y<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">cross_entropy_error</span>(<span class="hljs-params">y,t</span>):<br><br>    <span class="hljs-keyword">if</span> y.ndim == <span class="hljs-number">1</span>:<br><br>        t=t.reshape(<span class="hljs-number">1</span>,t.size)<br><br>        y=y.reshape(<span class="hljs-number">1</span>,y.size)<br><br>    batch_size = y.shape[<span class="hljs-number">0</span>]<br><br>    <span class="hljs-keyword">return</span> -np.<span class="hljs-built_in">sum</span>(t*np.log(y+<span class="hljs-number">1e-7</span>))/batch_size<br><br>  <br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">SoftmaxWithLoss</span>:<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br><br>        self.loss = <span class="hljs-literal">None</span><br><br>        self.y = <span class="hljs-literal">None</span><br><br>        self.t = <span class="hljs-literal">None</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span> (self,x,t):<br><br>        self.t = t<br><br>        self.y = softmax(x) <span class="hljs-comment"># 这个层可以分为两步，第一步计算`softmax`，第二步计算`loss`，即交叉熵</span><br><br>        self.loss = cross_entropy_error(self.y,self.t)  <span class="hljs-comment"># 输出与监督 的交叉熵</span><br><br>  <br><br>        <span class="hljs-keyword">return</span> self.loss<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">backward</span>(<span class="hljs-params">self,dout = <span class="hljs-number">1</span></span>):<br><br>        batch_size = self.t.shape[<span class="hljs-number">0</span>]<br><br>        dx = (self.y - self.t ) / batch_size<br><br>        <span class="hljs-keyword">return</span> dx<br><br></code></pre></td></tr></table></figure><p>需要注意的是，反向传播时需要将传播的值除以批的大小后，传递给前面的层是单个数据的误差。</p><h2 id="误差反向传播法的实现"><a href="#误差反向传播法的实现" class="headerlink" title="误差反向传播法的实现"></a>误差反向传播法的实现</h2><h3 id="1-神经网络学习步骤"><a href="#1-神经网络学习步骤" class="headerlink" title="1. 神经网络学习步骤"></a>1. 神经网络学习步骤</h3><ol start="0"><li>前提：</li></ol><p>   神经网络中有合适的权重和偏置，调整这些数据，以拟合训练数据的过程为学习。学习分为4个步骤</p><ol><li><p>(mini-batch)：从训练数据中随机选择一部分数据。</p></li><li><p>计算梯度：计算损失函数关于各个权重参数的梯度。</p></li><li><p>更新参数：将权重参数延梯度方向进行微笑的更新</p></li><li><p>重复1. 2. 3.</p></li></ol><p>在步骤2会使用到误差反向传播法，比数值微分高效许多。</p><p><code>二层神经网络(TwoLayerNet)</code>代码实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-comment"># coding: utf-8</span><br><br><span class="hljs-keyword">import</span> sys, os<br><br>sys.path.append(os.pardir)  <span class="hljs-comment"># 为了导入父目录的文件而进行的设定</span><br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-keyword">from</span> source.common.layers <span class="hljs-keyword">import</span> *<br><br><span class="hljs-keyword">from</span> source.common.gradient <span class="hljs-keyword">import</span> numerical_gradient<br><br><span class="hljs-keyword">from</span> collections <span class="hljs-keyword">import</span> OrderedDict<br><br>  <br>  <br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">TwoLayerNet</span>:<br><br>  <br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, input_size, hidden_size, output_size, weight_init_std = <span class="hljs-number">0.01</span></span>):<br><br>        <span class="hljs-comment"># 初始化权重</span><br><br>        self.params = &#123;&#125;<br><br>        self.params[<span class="hljs-string">&#x27;W1&#x27;</span>] = weight_init_std * np.random.randn(input_size, hidden_size)<br><br>        self.params[<span class="hljs-string">&#x27;b1&#x27;</span>] = np.zeros(hidden_size)<br><br>        self.params[<span class="hljs-string">&#x27;W2&#x27;</span>] = weight_init_std * np.random.randn(hidden_size, output_size)<br><br>        self.params[<span class="hljs-string">&#x27;b2&#x27;</span>] = np.zeros(output_size)<br><br>  <br><br><span class="hljs-comment">#+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++#</span><br><br>        <span class="hljs-comment"># 生成层</span><br><br>        self.layers = OrderedDict()<br><br>        self.layers[<span class="hljs-string">&#x27;Affine1&#x27;</span>] = Affine(self.params[<span class="hljs-string">&#x27;W1&#x27;</span>], self.params[<span class="hljs-string">&#x27;b1&#x27;</span>])<br><br>        self.layers[<span class="hljs-string">&#x27;Relu1&#x27;</span>] = Relu()<br><br>        self.layers[<span class="hljs-string">&#x27;Affine2&#x27;</span>] = Affine(self.params[<span class="hljs-string">&#x27;W2&#x27;</span>], self.params[<span class="hljs-string">&#x27;b2&#x27;</span>])<br><br>  <br><br>        self.lastLayer = SoftmaxWithLoss()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">predict</span>(<span class="hljs-params">self, x</span>):<br><br>        <span class="hljs-keyword">for</span> layer <span class="hljs-keyword">in</span> self.layers.values():<br><br>            x = layer.forward(x)<br><br><span class="hljs-comment">#---------------------------------------------------------------------------#</span><br><br>        <span class="hljs-keyword">return</span> x<br><br>    <span class="hljs-comment"># x:输入数据, t:监督数据</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">loss</span>(<span class="hljs-params">self, x, t</span>):<br><br>        y = self.predict(x)<br><br>        <span class="hljs-keyword">return</span> self.lastLayer.forward(y, t)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">accuracy</span>(<span class="hljs-params">self, x, t</span>):<br><br>        y = self.predict(x)<br><br>        y = np.argmax(y, axis=<span class="hljs-number">1</span>)<br><br>        <span class="hljs-keyword">if</span> t.ndim != <span class="hljs-number">1</span> : t = np.argmax(t, axis=<span class="hljs-number">1</span>)<br><br>        accuracy = np.<span class="hljs-built_in">sum</span>(y == t) / <span class="hljs-built_in">float</span>(x.shape[<span class="hljs-number">0</span>])<br><br>        <span class="hljs-keyword">return</span> accuracy<br><br>    <span class="hljs-comment"># x:输入数据, t:监督数据</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">numerical_gradient</span>(<span class="hljs-params">self, x, t</span>):<br><br>        loss_W = <span class="hljs-keyword">lambda</span> W: self.loss(x, t)<br><br>        grads = &#123;&#125;<br><br>        grads[<span class="hljs-string">&#x27;W1&#x27;</span>] = numerical_gradient(loss_W, self.params[<span class="hljs-string">&#x27;W1&#x27;</span>])<br><br>        grads[<span class="hljs-string">&#x27;b1&#x27;</span>] = numerical_gradient(loss_W, self.params[<span class="hljs-string">&#x27;b1&#x27;</span>])<br><br>        grads[<span class="hljs-string">&#x27;W2&#x27;</span>] = numerical_gradient(loss_W, self.params[<span class="hljs-string">&#x27;W2&#x27;</span>])<br><br>        grads[<span class="hljs-string">&#x27;b2&#x27;</span>] = numerical_gradient(loss_W, self.params[<span class="hljs-string">&#x27;b2&#x27;</span>])<br><br>        <span class="hljs-keyword">return</span> grads<br><br><span class="hljs-comment">#+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++#</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">gradient</span>(<span class="hljs-params">self, x, t</span>):<br><br>        <span class="hljs-comment"># forward</span><br><br>        self.loss(x, t)<br><br>  <br><br>        <span class="hljs-comment"># backward</span><br><br>        dout = <span class="hljs-number">1</span><br><br>        dout = self.lastLayer.backward(dout)<br><br>        layers = <span class="hljs-built_in">list</span>(self.layers.values())<br><br>        layers.reverse()<br><br>        <span class="hljs-keyword">for</span> layer <span class="hljs-keyword">in</span> layers:<br><br>            dout = layer.backward(dout)<br><br><span class="hljs-comment">#---------------------------------------------------------------------------#</span><br><br>        <span class="hljs-comment"># 设定</span><br><br>        grads = &#123;&#125;<br><br>        grads[<span class="hljs-string">&#x27;W1&#x27;</span>], grads[<span class="hljs-string">&#x27;b1&#x27;</span>] = self.layers[<span class="hljs-string">&#x27;Affine1&#x27;</span>].dW, self.layers[<span class="hljs-string">&#x27;Affine1&#x27;</span>].db<br><br>        grads[<span class="hljs-string">&#x27;W2&#x27;</span>], grads[<span class="hljs-string">&#x27;b2&#x27;</span>] = self.layers[<span class="hljs-string">&#x27;Affine2&#x27;</span>].dW, self.layers[<span class="hljs-string">&#x27;Affine2&#x27;</span>].db<br><br>  <br><br>        <span class="hljs-keyword">return</span> grads<br><br>  <br><br></code></pre></td></tr></table></figure><div class="note note-primary">            <p>注意<code>#++#</code>与<code>#--#</code>之间的部分，采用了<code>OrderedDict</code>有序字典，即可以记住添加元素的顺序。  </p><p>故正向传播只需要按照添加元素的顺序调用各层的<code>forward()</code>方法即可实现  </p><p>反向传播只需按照相反的顺序调用即可。  </p><p>这种以层的方式实现可以很轻松构建神经网络。</p>          </div><h3 id="梯度确认"><a href="#梯度确认" class="headerlink" title="梯度确认"></a>梯度确认</h3><p>由于反向传播法较为复杂，容易出错，故可以采用<code>数值微分法</code>进行确认。</p><p>代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-comment"># coding: utf-8</span><br><br><span class="hljs-keyword">import</span> sys, os<br><br>sys.path.append(os.pardir)  <span class="hljs-comment"># 为了导入父目录的文件而进行的设定</span><br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-keyword">from</span> source.dataset.mnist <span class="hljs-keyword">import</span> load_mnist<br><br><span class="hljs-keyword">from</span> source.ch05.two_layer_net <span class="hljs-keyword">import</span> TwoLayerNet<br><br>  <br><br><span class="hljs-comment"># 读入数据</span><br><br>(x_train, t_train), (x_test, t_test) = load_mnist(normalize=<span class="hljs-literal">True</span>, one_hot_label=<span class="hljs-literal">True</span>)<br><br>  <br><br>network = TwoLayerNet(input_size=<span class="hljs-number">784</span>, hidden_size=<span class="hljs-number">50</span>, output_size=<span class="hljs-number">10</span>)<br><br>  <br><br>x_batch = x_train[:<span class="hljs-number">3</span>]<br><br>t_batch = t_train[:<span class="hljs-number">3</span>]<br><br>  <br><br>grad_numerical = network.numerical_gradient(x_batch, t_batch)<br><br>grad_backprop = network.gradient(x_batch, t_batch)<br><br>  <br><br><span class="hljs-keyword">for</span> key <span class="hljs-keyword">in</span> grad_numerical.keys():<br><br>    diff = np.average( np.<span class="hljs-built_in">abs</span>(grad_backprop[key] - grad_numerical[key]) )<br><br>    <span class="hljs-built_in">print</span>(key + <span class="hljs-string">&quot;:&quot;</span> + <span class="hljs-built_in">str</span>(diff))<br><br></code></pre></td></tr></table></figure><p>    W1:2.7453979178765813e-10</p><p>    b1:1.5954478661383414e-09</p><p>    W2:4.2198711969510414e-09</p><p>    b2:1.399512964808669e-07</p><p>误差很小，故结果正确。</p><h3 id="使用反向传播法学习"><a href="#使用反向传播法学习" class="headerlink" title="使用反向传播法学习"></a>使用反向传播法学习</h3><p>因仅修改了<code>#++#</code>与<code>#--#</code> 部分，故不作解释。  </p><p>代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-comment"># coding: utf-8</span><br><br><span class="hljs-keyword">import</span> sys, os<br><br>sys.path.append(os.pardir)<br><br>  <br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-keyword">from</span> source.dataset.mnist <span class="hljs-keyword">import</span> load_mnist<br><br><span class="hljs-keyword">from</span> source.ch05.two_layer_net <span class="hljs-keyword">import</span> TwoLayerNet<br><br>  <br><br><span class="hljs-comment"># 读入数据</span><br><br>(x_train, t_train), (x_test, t_test) = load_mnist(normalize=<span class="hljs-literal">True</span>, one_hot_label=<span class="hljs-literal">True</span>)<br><br>  <br><br>network = TwoLayerNet(input_size=<span class="hljs-number">784</span>, hidden_size=<span class="hljs-number">50</span>, output_size=<span class="hljs-number">10</span>)<br><br>  <br><br>iters_num = <span class="hljs-number">10000</span><br><br>train_size = x_train.shape[<span class="hljs-number">0</span>]<br><br>batch_size = <span class="hljs-number">100</span><br><br>learning_rate = <span class="hljs-number">0.1</span><br><br>  <br><br>train_loss_list = []<br><br>train_acc_list = []<br><br>test_acc_list = []<br><br>  <br><br>iter_per_epoch = <span class="hljs-built_in">max</span>(train_size / batch_size, <span class="hljs-number">1</span>)<br><br>  <br><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(iters_num):<br><br>    batch_mask = np.random.choice(train_size, batch_size)<br><br>    x_batch = x_train[batch_mask]<br><br>    t_batch = t_train[batch_mask]<br><br><span class="hljs-comment">#+++++++++++++++++++++++++++++++++++++++++++++++++++++++++#</span><br><br>    <span class="hljs-comment"># 梯度</span><br><br>    <span class="hljs-comment">#grad = network.numerical_gradient(x_batch, t_batch)</span><br><br>    grad = network.gradient(x_batch, t_batch)<br><br><span class="hljs-comment">#---------------------------------------------------------#</span><br><br>    <span class="hljs-comment"># 更新</span><br><br>    <span class="hljs-keyword">for</span> key <span class="hljs-keyword">in</span> (<span class="hljs-string">&#x27;W1&#x27;</span>, <span class="hljs-string">&#x27;b1&#x27;</span>, <span class="hljs-string">&#x27;W2&#x27;</span>, <span class="hljs-string">&#x27;b2&#x27;</span>):<br><br>        network.params[key] -= learning_rate * grad[key]<br><br>    loss = network.loss(x_batch, t_batch)<br><br>    train_loss_list.append(loss)<br><br>    <span class="hljs-keyword">if</span> i % iter_per_epoch == <span class="hljs-number">0</span>:<br><br>        train_acc = network.accuracy(x_train, t_train)<br><br>        test_acc = network.accuracy(x_test, t_test)<br><br>        train_acc_list.append(train_acc)<br><br>        test_acc_list.append(test_acc)<br><br>        <span class="hljs-built_in">print</span>(train_acc, test_acc)<br><br>  <br><br></code></pre></td></tr></table></figure><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本章介绍了计算图法的误差反向传播法。  </p><ol><li><p>使用计算图，可以很清晰展现计算过程</p></li><li><p>计算图的节点由局部计算构成</p></li><li><p>计算图的正向传播进行一般的计算，计算图的反向传播可以计算各个节点的导数。</p></li><li><p>通过将神经网络的组成元素实现为层，可以高效的计算梯度。</p></li><li><p>通过数值计算和误差反向传播法比较，可以确认误差反向传播是否正确。</p></li></ol>]]></content>
    
    
    <categories>
      
      <category>DL</category>
      
    </categories>
    
    
    <tags>
      
      <tag>python</tag>
      
      <tag>DL</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>4.神经网络学习</title>
    <link href="/post/20240104122500.html"/>
    <url>/post/20240104122500.html</url>
    
    <content type="html"><![CDATA[<p><code>学习</code>即自动从数据集中获取最优参数的过程。</p><p>用<code>损失函数</code>来衡量学习的优劣</p><p>本书采用<code>函数斜率的梯度法</code></p><p>机器学习、深度学习极力避免人为介入</p><h2 id="引例"><a href="#引例" class="headerlink" title="引例"></a>引例</h2><p>识别手写<code>5</code>，该如何实现？</p><p>一种方案是，先从图像中提取<strong>特征量</strong>，图像的特征量表示为向量的形式。在计算机视觉里，常采用<em>SIFT，SURF,和HOG</em>等,然后使用机器学习中的<em>SVM,KNN</em>等方法学习。</p><p>而深度学习不需要找到这个“特征量”，即直接输入数据即可。故其也被称为<strong>端到端</strong>学习。</p><div class="note note-success">            <p>  </p><p>SIFT（Scale-Invariant Feature Transform）是一种图像处理算法，用于在数字图像中寻找关键点（keypoints）并计算这些关键点的描述符（descriptor）。SIFT算法最初由David Lowe在1999年提出，并在2004年进行了改进和扩展。  </p><p>SIFT算法的主要优点是其对尺度、旋转和亮度变化的鲁棒性，使其在图像配准、物体识别、图像检索等领域具有广泛的应用。SIFT算法的关键步骤包括尺度空间极值检测、关键点定位、定向分配、关键点描述和关键点匹配。  </p><p>在SIFT算法中，尺度空间极值检测用于检测图像中具有不同尺度和位置的关键点。通过在不同尺度上的高斯平滑和差分操作，可以在图像中找到稳定的极值点，这些点通常对应于图像中的角点、边缘和斑点等显著特征。  </p><p>关键点定位阶段对尺度空间极值点进行精确定位，排除低对比度和边缘响应不明显的点，并使用插值方法确定关键点的亚像素位置。  </p><p>定向分配阶段计算每个关键点的主要方向，以便后续步骤中关键点描述子的旋转不变性。  </p><p>关键点描述阶段使用关键点周围的图像梯度信息生成一个128维的描述子，该描述子能够描述关键点周围的局部外貌特征。  </p><p>最后，关键点匹配阶段将两个图像的关键点进行匹配，通常使用最近邻匹配和阈值筛选来确定匹配对。  </p><p>总之，SIFT算法是一种强大的图像处理算法，通过寻找图像中的关键点并计算其描述子，可以实现对图像中的特征进行鲁棒和准确的描述和匹配。  </p>          </div>  <div class="note note-success">            <p>  </p><p>SURF（Speeded-Up Robust Features）是一种计算机视觉算法，用于在数字图像中检测和描述关键点。它是由Herbert Bay等人在2006年提出的，旨在提高SIFT算法的计算速度和匹配性能。</p><p>与SIFT算法类似，SURF算法也具有尺度不变性和旋转不变性，能够在图像中找到具有稳定特征的关键点。然而，SURF算法通过使用一种称为积分图像（integral image）的数据结构，以及一种称为快速哈尔小波（Fast-Haar wavelet）变换的方法，实现了更快的计算速度。</p><p>SURF算法的关键步骤包括构建尺度空间、检测关键点、计算关键点的描述子和关键点匹配。</p><p>在构建尺度空间阶段，SURF算法使用一种尺度空间金字塔的结构，通过对图像进行多次尺度缩放来检测不同尺度的特征。</p><p>关键点检测阶段使用Hessian矩阵的行列式来检测尺度空间中的极值点，这些极值点被认为是图像中的关键点。</p><p>关键点描述阶段利用关键点周围的局部图像区域，通过计算Haar小波响应来生成一个描述子向量。这个描述子向量包含了关键点周围区域的梯度方向和强度信息。</p><p>最后，关键点匹配阶段使用一种快速的最近邻算法（例如KD树）来将两个图像的关键点进行匹配，以找到相似的特征点。</p><p>总的来说，SURF算法是一种高效、快速且具有良好性能的特征提取和匹配算法。它在计算机视觉中广泛应用于目标检测、图像配准、三维重建等领域。</p>          </div><div class="note note-success">            <p>HOG（Histogram of Oriented Gradients）是一种用于目标检测和图像识别的特征描述算法。HOG算法最初由Navneet Dalal和Bill Triggs在2005年提出，并在物体检测领域取得了很大的成功。</p><p>HOG算法的基本思想是将图像中的局部区域转换为特征向量，这些特征向量能够描述图像中的边缘和纹理信息。HOG算法对图像的梯度方向进行统计，生成一个直方图来表示图像中不同方向上的梯度分布。</p><p>HOG算法的主要步骤如下：</p><p>图像预处理：将输入图像进行预处理，通常包括灰度化、归一化和对比度增强等操作。</p><p>计算梯度：计算图像中每个像素点的梯度幅值和方向，可以使用Sobel等算子进行梯度计算。</p><p>划分图像区域：将图像划分为多个小的局部区域（cells），每个局部区域包含多个像素点。</p><p>计算局部直方图：对每个局部区域内的像素点，统计其梯度方向的分布情况，生成一个局部直方图。</p><p>归一化直方图：对于相邻的若干个局部区域，将它们的局部直方图进行归一化，以增强对光照变化的鲁棒性。</p><p>特征向量描述：将所有归一化的局部直方图连接起来，形成一个全局的特征向量，用于表示整个图像。</p><p>最终，HOG算法通过计算图像中不同位置上的特征向量之间的相似性，实现目标检测和图像识别任务。通常使用支持向量机（SVM）等分类器来训练和识别目标。</p><p>HOG算法在人脸检测、行人检测等领域取得了很好的效果，并且相对于其他特征描述算法，HOG算法具有计算简单、鲁棒性强的优点。</p>          </div><p>深度学习需要提高</p><ol><li><p>泛化能力</p></li><li><p>避免过拟合</p></li></ol><h3 id="损失函数："><a href="#损失函数：" class="headerlink" title="损失函数："></a>损失函数：</h3><p>是评价神经网络性能<strong>恶劣程度</strong>的指标。</p><ol><li>均方误差函数</li></ol><p>   $$E&#x3D;\frac{1}{2} \sum_k{(y_k-t_k)^2}$$$$y_k表示输出，t_k表示监督数据，k表示数据维度$$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> mean_squared_error<br><br>t=[<span class="hljs-number">0</span>  ,<span class="hljs-number">0</span>   ,<span class="hljs-number">1</span>  ,<span class="hljs-number">0</span>  ,<span class="hljs-number">0</span>   ,<span class="hljs-number">0</span>  ,<span class="hljs-number">0</span>  ,<span class="hljs-number">0</span>  ,<span class="hljs-number">0</span>  ,<span class="hljs-number">0</span>  ]<br><br>y=[<span class="hljs-number">0.1</span>,<span class="hljs-number">0.05</span>,<span class="hljs-number">0.6</span>,<span class="hljs-number">0.0</span>,<span class="hljs-number">0.05</span>,<span class="hljs-number">0.1</span>,<span class="hljs-number">0.0</span>,<span class="hljs-number">0.1</span>,<span class="hljs-number">0.0</span>,<span class="hljs-number">0.0</span>]<br><br><span class="hljs-built_in">print</span>(mean_squared_error(np.array(y),np.array(t)))<br><br></code></pre></td></tr></table></figure><p>    0.019500000000000007</p><ol start="2"><li>交叉熵误差</li></ol><p>   $$ E&#x3D;-\sum_k{t_k\log{y_k}} $$$$t_k采用one-hot表示$$</p><p>   该式只计算了正确标签输出的自然对数。误差的值由正确标签对应的输出结果决定的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">cross_entropy_error</span>(<span class="hljs-params">y,t</span>):<br><br>    delta=<span class="hljs-number">1e-7</span><br><br>    <span class="hljs-keyword">return</span> -np.<span class="hljs-built_in">sum</span>(t*np.log(y+delta))<br><br>t=[<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>]<br><br>y=[<span class="hljs-number">0.1</span>,<span class="hljs-number">0.05</span>,<span class="hljs-number">0.6</span>,<span class="hljs-number">0.0</span>,<span class="hljs-number">0.05</span>,<span class="hljs-number">0.1</span>,<span class="hljs-number">0.0</span>,<span class="hljs-number">0.1</span>,<span class="hljs-number">0.0</span>,<span class="hljs-number">0.0</span>]<br><br><span class="hljs-built_in">print</span>(cross_entropy_error(np.array(y),np.array(t)))<br><br></code></pre></td></tr></table></figure><p>    0.510825457099338</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><br>y=[<span class="hljs-number">0.1</span>,<span class="hljs-number">0.05</span>,<span class="hljs-number">0.1</span>,<span class="hljs-number">0.0</span>,<span class="hljs-number">0.05</span>,<span class="hljs-number">0.1</span>,<span class="hljs-number">0.0</span>,<span class="hljs-number">0.6</span>,<span class="hljs-number">0.0</span>,<span class="hljs-number">0.0</span>]<br><br><span class="hljs-built_in">print</span>(cross_entropy_error(np.array(y),np.array(t)))<br><br></code></pre></td></tr></table></figure><p>    2.302584092994546</p><h3 id="mini-batch"><a href="#mini-batch" class="headerlink" title="mini-batch"></a>mini-batch</h3><p>若全部计算损失，则耗费资源过大。故一般选择一部分，作为全部数据的<strong>近似</strong>(注意考虑分布，方差，均值等因素，尽量保持一致)。用这一部分数据学习。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-comment">#读入数据</span><br><br><span class="hljs-keyword">import</span> sys, os<br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-keyword">from</span> source.dataset.mnist <span class="hljs-keyword">import</span> load_mnist<br><br>(x_train,t_train),(x_test,t_test)=load_mnist(normalize=<span class="hljs-literal">True</span>,one_hot_label=<span class="hljs-literal">True</span>)<br><br><span class="hljs-built_in">print</span>(x_train.shape)<br><br><span class="hljs-built_in">print</span>(t_train.shape)<br><br></code></pre></td></tr></table></figure><p>    (60000, 784)</p><p>    (60000, 10)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-comment">#随机选10笔</span><br><br>train_size=x_train.shape[<span class="hljs-number">0</span>]<br><br>batch_size=<span class="hljs-number">10</span><br><br>batch_mask=np.random.choice(train_size,batch_size)<br><br>x_batch=x_train[batch_mask]<br><br>t_batch=t_train[batch_mask]<br><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-comment"># one-hot 的 batch 交叉熵</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">cross_entropy_error</span>(<span class="hljs-params">y,t</span>):<br><br>    <span class="hljs-keyword">if</span> y.ndim == <span class="hljs-number">1</span>:<br><br>        t=t.reshape(<span class="hljs-number">1</span>,t.size)<br><br>        y=y.reshape(<span class="hljs-number">1</span>,y.size)<br><br>    batch_size = y.shape[<span class="hljs-number">0</span>]<br><br>    <span class="hljs-keyword">return</span> -np.<span class="hljs-built_in">sum</span>(t*np.log(y+<span class="hljs-number">1e-7</span>))/batch_size<br><br></code></pre></td></tr></table></figure><div class="note note-dangerous">            <p>在计算机科学和数值计算中，由于浮点数的精度限制，当一个数值非常接近于零时，可能会出现数值误差问题。在这种情况下，对一个非常接近零的数值取对数时，可能会遇到无穷大或NaN（不是一个数字）的结果。  </p><p>为了避免这种情况，通常会在取对数之前，将待取对数的数值加上一个很小的常数（通常是类似1e-7这样的小数），以确保数值不会非常接近零。这样可以防止数值误差导致的无穷大或NaN的结果，并且得到一个合理的数值。  </p><p>在np.log(y+1e-7) 中的1e-7就是为了避免y值非常接近零时产生数值误差。通过将1e-7添加到y上，可以确保y+1e-7不会非常接近零，从而避免了数值误差问题。  </p>          </div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-comment"># lable形式 的 batch 交叉熵</span><br><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string"></span><br><span class="hljs-string">def cross_entropy_error(y,t):</span><br><span class="hljs-string"></span><br><span class="hljs-string">    if y.ndim == 1:</span><br><span class="hljs-string"></span><br><span class="hljs-string">        t=t.reshape(1,t.size)</span><br><span class="hljs-string"></span><br><span class="hljs-string">        y=y.reshape(1,y.size)</span><br><span class="hljs-string"></span><br><span class="hljs-string">    batch_size = y.shape[0]</span><br><span class="hljs-string"></span><br><span class="hljs-string">    return -np.sum(t*np.log(y[np.arrange(batch_size),t]+1e-7))/batch_size</span><br><span class="hljs-string"></span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><br></code></pre></td></tr></table></figure><h3 id="损失函数意义"><a href="#损失函数意义" class="headerlink" title="损失函数意义"></a>损失函数意义</h3><ol><li><p>不能使用识别精度作为指标，因为以它作为指标，很多地方导数都会变为<code>0</code>从而无法更新参数</p></li><li><p>使用损失函数作为指标，可以根据参数变化计算损失函数，从而得出导数。</p></li><li><p>因为识别精度有可能是，而且经常是离散的点，故<code>1.</code>中导数很多地方都是<code>0</code></p></li><li><p>同样原因，之前感知机的激活函数一般选用连续的值，即<code>sigmoid</code>函数，而不用<code>阶跃</code>函数。</p></li></ol><h2 id="数值计算"><a href="#数值计算" class="headerlink" title="数值计算"></a>数值计算</h2><h3 id="导数实现"><a href="#导数实现" class="headerlink" title="导数实现"></a>导数实现</h3><ol><li><p>不用导数的定义式，因为 $\delta x$ 太小会引入<code>舍入误差</code>。</p></li><li><p>使用<code>中心差分</code>,而不用<code>前向差分</code>。</p></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-comment"># 中心差分实现</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">numerical_diff</span>(<span class="hljs-params">f,x</span>):<br><br>    h=<span class="hljs-number">1e-4</span><br><br>    <span class="hljs-keyword">return</span> (f(x+h)-f(x-h))/(<span class="hljs-number">2</span>*h)<br><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-comment"># 测试</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">function_1</span>(<span class="hljs-params">x</span>):<br><br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0.01</span>*x**<span class="hljs-number">2</span>+<span class="hljs-number">0.1</span>*x<br><br>  <br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-keyword">import</span> matplotlib.pylab <span class="hljs-keyword">as</span> plt<br><br>  <br><br>x=np.arange(<span class="hljs-number">0.0</span>,<span class="hljs-number">20.0</span>,<span class="hljs-number">0.1</span>)<br><br>y=function_1(x)<br><br>plt.xlabel(<span class="hljs-string">&#x27;x&#x27;</span>)<br><br>plt.ylabel(<span class="hljs-string">&#x27;f(x)&#x27;</span>)<br><br>plt.plot(x,y)<br><br>plt.show()<br><br><span class="hljs-built_in">print</span>(numerical_diff(function_1,<span class="hljs-number">5</span>))<br><br><span class="hljs-built_in">print</span>(numerical_diff(function_1,<span class="hljs-number">10</span>))<br><br></code></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/Destiny-End/images/master/202401041227119.png" alt="方程曲线"></p><p>    0.1999999999990898</p><p>    0.2999999999986347</p><h3 id="偏导实现"><a href="#偏导实现" class="headerlink" title="偏导实现"></a>偏导实现</h3><p>$$f(x_0,x_1)&#x3D;x_0^2+x_1^2$$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-comment"># f(x0,x1)</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">function_2</span>(<span class="hljs-params">x</span>):<br><br>    <span class="hljs-keyword">return</span> x[<span class="hljs-number">0</span>]**<span class="hljs-number">2.0</span>+x[<span class="hljs-number">1</span>]**<span class="hljs-number">2.0</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">function_tmp1</span>(<span class="hljs-params">x0</span>):<br><br>    <span class="hljs-keyword">return</span> x0*x0+<span class="hljs-number">4.0</span>**<span class="hljs-number">2.0</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">function_tmp2</span>(<span class="hljs-params">x1</span>):<br><br>    <span class="hljs-keyword">return</span> <span class="hljs-number">3.0</span>**<span class="hljs-number">2.0</span> + x1*x1<br><br><span class="hljs-built_in">print</span>(numerical_diff(function_tmp1,(<span class="hljs-number">3.0</span>)))<br><br><span class="hljs-built_in">print</span>(numerical_diff(function_tmp2,(<span class="hljs-number">4.0</span>)))<br><br></code></pre></td></tr></table></figure><p>    6.00000000000378</p><p>    7.999999999999119</p><h3 id="梯度实现"><a href="#梯度实现" class="headerlink" title="梯度实现"></a>梯度实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-comment"># 梯度实现代码</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">numerical_gradient</span>(<span class="hljs-params">f,x</span>):<br><br>    h = <span class="hljs-number">1e-4</span><br><br>    grad=np.zeros_like(x)<br><br>  <br><br>    <span class="hljs-keyword">for</span> idx <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(x.size):<br><br>        tmp_val = x[idx]<br><br>        <span class="hljs-comment"># f(x+h)</span><br><br>        x[idx]=<span class="hljs-built_in">float</span>(tmp_val) + h<br><br>        fxh1=f(x)<br><br>        <span class="hljs-comment"># f(x-h)</span><br><br>        x[idx]=<span class="hljs-built_in">float</span>(tmp_val) - h<br><br>        fxh2=f(x)<br><br>  <br><br>        grad[idx]=(fxh1 - fxh2)/ (<span class="hljs-number">2</span>*h)<br><br>        x[idx]=tmp_val<br><br>  <br><br>    <span class="hljs-keyword">return</span> grad<br><br><span class="hljs-comment"># python 注意缩进</span><br><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-comment"># 测试梯度</span><br><br><span class="hljs-built_in">print</span>(numerical_gradient(function_2, np.array([<span class="hljs-number">3.0</span>,<span class="hljs-number">4.0</span>])))<br><br><span class="hljs-built_in">print</span>(numerical_gradient(function_2, np.array([<span class="hljs-number">0.0</span>,<span class="hljs-number">2.0</span>])))<br><br></code></pre></td></tr></table></figure><p>    [6. 8.]</p><p>    [0. 4.]</p><div class="note note-dangerous">            <p>注意一点，梯度只会指向<code>函数值下降</code>的地方，而不是<code>最低</code>的地方。即只会找到极值，而不是最值。</p>          </div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-comment"># python 梯度下降法</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">gradient_descent</span>(<span class="hljs-params">f,init_x,lr=<span class="hljs-number">0.01</span>,step_num=<span class="hljs-number">100</span></span>): <span class="hljs-comment"># init_x是初始值，lr是学习率</span><br><br>    x=init_x<br><br>  <br><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(step_num):<br><br>        grad=numerical_gradient(f,x)<br><br>        x-=lr*grad<br><br>    <span class="hljs-keyword">return</span> x<br><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-comment"># 梯度下降求最值</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">function_2</span>(<span class="hljs-params">x</span>):<br><br>    <span class="hljs-keyword">return</span> np.<span class="hljs-built_in">sum</span>(x**<span class="hljs-number">2</span>)<br><br>  <br><br>init_x=np.array([-<span class="hljs-number">3.0</span>,<span class="hljs-number">4.0</span>])<br><br><span class="hljs-built_in">print</span>(gradient_descent(function_2,init_x=init_x,lr=<span class="hljs-number">0.1</span>,step_num=<span class="hljs-number">100</span>))<br><br><span class="hljs-built_in">print</span>(gradient_descent(function_2,init_x=init_x,lr=<span class="hljs-number">0.1</span>,step_num=<span class="hljs-number">10</span>))<br><br><span class="hljs-built_in">print</span>(gradient_descent(function_2,init_x=init_x,lr=<span class="hljs-number">10.0</span>,step_num=<span class="hljs-number">100</span>))<br><br></code></pre></td></tr></table></figure><p>    [-6.11110793e-10  8.14814391e-10]</p><p>    [-6.56175217e-11  8.74900290e-11]</p><p>    [-9.70516708e+12  1.29488926e+13]</p><div class="note note-primary">            <p>学习率这种属于<code>超参数</code>，是人工设定。一般需要尝试多个值，找到合适的参数。</p>          </div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-comment"># 神经网络求梯度</span><br><br><span class="hljs-keyword">import</span> sys,os<br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-keyword">from</span> source.common.functions <span class="hljs-keyword">import</span> softmax, cross_entropy_error<br><br><span class="hljs-keyword">from</span> source.common.gradient <span class="hljs-keyword">import</span> numerical_gradient<br><br>  <br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">simpleNet</span>:<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br><br>        self.W = np.random.randn(<span class="hljs-number">2</span>,<span class="hljs-number">3</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">predict</span> (self, x):<br><br>        <span class="hljs-keyword">return</span> np.dot(x,self.W)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">loss</span>(<span class="hljs-params">self,x,t</span>):<br><br>        z=self.predict(x)<br><br>        y=softmax(z)<br><br>        loss=cross_entropy_error(y,t)<br><br>  <br><br>        <span class="hljs-keyword">return</span> loss<br><br><span class="hljs-comment"># 定义 2x3 参数网络，输出预测值</span><br><br>net = simpleNet()<br><br><span class="hljs-built_in">print</span>(net.W)<br><br>x=np.array([<span class="hljs-number">0.6</span>,<span class="hljs-number">0.9</span>])<br><br>p=net.predict(x)<br><br><span class="hljs-built_in">print</span>(p)<br><br>  <br><br></code></pre></td></tr></table></figure><p>    [[ 0.10575028 -0.12302507  0.67452961]</p><p>     [-0.65135332  0.12114118  0.91331758]]</p><p>    [-0.52276782  0.03521202  1.22670359]</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-comment"># 设置正确标签，计算损失函数</span><br><br><span class="hljs-built_in">print</span>(np.argmax(p))<br><br>t=np.array([<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>])<br><br>net.loss(x,t)<br><br></code></pre></td></tr></table></figure><p>    2</p><p>    1.5819330169514783</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-comment"># 计算各个参数梯度</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">f</span>(<span class="hljs-params">W</span>):<br><br>    <span class="hljs-keyword">return</span> net.loss(x,t)<br><br>dW=numerical_gradient(f,net.W)<br><br><span class="hljs-built_in">print</span>(dW)<br><br></code></pre></td></tr></table></figure><p>    [[ 0.07059899 -0.47665343  0.40605444]</p><p>     [ 0.10589848 -0.71498015  0.60908166]]</p><h2 id="学习算法的实现"><a href="#学习算法的实现" class="headerlink" title="学习算法的实现"></a>学习算法的实现</h2><p>学习步骤如下：</p><ol><li><p>mini-batch</p></li><li><p>计算梯度</p></li><li><p>更新参数</p></li><li><p>重复 1.</p></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-comment"># 2层神经网络</span><br><br><span class="hljs-comment"># coding: utf-8</span><br><br><span class="hljs-keyword">import</span> sys, os<br><br>sys.path.append(os.pardir)  <span class="hljs-comment"># 为了导入父目录的文件而进行的设定</span><br><br><span class="hljs-keyword">from</span> source.common.functions <span class="hljs-keyword">import</span> *<br><br><span class="hljs-keyword">from</span> source.common.gradient <span class="hljs-keyword">import</span> numerical_gradient<br><br>  <br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">TwoLayerNet</span>:<br><br>  <br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, input_size, hidden_size, output_size, weight_init_std=<span class="hljs-number">0.01</span></span>):<br><br>        <span class="hljs-comment"># 初始化权重</span><br><br>        self.params = &#123;&#125;<br><br>        self.params[<span class="hljs-string">&#x27;W1&#x27;</span>] = weight_init_std * np.random.randn(input_size, hidden_size) <span class="hljs-comment"># 正态分布的 input x hidden 大小的数组</span><br><br>        self.params[<span class="hljs-string">&#x27;b1&#x27;</span>] = np.zeros(hidden_size)<br><br>        self.params[<span class="hljs-string">&#x27;W2&#x27;</span>] = weight_init_std * np.random.randn(hidden_size, output_size)<br><br>        self.params[<span class="hljs-string">&#x27;b2&#x27;</span>] = np.zeros(output_size)<br><br>  <br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">predict</span>(<span class="hljs-params">self, x</span>):<br><br>        W1, W2 = self.params[<span class="hljs-string">&#x27;W1&#x27;</span>], self.params[<span class="hljs-string">&#x27;W2&#x27;</span>]<br><br>        b1, b2 = self.params[<span class="hljs-string">&#x27;b1&#x27;</span>], self.params[<span class="hljs-string">&#x27;b2&#x27;</span>]<br><br>        a1 = np.dot(x, W1) + b1<br><br>        z1 = sigmoid(a1)<br><br>        a2 = np.dot(z1, W2) + b2<br><br>        y = softmax(a2)<br><br>        <span class="hljs-keyword">return</span> y<br><br>    <span class="hljs-comment"># x:输入数据, t:监督数据</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">loss</span>(<span class="hljs-params">self, x, t</span>):<br><br>        y = self.predict(x)<br><br>        <span class="hljs-keyword">return</span> cross_entropy_error(y, t)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">accuracy</span>(<span class="hljs-params">self, x, t</span>):<br><br>        y = self.predict(x)<br><br>        y = np.argmax(y, axis=<span class="hljs-number">1</span>)<br><br>        t = np.argmax(t, axis=<span class="hljs-number">1</span>)<br><br>        accuracy = np.<span class="hljs-built_in">sum</span>(y == t) / <span class="hljs-built_in">float</span>(x.shape[<span class="hljs-number">0</span>])<br><br>        <span class="hljs-keyword">return</span> accuracy<br><br>    <span class="hljs-comment"># x:输入数据, t:监督数据</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">numerical_gradient</span>(<span class="hljs-params">self, x, t</span>):<br><br>        loss_W = <span class="hljs-keyword">lambda</span> W: self.loss(x, t)<br><br>        grads = &#123;&#125;<br><br>        grads[<span class="hljs-string">&#x27;W1&#x27;</span>] = numerical_gradient(loss_W, self.params[<span class="hljs-string">&#x27;W1&#x27;</span>])<br><br>        grads[<span class="hljs-string">&#x27;b1&#x27;</span>] = numerical_gradient(loss_W, self.params[<span class="hljs-string">&#x27;b1&#x27;</span>])<br><br>        grads[<span class="hljs-string">&#x27;W2&#x27;</span>] = numerical_gradient(loss_W, self.params[<span class="hljs-string">&#x27;W2&#x27;</span>])<br><br>        grads[<span class="hljs-string">&#x27;b2&#x27;</span>] = numerical_gradient(loss_W, self.params[<span class="hljs-string">&#x27;b2&#x27;</span>])<br><br>        <span class="hljs-keyword">return</span> grads<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">gradient</span>(<span class="hljs-params">self, x, t</span>):<br><br>        W1, W2 = self.params[<span class="hljs-string">&#x27;W1&#x27;</span>], self.params[<span class="hljs-string">&#x27;W2&#x27;</span>]<br><br>        b1, b2 = self.params[<span class="hljs-string">&#x27;b1&#x27;</span>], self.params[<span class="hljs-string">&#x27;b2&#x27;</span>]<br><br>        grads = &#123;&#125;<br><br>        batch_num = x.shape[<span class="hljs-number">0</span>]<br><br>        <span class="hljs-comment"># forward</span><br><br>        a1 = np.dot(x, W1) + b1<br><br>        z1 = sigmoid(a1)<br><br>        a2 = np.dot(z1, W2) + b2<br><br>        y = softmax(a2)<br><br>        <span class="hljs-comment"># backward</span><br><br>        dy = (y - t) / batch_num<br><br>        grads[<span class="hljs-string">&#x27;W2&#x27;</span>] = np.dot(z1.T, dy)<br><br>        grads[<span class="hljs-string">&#x27;b2&#x27;</span>] = np.<span class="hljs-built_in">sum</span>(dy, axis=<span class="hljs-number">0</span>)<br><br>        da1 = np.dot(dy, W2.T)<br><br>        dz1 = sigmoid_grad(a1) * da1<br><br>        grads[<span class="hljs-string">&#x27;W1&#x27;</span>] = np.dot(x.T, dz1)<br><br>        grads[<span class="hljs-string">&#x27;b1&#x27;</span>] = np.<span class="hljs-built_in">sum</span>(dz1, axis=<span class="hljs-number">0</span>)<br><br>  <br><br>        <span class="hljs-keyword">return</span> grads<br><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-comment"># coding: utf-8</span><br><br><span class="hljs-keyword">import</span> sys, os<br><br>sys.path.append(os.pardir)  <span class="hljs-comment"># 为了导入父目录的文件而进行的设定</span><br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br><span class="hljs-keyword">from</span> source.dataset.mnist <span class="hljs-keyword">import</span> load_mnist<br><br><span class="hljs-keyword">from</span> source.ch04.two_layer_net <span class="hljs-keyword">import</span> TwoLayerNet<br><br>  <br><br><span class="hljs-comment"># 读入数据</span><br><br>(x_train, t_train), (x_test, t_test) = load_mnist(normalize=<span class="hljs-literal">True</span>, one_hot_label=<span class="hljs-literal">True</span>)<br><br>  <br><br>network = TwoLayerNet(input_size=<span class="hljs-number">784</span>, hidden_size=<span class="hljs-number">50</span>, output_size=<span class="hljs-number">10</span>)<br><br>  <br><br><span class="hljs-comment"># 超参数</span><br><br>iters_num = <span class="hljs-number">10000</span>  <span class="hljs-comment"># 适当设定循环的次数</span><br><br>train_size = x_train.shape[<span class="hljs-number">0</span>]<br><br>batch_size = <span class="hljs-number">100</span><br><br>learning_rate = <span class="hljs-number">0.1</span><br><br>  <br><br>train_loss_list = []<br><br>train_acc_list = []<br><br>test_acc_list = []<br><br>  <br><br>iter_per_epoch = <span class="hljs-built_in">max</span>(train_size / batch_size, <span class="hljs-number">1</span>)<br><br>  <br><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(iters_num):<br><br>    batch_mask = np.random.choice(train_size, batch_size)<br><br>    x_batch = x_train[batch_mask]<br><br>    t_batch = t_train[batch_mask]<br><br>    <span class="hljs-comment"># 计算梯度</span><br><br>    <span class="hljs-comment">#grad = network.numerical_gradient(x_batch, t_batch)</span><br><br>    grad = network.gradient(x_batch, t_batch)<br><br>    <span class="hljs-comment"># 更新参数</span><br><br>    <span class="hljs-keyword">for</span> key <span class="hljs-keyword">in</span> (<span class="hljs-string">&#x27;W1&#x27;</span>, <span class="hljs-string">&#x27;b1&#x27;</span>, <span class="hljs-string">&#x27;W2&#x27;</span>, <span class="hljs-string">&#x27;b2&#x27;</span>):<br><br>        network.params[key] -= learning_rate * grad[key]<br><br>    loss = network.loss(x_batch, t_batch)<br><br>    train_loss_list.append(loss)<br><br>    <span class="hljs-keyword">if</span> i % iter_per_epoch == <span class="hljs-number">0</span>:<br><br>        train_acc = network.accuracy(x_train, t_train)<br><br>        test_acc = network.accuracy(x_test, t_test)<br><br>        train_acc_list.append(train_acc)<br><br>        test_acc_list.append(test_acc)<br><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;train acc, test acc | &quot;</span> + <span class="hljs-built_in">str</span>(train_acc) + <span class="hljs-string">&quot;, &quot;</span> + <span class="hljs-built_in">str</span>(test_acc))<br><br>  <br><br><span class="hljs-comment"># 绘制图形</span><br><br>markers = &#123;<span class="hljs-string">&#x27;train&#x27;</span>: <span class="hljs-string">&#x27;o&#x27;</span>, <span class="hljs-string">&#x27;test&#x27;</span>: <span class="hljs-string">&#x27;s&#x27;</span>&#125;<br><br>x = np.arange(<span class="hljs-built_in">len</span>(train_acc_list))<br><br>plt.plot(x, train_acc_list, label=<span class="hljs-string">&#x27;train acc&#x27;</span>)<br><br>plt.plot(x, test_acc_list, label=<span class="hljs-string">&#x27;test acc&#x27;</span>, linestyle=<span class="hljs-string">&#x27;--&#x27;</span>)<br><br>plt.xlabel(<span class="hljs-string">&quot;epochs&quot;</span>)<br><br>plt.ylabel(<span class="hljs-string">&quot;accuracy&quot;</span>)<br><br>plt.ylim(<span class="hljs-number">0</span>, <span class="hljs-number">1.0</span>)<br><br>plt.legend(loc=<span class="hljs-string">&#x27;lower right&#x27;</span>)<br><br>plt.show()<br><br></code></pre></td></tr></table></figure><p>    train acc, test acc | 0.09863333333333334, 0.0958</p><p>    train acc, test acc | 0.7992, 0.8057</p><p>    train acc, test acc | 0.8787833333333334, 0.8825</p><p>    train acc, test acc | 0.9001166666666667, 0.9031</p><p>    train acc, test acc | 0.9101166666666667, 0.9111</p><p>    train acc, test acc | 0.9163833333333333, 0.9195</p><p>    train acc, test acc | 0.9212333333333333, 0.9224</p><p>    train acc, test acc | 0.9265333333333333, 0.9276</p><p>    train acc, test acc | 0.9294, 0.9307</p><p>    train acc, test acc | 0.9323166666666667, 0.9333</p><p>    train acc, test acc | 0.9355333333333333, 0.9358</p><p>    train acc, test acc | 0.9381, 0.9389</p><p>    train acc, test acc | 0.93975, 0.9407</p><p>    train acc, test acc | 0.9418166666666666, 0.9419</p><p>    train acc, test acc | 0.9431166666666667, 0.9421</p><p>    train acc, test acc | 0.9453666666666667, 0.9446</p><p>    train acc, test acc | 0.9470833333333334, 0.9461</p><p><img src="https://raw.githubusercontent.com/Destiny-End/images/master/202401041227839.png" alt="训练精度变化"></p><p>这里的<code>epochs</code>代表所有数据都被使用过一次时的更新次数。  </p><p>e.g 10000笔数据，mini-batch 是 100，则一个<code>epoch</code>就是 100次。  </p><p>注意到<code>train</code>和<code>test</code>的识别精度曲线基本重合，故可以认没有发生<code>过拟合现象</code></p>]]></content>
    
    
    <categories>
      
      <category>DL</category>
      
    </categories>
    
    
    <tags>
      
      <tag>python</tag>
      
      <tag>DL</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>3. 神经网络初步</title>
    <link href="/post/20240102134400.html"/>
    <url>/post/20240102134400.html</url>
    
    <content type="html"><![CDATA[<h2 id="神经网络"><a href="#神经网络" class="headerlink" title="神经网络"></a>神经网络</h2><p>感知机通过组合，可以变得很强大。</p><p>但是有个关键问题，即权重的设定，实在是太麻烦了。</p><p>神经网络，即是为了解决这个问题。实现自动从数据中学习到合适的权值参数</p><h3 id="引例"><a href="#引例" class="headerlink" title="引例"></a>引例</h3><p>神经网络一般分成三个部分：输入层，中间层（隐藏层），输出层。</p><p>若中间层只有一层，则实际有权重的只有<em>输入和中间</em>，故将其称为二层神经网络：输入1层+中间1层。</p><p>感知机的<code>偏置b</code>，实际可以理解为一个值始终为1，权值为b的<code>输入</code>。</p><p>如此一来，偏置也可以理解为参数问题。故要解决的只有参数了。</p><p>将偏置统一后，输出判定函数亦可改成与<em>0</em>进行比较。</p><p>引入<code>h(x)</code>来定义这个函数。则  </p><p>$$y&#x3D;h(b+\omega_1x_1+\omega_2x2)$$</p><p>$$<br>h(x)&#x3D;<br>\begin{cases}<br>0(x\leq0)\<br>1(x&gt;1)<br>\end{cases}<br>$$</p><h3 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h3><p>这个<code>h(x)</code>即可认为是激活函数。作用在于决定何时输出1。</p><p>这样一个神经元可以分成两部分。  </p><p>第一部分计算<code>sum</code>，即$a&#x3D;b+\omega_1x_1+\omega_2x2$  </p><p>第二部分将结果传递给<code>激活函数</code>，这里是$y&#x3D;h(sum)$  </p><p>下面介绍一些激活函数</p><h4 id="sigmoid函数"><a href="#sigmoid函数" class="headerlink" title="sigmoid函数"></a>sigmoid函数</h4><p>$$ h&#x3D;\frac{1}{1+\exp(-x)}$$</p><p>看起来复杂，实际也仅仅是个函数，理解成输入输出即可。</p><p>与阶跃函数比较：</p><h4 id="阶跃函数实现"><a href="#阶跃函数实现" class="headerlink" title="阶跃函数实现"></a>阶跃函数实现</h4><p>即上文的<code>h(x)</code>  </p><p>实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">step_function</span>(<span class="hljs-params">x</span>):<br><br>    <span class="hljs-keyword">if</span>(x&gt;<span class="hljs-number">0</span>):<br><br>        <span class="hljs-keyword">return</span> <span class="hljs-number">1</span><br><br>    <span class="hljs-keyword">else</span>:<br><br>        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span><br><br><span class="hljs-comment"># 但这个函数无法接收np数组。故采用下面的写法</span><br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">step_function</span>(<span class="hljs-params">x</span>):<br><br>    y=x&gt;<span class="hljs-number">0</span><br><br>    <span class="hljs-keyword">return</span> y.astype(np.<span class="hljs-built_in">int</span>)<br><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><br>x=np.array([-<span class="hljs-number">1.0</span>,<span class="hljs-number">1.0</span>,<span class="hljs-number">2.0</span>])<br><br><span class="hljs-built_in">print</span>(x)<br><br>y=x&gt;<span class="hljs-number">0</span><br><br><span class="hljs-built_in">print</span>(y)<br><br><span class="hljs-built_in">print</span>(y.dtype)<br><br>y=y.astype(np.int32)<br><br><span class="hljs-built_in">print</span>(y)<br><br></code></pre></td></tr></table></figure><p>    [-1.  1.  2.]</p><p>    [False  True  True]</p><p>    bool</p><p>    [0 1 1]</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-comment"># 绘制阶跃函数</span><br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-keyword">import</span> matplotlib.pylab <span class="hljs-keyword">as</span> plt<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">step_function</span>(<span class="hljs-params">x</span>):<br><br>    <span class="hljs-keyword">return</span> np.array(x&gt;<span class="hljs-number">0</span>,dtype=np.int32)<br><br>x=np.arange(-<span class="hljs-number">5.0</span>,<span class="hljs-number">5.0</span>,<span class="hljs-number">0.1</span>)<br><br>y=step_function(x)<br><br>plt.plot(x,y)<br><br>plt.ylim(-<span class="hljs-number">0.1</span>,<span class="hljs-number">1.1</span>)<br><br>plt.show()<br><br></code></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/Destiny-End/images/master/202401021340909.png" alt="阶跃函数"></p><h4 id="sigmoid函数实现"><a href="#sigmoid函数实现" class="headerlink" title="sigmoid函数实现"></a>sigmoid函数实现</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">sigmoid</span>(<span class="hljs-params">x</span>):<br><br>    <span class="hljs-keyword">return</span> <span class="hljs-number">1</span>/(<span class="hljs-number">1</span>+np.exp(-x))<br><br>x=np.array([-<span class="hljs-number">1.0</span>,<span class="hljs-number">1.0</span>,<span class="hljs-number">2.0</span>])<br><br><span class="hljs-built_in">print</span>(sigmoid(x))<br><br></code></pre></td></tr></table></figure><p>    [0.26894142 0.73105858 0.88079708]</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-comment"># 绘制sigmoid函数</span><br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-keyword">import</span> matplotlib.pylab <span class="hljs-keyword">as</span> plt<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">sigmoid</span>(<span class="hljs-params">x</span>):<br><br>    <span class="hljs-keyword">return</span> <span class="hljs-number">1</span>/(<span class="hljs-number">1</span>+np.exp(-x))<br><br>x=np.arange(-<span class="hljs-number">5.0</span>,<span class="hljs-number">5.0</span>,<span class="hljs-number">0.1</span>)<br><br>y=sigmoid(x)<br><br>plt.plot(x,y)<br><br>plt.ylim(-<span class="hljs-number">0.1</span>,<span class="hljs-number">1.1</span>)<br><br>plt.show()<br><br></code></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/Destiny-End/images/master/202401021341868.png" alt="sigmoid函数"></p><h4 id="比较"><a href="#比较" class="headerlink" title="比较"></a>比较</h4><ol><li>不同：</li></ol><p>   根据图像很容易看出不同。  </p><p>   <code>sigmoid函数</code>具有光滑的性质，故其可以输出许多中间值，例如0.712，0.435…  </p><p>   但阶跃函数只能输出0 or 1，选择激活或者不激活。</p><ol start="2"><li>相同：</li></ol><p>   两者都是在输入小时，输出接近0；输入大时，输出接近1。</p><p>   两者的输出都介于0和1之间。  </p><div class="note note-primary">            <p>非线性函数</p><p>线性函数的一个很大的问题是无法发挥隐藏层优势。即设线性函数为$$ h(x)&#x3D;cx$$</p><p>则三层神经网络，等于$$h(h(h(x)))$$然而这实际上就是$$h(x)&#x3D;a \times x \ a&#x3D;c^3$$</p>          </div><h4 id="ReLU-函数"><a href="#ReLU-函数" class="headerlink" title="ReLU 函数"></a>ReLU 函数</h4><p><strong>Rectified Linear Unit</strong></p><p>特性：在输入大于0时，输出该值；在输入小于0时，输出0</p><p>$$h(x)&#x3D;\begin{cases}<br>x(x&gt;0)\<br>0(x\leq 0)<br>\end{cases}$$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">relu</span>(<span class="hljs-params">x</span>):<br><br>    <span class="hljs-keyword">return</span> np.maximum(<span class="hljs-number">0</span>, x)<br><br></code></pre></td></tr></table></figure><h3 id="多维数组运算"><a href="#多维数组运算" class="headerlink" title="多维数组运算"></a>多维数组运算</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-comment"># 一维数组</span><br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br>A=np.array([<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>])<br><br><span class="hljs-built_in">print</span>(A)<br><br><span class="hljs-built_in">print</span>(np.ndim(A))<br><br><span class="hljs-built_in">print</span>(A.shape)<br><br><span class="hljs-built_in">print</span>(A.shape[<span class="hljs-number">0</span>])<br><br></code></pre></td></tr></table></figure><p>    [1 2 3 4]</p><p>    1</p><p>    (4,)</p><p>    4</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-comment"># 二维数组</span><br><br>B=np.array([[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>],[<span class="hljs-number">3</span>,<span class="hljs-number">4</span>],[<span class="hljs-number">5</span>,<span class="hljs-number">6</span>]])<br><br><span class="hljs-built_in">print</span>(B)<br><br><span class="hljs-built_in">print</span>(np.ndim(B))<br><br><span class="hljs-built_in">print</span>(B.shape)<br><br></code></pre></td></tr></table></figure><p>    [[1 2]</p><p>     [3 4]</p><p>     [5 6]]</p><p>    2</p><p>    (3, 2)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-comment"># 矩阵乘法</span><br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;A:2x2 B:2x2 : &quot;</span>)<br><br>A=np.array([[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>],[<span class="hljs-number">3</span>,<span class="hljs-number">4</span>]])<br><br><span class="hljs-built_in">print</span>(A.shape)<br><br>B=np.array([[<span class="hljs-number">5</span>,<span class="hljs-number">6</span>],[<span class="hljs-number">7</span>,<span class="hljs-number">8</span>]])<br><br><span class="hljs-built_in">print</span>(B.shape)<br><br><span class="hljs-built_in">print</span>(np.dot(A,B))<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;\nA:2x3 B:3x2 : &quot;</span>)<br><br>A=np.array([[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>],[<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">6</span>]])<br><br><span class="hljs-built_in">print</span>(A.shape)<br><br>B=np.array([[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>],[<span class="hljs-number">5</span>,<span class="hljs-number">6</span>],[<span class="hljs-number">7</span>,<span class="hljs-number">8</span>]])<br><br><span class="hljs-built_in">print</span>(B.shape)<br><br><span class="hljs-built_in">print</span>(np.dot(A,B))<br><br><span class="hljs-comment"># A列与B行保持一致</span><br><br></code></pre></td></tr></table></figure><p>    A:2x2 B:2x2 :</p><p>    (2, 2)</p><p>    (2, 2)</p><p>    [[19 22]</p><p>     [43 50]]</p><p>    A:2x3 B:3x2 :</p><p>    (2, 3)</p><p>    (3, 2)</p><p>    [[32 38]</p><p>     [71 86]]</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-comment"># 神经网络内积</span><br><br>X=np.array([<span class="hljs-number">1</span>,<span class="hljs-number">2</span>])<br><br><span class="hljs-built_in">print</span>(X.shape)<br><br>W=np.array([[<span class="hljs-number">1</span>,<span class="hljs-number">3</span>,<span class="hljs-number">5</span>],[<span class="hljs-number">2</span>,<span class="hljs-number">4</span>,<span class="hljs-number">6</span>]])<br><br><span class="hljs-built_in">print</span>(W)<br><br><span class="hljs-built_in">print</span>(W.shape)<br><br>Y=np.dot(X,W)<br><br><span class="hljs-built_in">print</span>(Y)<br><br></code></pre></td></tr></table></figure><p>    (2,)</p><p>    [[1 3 5]</p><p>     [2 4 6]]</p><p>    (2, 3)</p><p>    [ 5 11 17]</p><h2 id="3层神经网络实现"><a href="#3层神经网络实现" class="headerlink" title="3层神经网络实现"></a>3层神经网络实现</h2><p>$$w^{(1)}<em>{12}\<br>w^{(1)}代表第1层权重\<br>w</em>{1.}代表后一层第1个神经元\  <br>w_{.2}代表前一层第2个神经元$$</p><p>注意，越“前”即越靠近输出层，越“后”越靠近输入层</p><h3 id="各层传递"><a href="#各层传递" class="headerlink" title="各层传递"></a>各层传递</h3><p>$$a^{(1)}<em>1&#x3D;\omega^{(1)}</em>{11}x_1+\omega^{(1)}<em>{12}x_2+\omega^{(1)}</em>{13}x_3\矩阵形式：A^{(1)}&#x3D;XW^{(1)}+B^{(1)}<br>$$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-comment"># 1层</span><br><br>X=np.array([<span class="hljs-number">1.0</span>,<span class="hljs-number">0.5</span>])<br><br>W1=np.array([[<span class="hljs-number">0.1</span>,<span class="hljs-number">0.3</span>,<span class="hljs-number">0.5</span>],[<span class="hljs-number">0.2</span>,<span class="hljs-number">0.4</span>,<span class="hljs-number">0.6</span>]])<br><br>B1=np.array([<span class="hljs-number">0.1</span>,<span class="hljs-number">0.2</span>,<span class="hljs-number">0.3</span>])<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;W1.shape : &quot;</span>+<span class="hljs-built_in">str</span>(W1.shape))<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;X.shape : &quot;</span>+<span class="hljs-built_in">str</span>(X.shape))<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;B1.shape : &quot;</span>+<span class="hljs-built_in">str</span>(B1.shape))<br><br>A1=np.dot(X,W1)+B1<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;A1 : &quot;</span>+<span class="hljs-built_in">str</span>(A1))<br><br>Z1=sigmoid(A1)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Z1 : &quot;</span>+<span class="hljs-built_in">str</span>(Z1))<br><br></code></pre></td></tr></table></figure><p>    W1.shape : (2, 3)</p><p>    X.shape : (2,)</p><p>    B1.shape : (3,)</p><p>    A1 : [0.3 0.7 1.1]</p><p>    Z1 : [0.57444252 0.66818777 0.75026011]</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-comment"># 2层</span><br><br>W2=np.array([[<span class="hljs-number">0.1</span>,<span class="hljs-number">0.4</span>],[<span class="hljs-number">0.2</span>,<span class="hljs-number">0.5</span>],[<span class="hljs-number">0.3</span>,<span class="hljs-number">0.6</span>]])<br><br>B2=np.array([<span class="hljs-number">0.1</span>,<span class="hljs-number">0.2</span>])<br><br><span class="hljs-built_in">print</span>(Z1.shape)<br><br><span class="hljs-built_in">print</span>(W2.shape)<br><br><span class="hljs-built_in">print</span>(B2.shape)<br><br>A2=np.dot(Z1,W2)+B2<br><br>Z2=sigmoid(A2)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;A2 : &quot;</span>+<span class="hljs-built_in">str</span>(A2))<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Z2 : &quot;</span>+<span class="hljs-built_in">str</span>(Z2))<br><br></code></pre></td></tr></table></figure><p>    (3,)</p><p>    (3, 2)</p><p>    (2,)</p><p>    A2 : [0.51615984 1.21402696]</p><p>    Z2 : [0.62624937 0.7710107 ]</p><p>输出层的激活函数与隐藏层有所不同</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-comment"># 第三层</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">identity_function</span>(<span class="hljs-params">x</span>):<br><br>    <span class="hljs-keyword">return</span> x<br><br>W3=np.array([[<span class="hljs-number">0.1</span>,<span class="hljs-number">0.3</span>],[<span class="hljs-number">0.2</span>,<span class="hljs-number">0.4</span>]])<br><br>B3=np.array([<span class="hljs-number">0.1</span>,<span class="hljs-number">0.2</span>])<br><br>A3=np.dot(Z2,W3)+B3<br><br>Y=identity_function(A3)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Y: &quot;</span>+<span class="hljs-built_in">str</span>(Y))<br><br></code></pre></td></tr></table></figure><p>    Y: [0.31682708 0.69627909]</p><h3 id="代码实现总结"><a href="#代码实现总结" class="headerlink" title="代码实现总结"></a>代码实现总结</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_network</span>():<br><br>    network = &#123;&#125;<br><br>    network[<span class="hljs-string">&#x27;W1&#x27;</span>] = np.array([[<span class="hljs-number">0.1</span>, <span class="hljs-number">0.3</span>, <span class="hljs-number">0.5</span>], [<span class="hljs-number">0.2</span>, <span class="hljs-number">0.4</span>, <span class="hljs-number">0.6</span>]])<br><br>    network[<span class="hljs-string">&#x27;b1&#x27;</span>] = np.array([<span class="hljs-number">0.1</span>, <span class="hljs-number">0.2</span>, <span class="hljs-number">0.3</span>])<br><br>    network[<span class="hljs-string">&#x27;W2&#x27;</span>] = np.array([[<span class="hljs-number">0.1</span>, <span class="hljs-number">0.4</span>], [<span class="hljs-number">0.2</span>, <span class="hljs-number">0.5</span>], [<span class="hljs-number">0.3</span>, <span class="hljs-number">0.6</span>]])<br><br>    network[<span class="hljs-string">&#x27;b2&#x27;</span>] = np.array([<span class="hljs-number">0.1</span>, <span class="hljs-number">0.2</span>])<br><br>    network[<span class="hljs-string">&#x27;W3&#x27;</span>] = np.array([[<span class="hljs-number">0.1</span>, <span class="hljs-number">0.3</span>], [<span class="hljs-number">0.2</span>, <span class="hljs-number">0.4</span>]])<br><br>    network[<span class="hljs-string">&#x27;b3&#x27;</span>] = np.array([<span class="hljs-number">0.1</span>, <span class="hljs-number">0.2</span>])<br><br>    <span class="hljs-keyword">return</span> network<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">network, x</span>):<br><br>    W1, W2, W3 = network[<span class="hljs-string">&#x27;W1&#x27;</span>], network[<span class="hljs-string">&#x27;W2&#x27;</span>], network[<span class="hljs-string">&#x27;W3&#x27;</span>]<br><br>    b1, b2, b3 = network[<span class="hljs-string">&#x27;b1&#x27;</span>], network[<span class="hljs-string">&#x27;b2&#x27;</span>], network[<span class="hljs-string">&#x27;b3&#x27;</span>]<br><br>    a1 = np.dot(x, W1) + b1<br><br>    z1 = sigmoid(a1)<br><br>    a2 = np.dot(z1, W2) + b2<br><br>    z2 = sigmoid(a2)<br><br>    a3 = np.dot(z2, W3) + b3<br><br>    y = identity_function(a3)<br><br>    <span class="hljs-keyword">return</span> y<br><br>network = init_network()<br><br>x = np.array([<span class="hljs-number">1.0</span>, <span class="hljs-number">0.5</span>])<br><br>y = forward(network, x)<br><br><span class="hljs-built_in">print</span>(y) <span class="hljs-comment"># [ 0.31682708 0.69627909]</span><br><br></code></pre></td></tr></table></figure><p>    [0.31682708 0.69627909]</p><h2 id="输出层设计"><a href="#输出层设计" class="headerlink" title="输出层设计"></a>输出层设计</h2><p>一般而言，<em>回归问题</em>用<code>恒等函数</code>,<em>分类问题</em>用<code>softmax函数</code></p><h3 id="恒等函数和softmax函数"><a href="#恒等函数和softmax函数" class="headerlink" title="恒等函数和softmax函数"></a>恒等函数和softmax函数</h3><p><code>恒等函数</code>不改变值，直接输出即可。</p><p><code>softmax函数</code>如下</p><p>$$y_k&#x3D;\frac{\exp{(a_k)}}{\sum_{i&#x3D;1}^n \exp{(a_i)}}\</p><p>分子：输入信号a_k的指数函数\</p><p>分母：所有输入信号指数函数之和$$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><br>a=np.array([<span class="hljs-number">0.3</span>,<span class="hljs-number">2.9</span>,<span class="hljs-number">4.0</span>])<br><br>exp_a=np.exp(a)<br><br><span class="hljs-built_in">print</span>(exp_a)<br><br></code></pre></td></tr></table></figure><p>    [ 1.34985881 18.17414537 54.59815003]</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><br>sum_exp_a=np.<span class="hljs-built_in">sum</span>(exp_a)<br><br><span class="hljs-built_in">print</span>(sum_exp_a)<br><br></code></pre></td></tr></table></figure><p>    74.1221542101633</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><br>y=exp_a/sum_exp_a<br><br><span class="hljs-built_in">print</span>(y)<br><br></code></pre></td></tr></table></figure><p>    [0.01821127 0.24519181 0.73659691]</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">softmax</span>(<span class="hljs-params">a</span>):<br><br>    exp_a=np.exp(a)<br><br>    sum_exp_a=np.<span class="hljs-built_in">sum</span>(exp_a)<br><br>    y=exp_a/sum_exp_a<br><br>    <span class="hljs-keyword">return</span> y<br><br></code></pre></td></tr></table></figure><div class="note note-danger">            <p><code>softmax函数</code>的实现，在计算机运算上有一定的缺陷。即容易溢出。</p><p>故进行如下改进</p><p>$$ y_k&#x3D;\frac{\exp{a_k+C^{‘}}}{\sum_{i&#x3D;1}^{n}\exp{a_i+C^{‘}}}$$</p><p>分子分母同时乘一个常数，值是不改变的。一般选取<code>C&#39;</code>为<code>输入信号的最大值</code></p>          </div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><br>a=np.array([<span class="hljs-number">1010</span>,<span class="hljs-number">1000</span>,<span class="hljs-number">990</span>])<br><br><span class="hljs-built_in">print</span>(np.exp(a)/np.<span class="hljs-built_in">sum</span>(np.exp(a)))<br><br>c=np.<span class="hljs-built_in">max</span>(a)<br><br><span class="hljs-built_in">print</span>(a-c)<br><br><span class="hljs-built_in">print</span>(np.exp(a-c)/np.<span class="hljs-built_in">sum</span>(np.exp(a-c)))<br><br></code></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs output">    [nan nan nan]<br><br>    [  0 -10 -20]<br><br>    [9.99954600e-01 4.53978686e-05 2.06106005e-09]<br><br>    C:\Users\Pigeon\AppData\Local\Temp\ipykernel_15560\2797153748.py:2: RuntimeWarning: overflow encountered in exp<br><br>      print(np.exp(a)/np.sum(np.exp(a)))<br><br>    C:\Users\Pigeon\AppData\Local\Temp\ipykernel_15560\2797153748.py:2: RuntimeWarning: invalid value encountered in true_divide<br><br>      print(np.exp(a)/np.sum(np.exp(a)))<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-comment"># 修正的softmax</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">softmax</span>(<span class="hljs-params">a</span>):<br><br>    c=np.<span class="hljs-built_in">max</span>(a)<br><br>    exp_a=np.exp(a-c)<br><br>    sum_exp_a=np.<span class="hljs-built_in">sum</span>(exp_a)<br><br>    y=exp_a/sum_exp_a<br><br>    <span class="hljs-keyword">return</span> y<br><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><br>a=np.array([<span class="hljs-number">0.3</span>,<span class="hljs-number">2.9</span>,<span class="hljs-number">4.0</span>])<br><br>y=softmax(a)<br><br><span class="hljs-built_in">print</span>(y)<br><br><span class="hljs-built_in">print</span>(np.<span class="hljs-built_in">sum</span>(y))<br><br></code></pre></td></tr></table></figure><p>    [0.01821127 0.24519181 0.73659691]</p><p>    1.0</p><h3 id="softmax函数特征"><a href="#softmax函数特征" class="headerlink" title="softmax函数特征"></a>softmax函数特征</h3><p>由于总和是1，故可以将其理解为不同输出的<code>概率分布</code>  </p><p>如上结果，可认为<code>y[0]</code>的概率为<code>0.018</code>,<code>y[1]</code>的概率为<code>0.245</code>,<code>y[2]</code>的概率为<code>0.737</code>  </p><p>故可以解释为：<em>因为第2个元素概率最高，所以答案是第2个类别</em>  </p><p>或者：<em>有74%的概率是第2个类别，25%是第1个类别，1%是第0个类别</em>  </p><p>softmax函数是单调递增函数，故它不会改变元素之间的大小关系。  </p><h2 id="手写数字识别"><a href="#手写数字识别" class="headerlink" title="手写数字识别"></a>手写数字识别</h2><p><code>MINISET</code>是一个包含了数字图像的训练集。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-comment"># coding: utf-8</span><br><br><span class="hljs-keyword">import</span> sys, os<br><br>sys.path.append(os.pardir)  <span class="hljs-comment"># 为了导入父目录的文件而进行的设定</span><br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-keyword">from</span> source.dataset.mnist <span class="hljs-keyword">import</span> load_mnist <span class="hljs-comment"># 我将本书源代码放在了同级的source文件夹里，故load函数是source.***</span><br><br><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">img_show</span>(<span class="hljs-params">img</span>):<br><br>    pil_img = Image.fromarray(np.uint8(img))<br><br>    pil_img.show()<br><br>(x_train, t_train), (x_test, t_test) = load_mnist(flatten=<span class="hljs-literal">True</span>, normalize=<span class="hljs-literal">False</span>)<br><br><span class="hljs-comment"># flatten   表示展开成一维数组，即 1*28*28 的三维数组 变成 一维 784元素数组</span><br><br><span class="hljs-comment"># normalize 表示将输入图像正则化为0.0-1.0的值。False 则保持输入图像的像素为0-255</span><br><br>img = x_train[<span class="hljs-number">0</span>]<br><br>label = t_train[<span class="hljs-number">0</span>]<br><br><span class="hljs-built_in">print</span>(label)  <span class="hljs-comment"># 5</span><br><br><span class="hljs-built_in">print</span>(img.shape)  <span class="hljs-comment"># (784,)</span><br><br>img = img.reshape(<span class="hljs-number">28</span>, <span class="hljs-number">28</span>)  <span class="hljs-comment"># 把图像的形状变为原来的尺寸</span><br><br><span class="hljs-built_in">print</span>(img.shape)  <span class="hljs-comment"># (28, 28)</span><br><br>img_show(img)<br><br></code></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><code class="hljs output">    Downloading train-images-idx3-ubyte.gz ...<br><br>    Done<br><br>    Downloading train-labels-idx1-ubyte.gz ...<br><br>    Done<br><br>    Downloading t10k-images-idx3-ubyte.gz ...<br><br>    Done<br><br>    Downloading t10k-labels-idx1-ubyte.gz ...<br><br>    Done<br><br>    Converting train-images-idx3-ubyte.gz to NumPy Array ...<br><br>    Done<br><br>    Converting train-labels-idx1-ubyte.gz to NumPy Array ...<br><br>    Done<br><br>    Converting t10k-images-idx3-ubyte.gz to NumPy Array ...<br><br>    Done<br><br>    Converting t10k-labels-idx1-ubyte.gz to NumPy Array ...<br><br>    Done<br><br>    Creating pickle file ...<br><br>    Done!<br><br>    5<br><br>    (784,)<br><br>    (28, 28)<br></code></pre></td></tr></table></figure><h3 id="神经网络处理"><a href="#神经网络处理" class="headerlink" title="神经网络处理"></a>神经网络处理</h3><p>输入层：图像像素，共784个神经元</p><p>输出层：识别出来的数字，共10个神经元</p><p>隐藏层：设计为2层，第1层50个，第2层100个  </p><p>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-comment"># coding: utf-8</span><br><br><span class="hljs-keyword">import</span> sys, os<br><br>sys.path.append(os.pardir)  <span class="hljs-comment"># 为了导入父目录的文件而进行的设定</span><br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-keyword">import</span> pickle<br><br><span class="hljs-keyword">from</span> source.dataset.mnist <span class="hljs-keyword">import</span> load_mnist<br><br><span class="hljs-keyword">from</span> source.common.functions <span class="hljs-keyword">import</span> sigmoid, softmax<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_data</span>():<br><br>    (x_train, t_train), (x_test, t_test) = load_mnist(normalize=<span class="hljs-literal">True</span>, flatten=<span class="hljs-literal">True</span>, one_hot_label=<span class="hljs-literal">False</span>)<br><br>    <span class="hljs-keyword">return</span> x_test, t_test<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_network</span>():<br><br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;./source/ch03/sample_weight.pkl&quot;</span>, <span class="hljs-string">&#x27;rb&#x27;</span>) <span class="hljs-keyword">as</span> f:<br><br>        network = pickle.load(f)<br><br>    <span class="hljs-keyword">return</span> network<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">predict</span>(<span class="hljs-params">network, x</span>):<br><br>    W1, W2, W3 = network[<span class="hljs-string">&#x27;W1&#x27;</span>], network[<span class="hljs-string">&#x27;W2&#x27;</span>], network[<span class="hljs-string">&#x27;W3&#x27;</span>]<br><br>    b1, b2, b3 = network[<span class="hljs-string">&#x27;b1&#x27;</span>], network[<span class="hljs-string">&#x27;b2&#x27;</span>], network[<span class="hljs-string">&#x27;b3&#x27;</span>]<br><br>    a1 = np.dot(x, W1) + b1<br><br>    z1 = sigmoid(a1)<br><br>    a2 = np.dot(z1, W2) + b2<br><br>    z2 = sigmoid(a2)<br><br>    a3 = np.dot(z2, W3) + b3<br><br>    y = softmax(a3)<br><br>    <span class="hljs-keyword">return</span> y<br><br></code></pre></td></tr></table></figure><div class="note note-success">            <p>init_network() 读入pickle文件中 已经学习好的权重参数</p>          </div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><br>x, t = get_data()<br><br>network = init_network()<br><br>accuracy_cnt = <span class="hljs-number">0</span><br><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(x)):<br><br>    y = predict(network, x[i])<br><br>    p= np.argmax(y) <span class="hljs-comment"># 获取概率最高的元素的索引</span><br><br>    <span class="hljs-keyword">if</span> p == t[i]:<br><br>        accuracy_cnt += <span class="hljs-number">1</span><br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Accuracy:&quot;</span> + <span class="hljs-built_in">str</span>(<span class="hljs-built_in">float</span>(accuracy_cnt) / <span class="hljs-built_in">len</span>(x)))<br><br></code></pre></td></tr></table></figure><p>    Accuracy:0.9352</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><br>x,_=get_data()<br><br>network=init_network()<br><br>W1,W2,W3=network[<span class="hljs-string">&#x27;W1&#x27;</span>],network[<span class="hljs-string">&#x27;W2&#x27;</span>],network[<span class="hljs-string">&#x27;W3&#x27;</span>]<br><br><span class="hljs-built_in">print</span>(x.shape)<br><br><span class="hljs-built_in">print</span>(x[<span class="hljs-number">0</span>].shape)<br><br><span class="hljs-built_in">print</span>(W1.shape)<br><br><span class="hljs-built_in">print</span>(W2.shape)<br><br><span class="hljs-built_in">print</span>(W3.shape)<br><br></code></pre></td></tr></table></figure><p>    (10000, 784)</p><p>    (784,)</p><p>    (784, 50)</p><p>    (50, 100)</p><p>    (100, 10)</p><p>单图片维数变化图</p><p><img src="https://raw.githubusercontent.com/Destiny-End/images/master/202401021317612.png" alt="单图维数变化"></p><h3 id="批处理"><a href="#批处理" class="headerlink" title="批处理"></a>批处理</h3><p>大多数数值计算的库都进行了能够高效处理代行数组运算的最优化。  </p><p>使用批处理可以大幅缩短每张图像的处理时间</p><p>批处理代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><br>x, t = get_data()<br><br>network = init_network()<br><br>batch_size = <span class="hljs-number">100</span> <span class="hljs-comment"># 批数量</span><br><br>accuracy_cnt = <span class="hljs-number">0</span><br><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(x), batch_size):<br><br>    x_batch = x[i:i+batch_size] <span class="hljs-comment">#将X分批</span><br><br>    y_batch = predict(network, x_batch) <span class="hljs-comment">#这一批每个的结果概率</span><br><br>    p = np.argmax(y_batch, axis=<span class="hljs-number">1</span>) <span class="hljs-comment">#找到这一批当中每个的概率最大的索引</span><br><br>    accuracy_cnt += np.<span class="hljs-built_in">sum</span>(p == t[i:i+batch_size]) <span class="hljs-comment">#计算与结果是否相符</span><br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Accuracy:&quot;</span> + <span class="hljs-built_in">str</span>(<span class="hljs-built_in">float</span>(accuracy_cnt) / <span class="hljs-built_in">len</span>(x)))<br><br></code></pre></td></tr></table></figure><p>    Accuracy:0.9352</p><p>批处理维数变化：</p><p><img src="https://raw.githubusercontent.com/Destiny-End/images/master/202401021317612.png" alt="批处理维数变化"></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ol><li><p>分类问题在输出层使用<code>softmax</code>函数，总和是1，每项输出代表该索引概率。</p></li><li><p>激活函数一般使用<code>sigmoid</code>函数或者<code>ReLU</code>函数，<code>ReLU</code>:Rectified Linear Unit,矫正线性单元</p></li><li><p>机器学习问题大体分为回归和分类问题</p></li></ol><p>   回归问题一般使用恒等函数</p><p>   分类问题一般使用<code>softmax</code>函数</p><ol start="4"><li><p>分类问题输出层设置为要分类的类别数</p></li><li><p>以批处理进行运算，可大幅提高运算速度。上面的结果中，未使用批处理是<code>0.6s</code>，而使用批处理是<code>0.2s</code></p></li></ol>]]></content>
    
    
    <categories>
      
      <category>DL</category>
      
    </categories>
    
    
    <tags>
      
      <tag>python</tag>
      
      <tag>DL</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>2. 感知机</title>
    <link href="/post/20240102103800.html"/>
    <url>/post/20240102103800.html</url>
    
    <content type="html"><![CDATA[<h2 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h2><p>感知机类似一个函数，接收多个输入，形成一个输出。接收的每个输入，会为其赋予不同的权重<strong>w</strong>，再将它们累加，与感知机的阈值<strong>theta</strong>比较。若<em>小于等于</em>阈值，则输出0;大于则输出1。</p><h2 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h2><p>一个感知机，实际上类似于“变色龙”的角色。控制其参数的构成，就可以得到多种逻辑门。“统一构造”，使得原始问题转变为了确定参数问题。在形成多种逻辑门的时候，是我们人自行设计参数，来完成我们的需求。</p><p>而机器学习，就是将这个<strong>决定参数的工作</strong>交给机器来完成。通过<strong>学习</strong>来确定合适的参数。我们需要做的就是思考构造（<em>模型</em>），并给计算机训练数据。</p><h2 id="Python简单实现"><a href="#Python简单实现" class="headerlink" title="Python简单实现"></a>Python简单实现</h2><h3 id="引例"><a href="#引例" class="headerlink" title="引例"></a>引例</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-comment"># 感知机实现的简单代码</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">AND</span>(<span class="hljs-params">x1,x2</span>):<br><br>    w1,w2,theta=<span class="hljs-number">0.5</span>,<span class="hljs-number">0.5</span>,<span class="hljs-number">0.7</span><br><br>    tmp=x1*w1+x2*w2-theta<br><br>    <span class="hljs-keyword">if</span> tmp&lt;=<span class="hljs-number">0</span>:<br><br>        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span><br><br>    <span class="hljs-keyword">else</span>:<br><br>        <span class="hljs-keyword">return</span> <span class="hljs-number">1</span><br><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-comment"># test AND func</span><br><br><span class="hljs-built_in">print</span>(AND(<span class="hljs-number">0</span>,<span class="hljs-number">0</span>))<br><br><span class="hljs-built_in">print</span>(AND(<span class="hljs-number">1</span>,<span class="hljs-number">0</span>))<br><br><span class="hljs-built_in">print</span>(AND(<span class="hljs-number">0</span>,<span class="hljs-number">1</span>))<br><br><span class="hljs-built_in">print</span>(AND(<span class="hljs-number">1</span>,<span class="hljs-number">1</span>))<br><br></code></pre></td></tr></table></figure><p>    0</p><p>    0</p><p>    0</p><p>    1</p><h4 id="使用NumPy完成"><a href="#使用NumPy完成" class="headerlink" title="使用NumPy完成"></a>使用NumPy完成</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-comment"># np使用</span><br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br>x=np.array([<span class="hljs-number">0</span>,<span class="hljs-number">1</span>])<br><br>w=np.array([<span class="hljs-number">0.5</span>,<span class="hljs-number">0.5</span>])<br><br>b=-<span class="hljs-number">0.7</span><br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot; w * x = &quot;</span>+<span class="hljs-built_in">str</span>(w*x))<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;np.sum = &quot;</span>+<span class="hljs-built_in">str</span>(np.<span class="hljs-built_in">sum</span>(w*x)))<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;np.sum + b = &quot;</span>+<span class="hljs-built_in">str</span>(np.<span class="hljs-built_in">sum</span>(w*x) + b)) <span class="hljs-comment">#有误差，由float定义导致，0.2无法精确表示。</span><br><br></code></pre></td></tr></table></figure><p>     w * x &#x3D; [0.  0.5]</p><p>    np.sum &#x3D; 0.5</p><p>    np.sum + b &#x3D; -0.19999999999999996</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-comment"># np AND</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">AND</span>(<span class="hljs-params">x1,x2</span>):<br><br>    x=np.array([x1,x2])<br><br>    w=np.array([<span class="hljs-number">0.5</span>,<span class="hljs-number">0.5</span>])<br><br>    b=-<span class="hljs-number">0.7</span><br><br>    tmp=np.<span class="hljs-built_in">sum</span>(w*x)+b<br><br>    <span class="hljs-keyword">if</span>(tmp &lt;= <span class="hljs-number">0</span>):<br><br>        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span><br><br>    <span class="hljs-keyword">else</span>:<br><br>        <span class="hljs-keyword">return</span> <span class="hljs-number">1</span><br><br><span class="hljs-comment"># 注意这里b是偏置，绝对值越大，越难激活。实际上比较的是 w*b&lt;=b ? 0:1</span><br><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-comment"># np NAND</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">NAND</span>(<span class="hljs-params">x1,x2</span>):<br><br>    x=np.array([x1,x2])<br><br>    <span class="hljs-comment"># 仅w和b不同，其余一致。</span><br><br>    w=np.array([-<span class="hljs-number">0.5</span>,-<span class="hljs-number">0.5</span>])<br><br>    b=<span class="hljs-number">0.7</span><br><br>    tmp=np.<span class="hljs-built_in">sum</span>(w*x)+b<br><br>    <span class="hljs-keyword">if</span>(tmp &lt;= <span class="hljs-number">0</span>):<br><br>        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span><br><br>    <span class="hljs-keyword">else</span>:<br><br>        <span class="hljs-keyword">return</span> <span class="hljs-number">1</span><br><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-comment"># np OR</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">OR</span>(<span class="hljs-params">x1,x2</span>):<br><br>    x=np.array([x1,x2])<br><br>    <span class="hljs-comment"># 仅w和b不同，其余一致。</span><br><br>    w=np.array([<span class="hljs-number">0.5</span>,<span class="hljs-number">0.5</span>])<br><br>    b=-<span class="hljs-number">0.2</span><br><br>    tmp=np.<span class="hljs-built_in">sum</span>(w*x)+b<br><br>    <span class="hljs-keyword">if</span>(tmp &lt;= <span class="hljs-number">0</span>):<br><br>        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span><br><br>    <span class="hljs-keyword">else</span>:<br><br>        <span class="hljs-keyword">return</span> <span class="hljs-number">1</span><br><br></code></pre></td></tr></table></figure><h3 id="多层感知机"><a href="#多层感知机" class="headerlink" title="多层感知机"></a>多层感知机</h3><p>XOR 逻辑门，则无法由感知机实现。</p><p>因为感知机只能形成一条<strong>直线</strong>，即将空间分成线性空间。而XOR需要非线性空间，即用曲线分割。</p><p>故使用多层感知机来完成。</p><h4 id="实现XOR"><a href="#实现XOR" class="headerlink" title="实现XOR"></a>实现XOR</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-comment"># XOR</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">XOR</span>(<span class="hljs-params">x1,x2</span>):<br><br>    s1=NAND(x1,x2)<br><br>    s2=OR(x1,x2)<br><br>    y=AND(s1,s2)<br><br>    <span class="hljs-keyword">return</span> y<br><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-comment"># test XOR</span><br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;xor(0,0) : &quot;</span>+<span class="hljs-built_in">str</span>(XOR(<span class="hljs-number">0</span>,<span class="hljs-number">0</span>)))<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;xor(0,1) : &quot;</span>+<span class="hljs-built_in">str</span>(XOR(<span class="hljs-number">0</span>,<span class="hljs-number">1</span>)))<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;xor(1,0) : &quot;</span>+<span class="hljs-built_in">str</span>(XOR(<span class="hljs-number">1</span>,<span class="hljs-number">0</span>)))<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;xor(1,1) : &quot;</span>+<span class="hljs-built_in">str</span>(XOR(<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)))<br><br></code></pre></td></tr></table></figure><p>    xor(0,0) : 0</p><p>    xor(0,1) : 1</p><p>    xor(1,0) : 1</p><p>    xor(1,1) : 0</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ol><li><p>感知机即接收多个输入，形成一个输出</p></li><li><p>不同感知机仅参数不同，其余完全一致</p></li><li><p>单个感知机仅可完成<strong>线性分割</strong>，即实现<strong>AND,NAND,OR</strong></p></li><li><p>通过对感知机进行组合，即可实现<strong>非线性分隔</strong>，即完成复杂的函数，类似于XOR。</p></li><li><p>实际上，多层感知机足以构建起一个计算机</p></li></ol>]]></content>
    
    
    <categories>
      
      <category>DL</category>
      
    </categories>
    
    
    <tags>
      
      <tag>python</tag>
      
      <tag>DL</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>1. python基础</title>
    <link href="/post/20231230113500.html"/>
    <url>/post/20231230113500.html</url>
    
    <content type="html"><![CDATA[<h2 id="1-3-python入门"><a href="#1-3-python入门" class="headerlink" title="1.3 python入门"></a>1.3 python入门</h2><h3 id="1-3-2-查看数据类型"><a href="#1-3-2-查看数据类型" class="headerlink" title="1.3.2 查看数据类型"></a>1.3.2 查看数据类型</h3><p>使用type()</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-built_in">type</span>(<span class="hljs-number">10.04</span>)<br><br><span class="hljs-comment">## float</span><br><br></code></pre></td></tr></table></figure><h3 id="1-3-4-列表基本用法"><a href="#1-3-4-列表基本用法" class="headerlink" title="1.3.4 列表基本用法"></a>1.3.4 列表基本用法</h3><p>如下</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><br>a=[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">5</span>]<br><span class="hljs-built_in">print</span>(a)<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">len</span>(a))<br>a[<span class="hljs-number">0</span>]<br>a[<span class="hljs-number">4</span>]<br>a[<span class="hljs-number">4</span>]=<span class="hljs-number">99</span><br><span class="hljs-built_in">print</span>(a)<br><br><span class="hljs-comment">## [1, 2, 3, 4, 5]</span><br><span class="hljs-comment">## 5</span><br><span class="hljs-comment">## [1, 2, 3, 4, 99]</span><br><br><br></code></pre></td></tr></table></figure><h4 id="元素访问-切片"><a href="#元素访问-切片" class="headerlink" title="元素访问 切片"></a>元素访问 切片</h4><p>从0开始</p><p>“：”代表切片</p><p><code>:</code>前代表开始元素，后代表结束元素</p><p>前后都可用正负，正表示第几个，负表示相对于<code>n</code>的距离。故<code>-1</code>代表<code>n-1</code>,代表最后一个元素。</p><p>例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><br>a=[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">99</span>]<br><br><span class="hljs-built_in">print</span>(a[-<span class="hljs-number">4</span>:-<span class="hljs-number">1</span>])<br><br><span class="hljs-comment">## [2, 3, 4]</span><br><br><span class="hljs-built_in">print</span>(a[-<span class="hljs-number">3</span>:])<br><br><span class="hljs-comment">## [3,4,99]</span><br><br></code></pre></td></tr></table></figure><p>若<code>:</code>前后留空,则<br>    前空代表从头开始<br>    后空代表遍历到结尾</p><p>若超出范围，返回空列表。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-built_in">print</span>(a)<br><span class="hljs-built_in">print</span>(a[<span class="hljs-number">0</span>:<span class="hljs-number">2</span>])<br><span class="hljs-built_in">print</span>(a[<span class="hljs-number">1</span>:])<br><span class="hljs-built_in">print</span>(a[-<span class="hljs-number">4</span>:-<span class="hljs-number">1</span>])<br><span class="hljs-built_in">print</span>(a[-<span class="hljs-number">3</span>:])<br><span class="hljs-built_in">print</span>(a[:])<br><br><span class="hljs-comment">##    [1, 2, 3, 4, 99]</span><br><span class="hljs-comment">##    [1, 2]</span><br><span class="hljs-comment">##    [2, 3, 4, 99]</span><br><span class="hljs-comment">##    [2, 3, 4]</span><br><span class="hljs-comment">##    [3, 4, 99]</span><br><span class="hljs-comment">##    [1, 2, 3, 4, 99]</span><br></code></pre></td></tr></table></figure><h3 id="1-3-5-字典"><a href="#1-3-5-字典" class="headerlink" title="1.3.5 字典"></a>1.3.5 字典</h3><p>以<code>key-value</code>形式存储</p><p>访问时用中括号，下标使用<code>key</code>部分值</p><p>例如</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">me=&#123;<span class="hljs-string">&#x27;height&#x27;</span>:<span class="hljs-number">180</span>,<span class="hljs-number">2</span>:<span class="hljs-number">160</span>&#125;<br><span class="hljs-built_in">print</span>(me[<span class="hljs-string">&#x27;height&#x27;</span>])<br><span class="hljs-built_in">print</span>(me)<br><span class="hljs-built_in">print</span>(me[<span class="hljs-number">2</span>])<br><br><span class="hljs-comment">## output:</span><br><span class="hljs-comment">## 180</span><br><span class="hljs-comment">## &#123;&#x27;height&#x27;: 180, 2: 160&#125;</span><br><span class="hljs-comment">## 160</span><br></code></pre></td></tr></table></figure><p>这里的<code>2</code>就代表了<code>me</code>的关键词为<code>2</code>的项目，它的值是<code>160</code>。</p><div class="note note-warning">            <p>需要注意的是，如果使用不存在的键进行访问，会引发 KeyError 异常。为了避免这种情况，可以使用字典的 get() 方法，它允许提供默认值，当键不存在时返回该默认值。例如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">me = &#123;<span class="hljs-string">&quot;weight&quot;</span>: <span class="hljs-number">70</span>, <span class="hljs-string">&quot;height&quot;</span>: <span class="hljs-number">180</span>&#125;<br>age = me.get(<span class="hljs-string">&quot;age&quot;</span>, <span class="hljs-number">0</span>)<br><span class="hljs-built_in">print</span>(age)  <span class="hljs-comment"># 输出：0</span><br></code></pre></td></tr></table></figure><p>在上面的例子中，我们使用 get() 方法来获取键 “age” 对应的值，如果键不存在，则返回默认值 0。这样可以避免出现 KeyError 异常。</p><p>默认值若不指定，则为<code>None</code></p>          </div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><br>me=&#123;<span class="hljs-string">&#x27;height&#x27;</span>:<span class="hljs-number">180</span>,<span class="hljs-number">2</span>:<span class="hljs-number">160</span>&#125;<br><span class="hljs-built_in">print</span>(me[<span class="hljs-string">&#x27;height&#x27;</span>])<br><span class="hljs-built_in">print</span>(me)<br><span class="hljs-built_in">print</span>(me[<span class="hljs-number">2</span>])<br><span class="hljs-built_in">print</span>(me.get(<span class="hljs-string">&quot;age&quot;</span>))<br><span class="hljs-comment">##    180</span><br><span class="hljs-comment">##    &#123;&#x27;height&#x27;: 180, 2: 160&#125;</span><br><span class="hljs-comment">##    160</span><br><span class="hljs-comment">##    None</span><br><br></code></pre></td></tr></table></figure><h3 id="1-3-6-bool"><a href="#1-3-6-bool" class="headerlink" title="1.3.6 bool"></a>1.3.6 bool</h3><p>以下是很有意思的一段代码</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python">flag=<span class="hljs-literal">True</span><br>flag=<span class="hljs-keyword">not</span> flag<br><span class="hljs-built_in">print</span>(flag)<br>flag=~flag<br><span class="hljs-built_in">print</span>(flag)<br>flag=~flag<br><span class="hljs-built_in">print</span>(flag)<br><br></code></pre></td></tr></table></figure><p>代码中，首先定义了一个<code>bool</code>类型的flag。</p><ol><li><p>对其<code>取非输出</code>，输出是<code>False</code>，没毛病。</p></li><li><p>对其再进行<code>取反输出</code>，这时候输出是<code>-1</code></p></li><li><p>对其再进行<code>取反输出</code>，这时候输出是<code>0</code>,</p></li></ol><p>可见，对布尔类型只能使用<code>and</code>,<code>or</code>,<code>not</code>操作</p><p>使用<code>取反</code>操作会出现类型转换，使得<code>布尔类型</code>变成<code>整数类型</code>，从而输出<code>0000 0000</code>的<code>按位取反</code>结果，是<code>FFFF FFFF</code>,在补码中表示<code>-1</code>,与输出吻合。</p><p>再进行取反，结果就是<code>0000 0000</code>，输出是0。</p><p>同样，对<code>True</code>类型进行按位取反，表示对<code>0000 0001</code>按位取反，结果是<code>FFFF FFFE</code>，补码表示<code>-2</code>。对<code>True</code>进行<code>取反取反输出</code>，结果就是<code>0000 0001</code>,输出<code>整型</code>的<code>1</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><br>flag=<span class="hljs-literal">True</span><br>flag=<span class="hljs-keyword">not</span> flag<br><span class="hljs-built_in">print</span>(flag)<br><span class="hljs-built_in">print</span>(~flag)<br><span class="hljs-built_in">print</span>(~~flag)<br>flag2=<span class="hljs-literal">True</span><br><span class="hljs-built_in">print</span>(~flag2)<br><span class="hljs-built_in">print</span>(~~flag2)<br><br><span class="hljs-comment">##    False</span><br><span class="hljs-comment">##    -1</span><br><span class="hljs-comment">##    0</span><br><span class="hljs-comment">##    -2</span><br><span class="hljs-comment">##    1</span><br></code></pre></td></tr></table></figure><h3 id="1-3-8-for语句"><a href="#1-3-8-for语句" class="headerlink" title="1.3.8 for语句"></a>1.3.8 for语句</h3><p>记得后面有个冒号，循环体内要缩进</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> [<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>]:<br>    <span class="hljs-built_in">print</span>(i)<br>    <br><span class="hljs-comment">##    1</span><br><span class="hljs-comment">##    2</span><br><span class="hljs-comment">##    3</span><br></code></pre></td></tr></table></figure><h3 id="1-3-9-函数"><a href="#1-3-9-函数" class="headerlink" title="1.3.9 函数"></a>1.3.9 函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">hello</span>(<span class="hljs-params"><span class="hljs-built_in">object</span>=<span class="hljs-string">&quot;World&quot;</span></span>):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Hello &quot;</span>+<span class="hljs-built_in">object</span>+<span class="hljs-string">&quot; !&quot;</span>)<br>hello()<br>hello(<span class="hljs-string">&quot;CAT&quot;</span>)<br></code></pre></td></tr></table></figure><p>这里第一句使用了默认参数，输出<code>Hello World !</code></p><p>第二句传入参数，输出<code>Hello CAT !</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">hello</span>(<span class="hljs-params"><span class="hljs-built_in">object</span>=<span class="hljs-string">&quot;World&quot;</span></span>):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Hello &quot;</span>+<span class="hljs-built_in">object</span>+<span class="hljs-string">&quot; !&quot;</span>)<br>hello()<br>hello(<span class="hljs-string">&quot;CAT&quot;</span>)<br><br><span class="hljs-comment">##    Hello World !</span><br><span class="hljs-comment">##    Hello CAT !</span><br><br></code></pre></td></tr></table></figure><h3 id="1-4-2-Class类"><a href="#1-4-2-Class类" class="headerlink" title="1.4.2 Class类"></a>1.4.2 Class类</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">类名</span>：<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, 参数, …</span>): <span class="hljs-comment"># 构造函数</span><br>...<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">方法名1</span>(<span class="hljs-params">self, 参数, …</span>): <span class="hljs-comment"># 方法1</span><br>...<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">方法名2</span>(<span class="hljs-params">self, 参数, …</span>): <span class="hljs-comment"># 方法2</span><br>...<br><br></code></pre></td></tr></table></figure><ol><li>构造函数 <code>__init__(self,parameters...)</code></li></ol><p>   这个函数在构造类的时候执行一次，根据参数和构造函数来 赋初值</p><ol start="2"><li>方法s： 可以给类里面不同的<code>方法</code>定义不同的功能。类似于类里面的函数。注意第一个参数必须是<code>显式的self</code></li></ol><p>   在 Python 类的方法中，self 是一个特殊的参数，用于引用当前对象实例。它是约定俗成的命名，但实际上可以使用任何名称。如果在类的方法中不指定 self 参数，会导致以下问题：</p><p>    1. 访问不到对象的属性和方法：在类的方法中，如果没有指定 self 参数，将无法访问到对象的属性和其他方法。这是因为没有指定 self 参数，无法确定当前对象实例的引用。</p><p>    2. 无法修改对象的属性：没有 self 参数，无法通过引用对象实例来修改对象的属性。对象的属性只能通过类方法或实例方法中的 self 参数进行修改。</p><p>    3. 无法调用其他方法：在类的方法中，如果没有指定 self 参数，无法调用其他方法。因为没有指定 self 参数，无法确定调用哪个对象实例的方法。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Man</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, name</span>):<br>        self.name = name<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Initialized!&quot;</span>)<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">hello</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Hello &quot;</span> + self.name + <span class="hljs-string">&quot;!&quot;</span>)<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">goodbye</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Good-bye &quot;</span> + self.name + <span class="hljs-string">&quot;!&quot;</span>)<br>m = Man(<span class="hljs-string">&quot;David&quot;</span>)<br>m.hello()<br>m.goodbye()<br><span class="hljs-comment">##    Initialized!</span><br><span class="hljs-comment">##    Hello David!</span><br><span class="hljs-comment">##    Good-bye David!</span><br></code></pre></td></tr></table></figure><h2 id="1-5-Numpy"><a href="#1-5-Numpy" class="headerlink" title="1.5 Numpy"></a>1.5 Numpy</h2><h3 id="1-5-2-NumPy数组"><a href="#1-5-2-NumPy数组" class="headerlink" title="1.5.2 NumPy数组"></a>1.5.2 NumPy数组</h3><p>使用<code>numpy.array(...)</code>创建NP数组，</p><p>创建出来的数组类型是<code>numpy.ndarray</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br>x=np.array([<span class="hljs-number">1.0</span>,<span class="hljs-number">2.0</span>,<span class="hljs-number">3.0</span>])<br><span class="hljs-built_in">print</span>(x)<br><span class="hljs-built_in">type</span>(x)<br><br><span class="hljs-comment">##    [1. 2. 3.]</span><br><span class="hljs-comment">##    numpy.ndarray</span><br></code></pre></td></tr></table></figure><h3 id="1-5-3-NumPy-element-wise"><a href="#1-5-3-NumPy-element-wise" class="headerlink" title="1.5.3 NumPy element-wise"></a>1.5.3 NumPy element-wise</h3><p>前提：X和Y的<strong>维数</strong>必须一致，才可进行算术运算。</p><p><code>element-wise</code>是按<code>元素</code>进行操作，即<code>X的某一元素</code>与<code>Y的对应元素</code>进行<code>算术运算</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python">x=np.array([<span class="hljs-number">1.0</span>,<span class="hljs-number">2.0</span>,<span class="hljs-number">3.0</span>])<br>y=np.array([<span class="hljs-number">2.0</span>,<span class="hljs-number">4.0</span>,<span class="hljs-number">6.0</span>])<br><br><span class="hljs-built_in">print</span>(x+y)<br><span class="hljs-built_in">print</span>(x*y)<br><span class="hljs-built_in">print</span>(x/y)<br><br><span class="hljs-comment">##    [3. 6. 9.]</span><br><span class="hljs-comment">##    [ 2.  8. 18.]</span><br><span class="hljs-comment">##    [0.5 0.5 0.5]</span><br></code></pre></td></tr></table></figure><h3 id="1-5-4-NumPy的N维数组"><a href="#1-5-4-NumPy的N维数组" class="headerlink" title="1.5.4 NumPy的N维数组"></a>1.5.4 NumPy的N维数组</h3><p>注意，多维数组是对某一元素进行扩展。即首先是个Array，最外层应该由中括号包起来，然后内层根据需要扩展维数。</p><p>用<code>A.shape</code>即A的<code>shape元组</code>来查看维数，</p><p><code>A.dtype</code>即A的<code>numpy.dtype[int32]</code><sup id="fnref:1" class="footnote-ref"><a href="#fn:1" rel="footnote"><span class="hint--top hint--rounded" aria-label="`numpy.dtype[int32]` 是 NumPy 库中的数据类型对象，表示一个具体的数据类型。在这种情况下，int32 表示一个 32 位整数的数据类型。">[1]</span></a></sup>来查看数据类型</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><br>A=np.array([ [<span class="hljs-number">1</span>,<span class="hljs-number">2</span>],<br>             [<span class="hljs-number">3</span>,<span class="hljs-number">4</span>],<br>             [<span class="hljs-number">5</span>,<span class="hljs-number">6</span>]])<br><span class="hljs-built_in">print</span>(A)<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">type</span>(A.shape))<br><span class="hljs-built_in">print</span>(A.shape)<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">type</span>(A.dtype))<br><span class="hljs-built_in">print</span>(A.dtype)<br><br><span class="hljs-comment">##    [[1 2]</span><br><span class="hljs-comment">##     [3 4]</span><br><span class="hljs-comment">##     [5 6]]</span><br><span class="hljs-comment">##    &lt;class &#x27;tuple&#x27;&gt;</span><br><span class="hljs-comment">##    (3, 2)</span><br><span class="hljs-comment">##    &lt;class &#x27;numpy.dtype[int32]&#x27;&gt;</span><br><span class="hljs-comment">##    int32</span><br></code></pre></td></tr></table></figure><p>对于多维数组，也可进行<code>element-wise</code>运算。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python">A=np.array([ [<span class="hljs-number">1</span>,<span class="hljs-number">2</span>],<br>             [<span class="hljs-number">3</span>,<span class="hljs-number">4</span>],<br>             [<span class="hljs-number">5</span>,<span class="hljs-number">6</span>]])<br>B=np.array([ [<span class="hljs-number">1</span>,<span class="hljs-number">2</span>],<br>            [<span class="hljs-number">3</span>,<span class="hljs-number">4</span>],<br>            [<span class="hljs-number">5</span>,<span class="hljs-number">6</span>]])<br><span class="hljs-built_in">print</span>(A+B)<br><span class="hljs-built_in">print</span>(A*B)<br><br><span class="hljs-comment">##    [[ 2  4]</span><br><span class="hljs-comment">##     [ 6  8]</span><br><span class="hljs-comment">##     [10 12]]</span><br><span class="hljs-comment">##    [[ 1  4]</span><br><span class="hljs-comment">##     [ 9 16]</span><br><span class="hljs-comment">##     [25 36]]</span><br></code></pre></td></tr></table></figure><h3 id="1-5-5-广播"><a href="#1-5-5-广播" class="headerlink" title="1.5.5 广播"></a>1.5.5 广播</h3><p>即将标量通过扩展，形成<code>和向量同维度的，所有元素均为标量值的</code>向量，然后对这两个向量进行<code>element-wise</code>算术运算。</p><p>注意，一般是中括号内部对齐。即<code>A的中括号内第一个元素</code>，与<code>B的中括号第一个元素</code>进行广播相乘。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><br>A=np.array([ [<span class="hljs-number">1</span>,<span class="hljs-number">2</span>],<br>             [<span class="hljs-number">3</span>,<span class="hljs-number">4</span>],<br>             [<span class="hljs-number">5</span>,<span class="hljs-number">6</span>]])<br>B=np.array([ <span class="hljs-number">10</span>,<span class="hljs-number">20</span>])<br><span class="hljs-built_in">print</span>(A*B)<br><span class="hljs-comment">##    [[ 10  40]</span><br><span class="hljs-comment">##     [ 30  80]</span><br><span class="hljs-comment">##     [ 50 120]]</span><br></code></pre></td></tr></table></figure><h3 id="1-5-6-访问元素"><a href="#1-5-6-访问元素" class="headerlink" title="1.5.6 访问元素"></a>1.5.6 访问元素</h3><p><code>A=np.array([ [1,2],[3,4],[5,6]])</code></p><ol><li>按照中括号内进行索引，从0开始编号。</li></ol><p>   <code>A[0]</code>  <code>A[0][3]</code></p><ol start="2"><li>使用<code>for语句</code></li></ol><p>    <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><br>    <span class="hljs-keyword">for</span> row <span class="hljs-keyword">in</span> A:<br>        <span class="hljs-built_in">print</span>(row)<br><br>    <span class="hljs-comment">## [1 2]</span><br>    <span class="hljs-comment">## [3 4]</span><br>    <span class="hljs-comment">## [5 6]</span><br><br></code></pre></td></tr></table></figure></p><ol start="3"><li>使用数组法</li></ol><p>   <code>print(A[0,1])</code></p><p>   <code>## 2</code></p><p>由访问元素，可以批量进行某些运算。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><br>A&gt;<span class="hljs-number">4</span><br><br><span class="hljs-comment">## [[False False]</span><br><span class="hljs-comment">## [False False]</span><br><span class="hljs-comment">## [ True  True]]</span><br><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><br>A=np.array([ [<span class="hljs-number">1</span>,<span class="hljs-number">2</span>],<br>             [<span class="hljs-number">3</span>,<span class="hljs-number">4</span>],<br>             [<span class="hljs-number">5</span>,<span class="hljs-number">6</span>]])<br><span class="hljs-built_in">print</span>(A[<span class="hljs-number">0</span>])<br><span class="hljs-built_in">print</span>((A))<br><span class="hljs-keyword">for</span> row <span class="hljs-keyword">in</span> A:<br>    <span class="hljs-built_in">print</span>(row)<br><span class="hljs-built_in">print</span>(A[<span class="hljs-number">0</span>,<span class="hljs-number">1</span>])<br><span class="hljs-built_in">print</span>(A&gt;<span class="hljs-number">4</span>)<br><br><span class="hljs-comment">##    [1 2]</span><br><span class="hljs-comment">##    [[1 2]</span><br><span class="hljs-comment">##     [3 4]</span><br><span class="hljs-comment">##     [5 6]]</span><br><span class="hljs-comment">##    [1 2]</span><br><span class="hljs-comment">##    [3 4]</span><br><span class="hljs-comment">##    [5 6]</span><br><span class="hljs-comment">##    2</span><br><span class="hljs-comment">##    [[False False]</span><br><span class="hljs-comment">##     [False False]</span><br><span class="hljs-comment">##     [ True  True]]</span><br></code></pre></td></tr></table></figure><h2 id="1-6-Matplotlib-图像绘制"><a href="#1-6-Matplotlib-图像绘制" class="headerlink" title="1.6 Matplotlib 图像绘制"></a>1.6 Matplotlib 图像绘制</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br>x=np.arange(<span class="hljs-number">0</span>,<span class="hljs-number">6</span>,<span class="hljs-number">0.1</span>)<br>y1=np.sin(x)<br>y2=np.cos(x)<br>plt.plot(x,y1,label=<span class="hljs-string">&quot;sin&quot;</span>)<br>plt.plot(x,y2,linestyle=<span class="hljs-string">&quot;--&quot;</span>,label=<span class="hljs-string">&quot;cos&quot;</span>)<br><br>plt.xlabel(<span class="hljs-string">&quot;x&quot;</span>)<br>plt.ylabel(<span class="hljs-string">&quot;Y&quot;</span>)<br>plt.title(<span class="hljs-string">&#x27;sin&amp;cos&#x27;</span>)<br>plt.legend()        <span class="hljs-comment">#添加图例</span><br><br>plt.show()<br><br></code></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/Destiny-End/images/master/202312302104352.png" alt="sin&amp;cos"></p><h3 id="1-6-3-显示图像"><a href="#1-6-3-显示图像" class="headerlink" title="1.6.3 显示图像"></a>1.6.3 显示图像</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">from</span> matplotlib.image <span class="hljs-keyword">import</span> imread<br>img = imread(<span class="hljs-string">&#x27;titanic.jpg&#x27;</span>)<br>plt.imshow(img)<br>plt.show()<br></code></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/Destiny-End/images/master/202312302104454.png" alt="image"></p><section class="footnotes"><div class="footnote-list"><ol><li><span id="fn:1" class="footnote-text"><span><code>numpy.dtype[int32]</code> 是 NumPy 库中的数据类型对象，表示一个具体的数据类型。在这种情况下，int32 表示一个 32 位整数的数据类型。<a href="#fnref:1" rev="footnote" class="footnote-backref"> ↩</a></span></span></li></ol></div></section>]]></content>
    
    
    <categories>
      
      <category>DL</category>
      
    </categories>
    
    
    <tags>
      
      <tag>python</tag>
      
      <tag>DL</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>打造背单词工具 Goldendict+Anki</title>
    <link href="/post/20231229174800.html"/>
    <url>/post/20231229174800.html</url>
    
    <content type="html"><![CDATA[<p>最近发现本地词典工具<code>Goldendict</code>挺好使，还发现它可以连接<code>Anki</code>。下文就记录如何连接Goldendict和anki。</p><h2 id="1-根据文档，完成基本配置"><a href="#1-根据文档，完成基本配置" class="headerlink" title="1. 根据文档，完成基本配置"></a>1. 根据文档，完成基本配置</h2><p>文档地址：<code>https://xiaoyifang.github.io/goldendict-ng/topic_anki/</code></p><h2 id="2-DEBUG篇"><a href="#2-DEBUG篇" class="headerlink" title="2. DEBUG篇"></a>2. DEBUG篇</h2><p>文档配置完总会有各种问题。Debug主要有两个点</p><h3 id="1）GoldenDict的消息框"><a href="#1）GoldenDict的消息框" class="headerlink" title="1）GoldenDict的消息框"></a>1）GoldenDict的消息框</h3><p><img src="https://raw.githubusercontent.com/Destiny-End/images/master/202312301247226.png" alt="GoldenDict消息框"></p><p>在<code>Goldendict界面</code>的左下角就有提示。</p><h3 id="2）AnkiConnect的log记录"><a href="#2）AnkiConnect的log记录" class="headerlink" title="2）AnkiConnect的log记录"></a>2）AnkiConnect的log记录</h3><p>Goldendict和Anki是通过<code>ankiweb</code>这个插件进行通信的。<br><code>Ctrl+Shift+A</code>打开插件界面，在<br><img src="https://raw.githubusercontent.com/Destiny-End/images/master/202312301248580.png" alt="Anki插件设置"></p><p>右下角，有个插件设置。里面就是配置文件。我的配置如下</p><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs prolog">&#123;<br><br><span class="hljs-string">&quot;apiKey&quot;</span>: null,<br><br><span class="hljs-string">&quot;apiLogPath&quot;</span>: <span class="hljs-string">&quot;G://@GoldenDict//AnkiLog//log.txt&quot;</span>,<br><br><span class="hljs-string">&quot;ignoreOriginList&quot;</span>: [],<br><br><span class="hljs-string">&quot;webBindAddress&quot;</span>: <span class="hljs-string">&quot;127.0.0.1&quot;</span>,<br><br><span class="hljs-string">&quot;webBindPort&quot;</span>: <span class="hljs-number">10110</span>,<br><br><span class="hljs-string">&quot;webCorsOriginList&quot;</span>: [<br><br><span class="hljs-string">&quot;http://localhost&quot;</span><br><br>]<br><br>&#125;<br></code></pre></td></tr></table></figure><p>其中的<code>apiLogPath</code>就是日志目录。比如我尝试发送到anki两次：</p><figure class="highlight wren"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><code class="hljs wren">[<span class="hljs-variable">request</span>]<br>&#123;<br>    <span class="hljs-string">&quot;action&quot;</span>: <span class="hljs-string">&quot;addNote&quot;</span>,<br>    <span class="hljs-string">&quot;params&quot;</span>: &#123;<br>        <span class="hljs-string">&quot;note&quot;</span>: &#123;<br>            <span class="hljs-string">&quot;deckName&quot;</span>: <span class="hljs-string">&quot;English&quot;</span>,<br>            <span class="hljs-string">&quot;fields&quot;</span>: &#123;<br>                <span class="hljs-string">&quot;back&quot;</span>: <span class="hljs-string">&quot;god /<span class="hljs-char escape_">\u0261</span><span class="hljs-char escape_">\u0252</span>d $ <span class="hljs-char escape_">\u0261</span><span class="hljs-char escape_">\u0251</span>\u02d0d/ \u25cf\u25cf\u25cf S1 W1 noun  <span class="hljs-char escape_">\r</span>&lt;br&gt;N1. <span class="hljs-char escape_">\u2192</span> God<span class="hljs-char escape_">\r</span>&lt;br&gt;2<span class="hljs-char escape_">\u2003</span> COUNTABLE a male spirit or being who is believed by some religions to control the world or part of it, or who represents a particular quality <span class="hljs-char escape_">\u2192</span> goddess<span class="hljs-char escape_">\r</span>&lt;br&gt;god of<span class="hljs-char escape_">\r</span>&lt;br&gt; Mars, the god of war<span class="hljs-char escape_">\r</span>&lt;br&gt;<span class="hljs-char escape_">\u6218</span>\u795e\u739b\u5c14\u65af<span class="hljs-char escape_">\r</span>&lt;br&gt;Roman/Greek etc god<span class="hljs-char escape_">\r</span>&lt;br&gt; Zeus was one of the most well-known Greek gods.<span class="hljs-char escape_">\r</span>&lt;br&gt;3<span class="hljs-char escape_">\u2003</span> God<span class="hljs-char escape_">\u2019</span>s gift to somebody/somethingATTRACTsomeone who thinks they are perfect or extremely attractive <span class="hljs-char escape_">\u2013</span> used to show disapproval<span class="hljs-char escape_">\r</span>&lt;br&gt; Paul thinks he<span class="hljs-char escape_">\u2019</span>s God<span class="hljs-char escape_">\u2019</span>s gift to women.<span class="hljs-char escape_">\r</span>&lt;br&gt;4<span class="hljs-char escape_">\u2003</span> COUNTABLE someone who is admired very much<span class="hljs-char escape_">\r</span>&lt;br&gt; To his fans he is a god.&quot;</span>,<br>                <span class="hljs-string">&quot;front&quot;</span>: <span class="hljs-string">&quot;god&quot;</span>,<br>                <span class="hljs-string">&quot;sentence&quot;</span>: <span class="hljs-string">&quot;&lt;b&gt;god&lt;/b&gt;en&quot;</span><br>            &#125;,<br>            <span class="hljs-string">&quot;modelName&quot;</span>: <span class="hljs-string">&quot;word&quot;</span>,<br>            <span class="hljs-string">&quot;options&quot;</span>: &#123;<br>                <span class="hljs-string">&quot;allowDuplicate&quot;</span>: <span class="hljs-literal">true</span><br>            &#125;,<br>            <span class="hljs-string">&quot;tags&quot;</span>: []<br>        &#125;<br>    &#125;,<br>    <span class="hljs-string">&quot;version&quot;</span>: <span class="hljs-number">6</span><br>&#125;<br><br>[<span class="hljs-variable">reply</span>]<br>&#123;<br>    <span class="hljs-string">&quot;error&quot;</span>: <span class="hljs-string">&quot;deck was not found: English&quot;</span>,<br>    <span class="hljs-string">&quot;result&quot;</span>: <span class="hljs-literal">null</span><br>&#125;<br><br>[<span class="hljs-variable">request</span>]<br>&#123;<br>    <span class="hljs-string">&quot;action&quot;</span>: <span class="hljs-string">&quot;addNote&quot;</span>,<br>    <span class="hljs-string">&quot;params&quot;</span>: &#123;<br>        <span class="hljs-string">&quot;note&quot;</span>: &#123;<br>            <span class="hljs-string">&quot;deckName&quot;</span>: <span class="hljs-string">&quot;English&quot;</span>,<br>            <span class="hljs-string">&quot;fields&quot;</span>: &#123;<br>                <span class="hljs-string">&quot;back&quot;</span>: <span class="hljs-string">&quot;god /<span class="hljs-char escape_">\u0261</span><span class="hljs-char escape_">\u0252</span>d $ <span class="hljs-char escape_">\u0261</span><span class="hljs-char escape_">\u0251</span>\u02d0d/ \u25cf\u25cf\u25cf S1 W1 noun  <span class="hljs-char escape_">\r</span>&lt;br&gt;N1. <span class="hljs-char escape_">\u2192</span> God<span class="hljs-char escape_">\r</span>&lt;br&gt;2<span class="hljs-char escape_">\u2003</span> COUNTABLE a male spirit or being who is believed by some religions to control the world or part of it, or who represents a particular quality <span class="hljs-char escape_">\u2192</span> goddess<span class="hljs-char escape_">\r</span>&lt;br&gt;god of<span class="hljs-char escape_">\r</span>&lt;br&gt; Mars, the god of war<span class="hljs-char escape_">\r</span>&lt;br&gt;<span class="hljs-char escape_">\u6218</span>\u795e\u739b\u5c14\u65af<span class="hljs-char escape_">\r</span>&lt;br&gt;Roman/Greek etc god<span class="hljs-char escape_">\r</span>&lt;br&gt; Zeus was one of the most well-known Greek gods.<span class="hljs-char escape_">\r</span>&lt;br&gt;3<span class="hljs-char escape_">\u2003</span> God<span class="hljs-char escape_">\u2019</span>s gift to somebody/somethingATTRACTsomeone who thinks they are perfect or extremely attractive <span class="hljs-char escape_">\u2013</span> used to show disapproval<span class="hljs-char escape_">\r</span>&lt;br&gt; Paul thinks he<span class="hljs-char escape_">\u2019</span>s God<span class="hljs-char escape_">\u2019</span>s gift to women.<span class="hljs-char escape_">\r</span>&lt;br&gt;4<span class="hljs-char escape_">\u2003</span> COUNTABLE someone who is admired very much<span class="hljs-char escape_">\r</span>&lt;br&gt; To his fans he is a god.&quot;</span>,<br>                <span class="hljs-string">&quot;front&quot;</span>: <span class="hljs-string">&quot;god&quot;</span>,<br>                <span class="hljs-string">&quot;sentence&quot;</span>: <span class="hljs-string">&quot;&lt;b&gt;god&lt;/b&gt;en&quot;</span><br>            &#125;,<br>            <span class="hljs-string">&quot;modelName&quot;</span>: <span class="hljs-string">&quot;word&quot;</span>,<br>            <span class="hljs-string">&quot;options&quot;</span>: &#123;<br>                <span class="hljs-string">&quot;allowDuplicate&quot;</span>: <span class="hljs-literal">true</span><br>            &#125;,<br>            <span class="hljs-string">&quot;tags&quot;</span>: []<br>        &#125;<br>    &#125;,<br>    <span class="hljs-string">&quot;version&quot;</span>: <span class="hljs-number">6</span><br>&#125;<br><br>[<span class="hljs-variable">reply</span>]<br>&#123;<br>    <span class="hljs-string">&quot;error&quot;</span>: <span class="hljs-literal">null</span>,<br>    <span class="hljs-string">&quot;result&quot;</span>: <span class="hljs-number">1703842707231</span><br>&#125;<br></code></pre></td></tr></table></figure><p>可以看到第一次<code>reply</code>提示<code>deck未创建</code>，创建<code>deck</code>后，就不会报错了。<code>anki</code>里也正常显示。</p>]]></content>
    
    
    <categories>
      
      <category>Anki</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Anki</tag>
      
      <tag>Goldendict</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Docker配置qBittorrent</title>
    <link href="/post/20231204031100.html"/>
    <url>/post/20231204031100.html</url>
    
    <content type="html"><![CDATA[<p>本来不打算写这个的，以为一行命令就能搞定。没想到啊，失算了。</p><h2 id="拉镜像"><a href="#拉镜像" class="headerlink" title="拉镜像"></a>拉镜像</h2><figure class="highlight docker"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs docker">docker pull linux:qbittorrent:latest<br></code></pre></td></tr></table></figure><p>就是这个latest，新版把默认密码改了，害我查半天。</p><h2 id="编compose文件"><a href="#编compose文件" class="headerlink" title="编compose文件"></a>编compose文件</h2><p>我习惯用<code>compose</code>文件来起服务，这样不至于下次看<code>docker</code>的时候忘了之前咋映射的。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">version:</span> <span class="hljs-string">&quot;3.5&quot;</span><br><span class="hljs-attr">services:</span><br>  <span class="hljs-attr">qbittorrent:</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">linuxserver/qbittorrent</span><br>    <span class="hljs-attr">container_name:</span> <span class="hljs-string">qbittorrent</span><br>    <span class="hljs-attr">environment:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">PUID=1000</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">PGID=1000</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">TZ=Asia/Shanghai</span> <span class="hljs-comment"># 你的时区</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">UMASK_SET=022</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">WEBUI_PORT=9999</span> <span class="hljs-comment"># 将此处修改成你欲使用的 WEB 管理平台端口</span><br>    <span class="hljs-attr">volumes:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">./config:/config</span> <span class="hljs-comment"># 绝对路径请修改为自己的config文件夹</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">/home/share:/downloads</span> <span class="hljs-comment"># 绝对路径请修改为自己的downloads文件夹</span><br>    <span class="hljs-attr">ports:</span><br>      <span class="hljs-comment"># 要使用的映射下载端口与内部下载端口，可保持默认，安装完成后在管理页面仍然可以改成其他端口。</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-number">6881</span><span class="hljs-string">:6881</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-number">6881</span><span class="hljs-string">:6881/udp</span><br>      <span class="hljs-comment"># 此处WEB UI 目标端口与内部端口务必保证相同，见问题[^1]</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-number">9999</span><span class="hljs-string">:9999</span><br>    <span class="hljs-attr">restart:</span> <span class="hljs-string">unless-stopped</span><br></code></pre></td></tr></table></figure><p>[^1] 这里的端口，右边代表的是容器内部的端口，所以需要和上面<code>- WEBUI_PORT=9999</code>保持一致。左边代表映射到<code>host</code>上的端口，目标就是<code>9999</code>，所以三个设成一样的就行。</p><h2 id="起服务"><a href="#起服务" class="headerlink" title="起服务"></a>起服务</h2><p>有人可能就疑惑了。这不一行的事吗？还要设一个小节？hhh，我也是这么想的。</p><figure class="highlight docker"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs docker">docker compose up -d<br></code></pre></td></tr></table></figure><p>没错，我就是这么起的。然后查了一堆密码，无数次翻看<code>docker compose</code>文件。<br>没有啊？我没设置密码啊。</p><div class="note note-warning">            <p>这里不能用<code>-d</code>选项，因为<strong>新版改了</strong>，默认密码不是<code>adminadmin</code>，而是随机生成的。</p>          </div><p>使用<code>docker compose up</code>命令，可以看到输出信息。如下</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><code class="hljs log">docker compose up   <br>[+] Building 0.0s (0/0)                                             docker:default<br>[+] Running 2/2<br> ✔ Network qbittorrent_default  Created                                       0.1s <br> ✔ Container qbittorrent        Created                                       0.1s <br>Attaching to qbittorrent<br>qbittorrent  | [migrations] started<br>qbittorrent  | [migrations] no migrations found<br>qbittorrent  | ───────────────────────────────────────<br>qbittorrent  | <br>qbittorrent  |       ██╗     ███████╗██╗ ██████╗ <br>qbittorrent  |       ██║     ██╔════╝██║██╔═══██╗<br>qbittorrent  |       ██║     ███████╗██║██║   ██║<br>qbittorrent  |       ██║     ╚════██║██║██║   ██║<br>qbittorrent  |       ███████╗███████║██║╚██████╔╝<br>qbittorrent  |       ╚══════╝╚══════╝╚═╝ ╚═════╝ <br>qbittorrent  | <br>qbittorrent  |    Brought to you by linuxserver.io<br>qbittorrent  | ───────────────────────────────────────<br>qbittorrent  | <br>qbittorrent  | To support LSIO projects visit:<br>qbittorrent  | https://www.linuxserver.io/donate/<br>qbittorrent  | <br>qbittorrent  | ───────────────────────────────────────<br>qbittorrent  | GID/UID<br>qbittorrent  | ───────────────────────────────────────<br>qbittorrent  | <br>qbittorrent  | User UID:    1000<br>qbittorrent  | User GID:    1000<br>qbittorrent  | ───────────────────────────────────────<br>qbittorrent  | <br>qbittorrent  | [custom-init] No custom files found, skipping...<br>qbittorrent  | WebUI will be started shortly after internal preparations. Please wait...<br>qbittorrent  | <br>qbittorrent  | ******** Information ********<br>qbittorrent  | To control qBittorrent, access the WebUI at: http://localhost:9999<br>qbittorrent  | <br>qbittorrent  | The WebUI administrator username is: admin<br>qbittorrent  | The WebUI administrator password was not set. A temporary password is provided for this session: t3G53FAC6<br>qbittorrent  | You should set your own password in program preferences.<br>qbittorrent  | Connection to localhost (127.0.0.1) 9999 port [tcp/*] succeeded!<br>qbittorrent  | [ls.io-init] done.<br></code></pre></td></tr></table></figure><p>诺，上面的<code>A temporary password is provided for this session:</code> <strong>t3G53FAC6</strong>就是临时密码。这要是查论坛，查明天也破不了案。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>没事干多看看<code>log</code>，有事了先看<code>log</code>，懵逼了先翻<code>log</code></p><div class="note note-primary">            <p>log log log log log</p>          </div><p>（这是我惩罚我自己的)<br>哦，以后码代码的时候也要记得<code>log</code>。关键位置及时记录，有迹可循。</p>]]></content>
    
    
    <categories>
      
      <category>Docker</category>
      
      <category>qBittorent</category>
      
    </categories>
    
    
    <tags>
      
      <tag>linux</tag>
      
      <tag>Docker</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Fluid部分配置</title>
    <link href="/post/20231203162600.html"/>
    <url>/post/20231203162600.html</url>
    
    <content type="html"><![CDATA[<h2 id="色块配置-1"><a href="#色块配置-1" class="headerlink" title="色块配置[1]"></a>色块配置<sup id="fnref:1" class="footnote-ref"><a href="#fn:1" rel="footnote"><span class="hint--top hint--rounded" aria-label="Fluid用户手册——https://fluid-dev.github.io/hexo-fluid-docs/guide/">[1]</span></a></sup></h2><p>一行代码搞定</p><figure class="highlight django"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs django"><span class="hljs-template-tag">&#123;% <span class="hljs-name">note</span> primary %&#125;</span><span class="language-xml"></span><br><span class="language-xml">...内容</span><br><span class="language-xml"></span><span class="hljs-template-tag">&#123;% <span class="hljs-name">endnote</span> %&#125;</span><br></code></pre></td></tr></table></figure><h3 id="效果"><a href="#效果" class="headerlink" title="效果"></a>效果</h3><div class="note note-primary">            <p>…内容</p>          </div><h3 id="可选标签"><a href="#可选标签" class="headerlink" title="可选标签"></a>可选标签</h3><p><img src="https://raw.githubusercontent.com/Destiny-End/images/master/202312301252515.png" alt="标签"></p><h2 id="参考配置-1"><a href="#参考配置-1" class="headerlink" title="参考配置[1]"></a>参考配置<sup id="fnref:1" class="footnote-ref"><a href="#fn:1" rel="footnote"><span class="hint--top hint--rounded" aria-label="Fluid用户手册——https://fluid-dev.github.io/hexo-fluid-docs/guide/">[1]</span></a></sup></h2><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs markdown">正文<br>这是一句话[^1]<br><span class="hljs-section">## 参考</span><br>[<span class="hljs-symbol">^1</span>]: <span class="hljs-link">参考资料1</span><br>[<span class="hljs-symbol">^2</span>]: <span class="hljs-link">参考资料2</span><br></code></pre></td></tr></table></figure><h3 id="效果-1"><a href="#效果-1" class="headerlink" title="效果"></a>效果</h3><section class="footnotes"><div class="footnote-list"><ol><li><span id="fn:1" class="footnote-text"><span>Fluid用户手册——<a href="https://fluid-dev.github.io/hexo-fluid-docs/guide/">https://fluid-dev.github.io/hexo-fluid-docs/guide/</a><a href="#fnref:1" rev="footnote" class="footnote-backref"> ↩</a></span></span></li></ol></div></section>]]></content>
    
    
    <categories>
      
      <category>linux运维</category>
      
      <category>环境配置</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Hexo</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NextCloud装错app卡死</title>
    <link href="/post/20231203154500.html"/>
    <url>/post/20231203154500.html</url>
    
    <content type="html"><![CDATA[<h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><p>我这里挂了个外部存储，但是外部存储内容有点多，导致Nextcloud不停建立索引，网页都无响应。<br>没法进网页就没法从网页端关闭这个东西。只能考虑命令行。</p><h2 id="命令"><a href="#命令" class="headerlink" title="命令"></a>命令</h2><p>事先要求: 你一定要知道是哪个应用导致你卡死的, 例如<code>richdocumentsXXXXX</code>。进入<code>docker</code>后, 首先要看看应用叫啥名字? 命令如下：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">sudo -u www-data php occ app:list<br></code></pre></td></tr></table></figure><p>然后禁用这个<code>app/插件</code> </p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">sudo -u www-data php occ app:<span class="hljs-built_in">disable</span> &lt;出了问题的应用&gt;<br></code></pre></td></tr></table></figure><p>比如我这里</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><code class="hljs sh">$ docker <span class="hljs-built_in">exec</span> -it 01fb /bin/bash                                                                       [15:32:49]<br>01fb977d257d:/var/www/html<span class="hljs-comment"># sudo -u www-data php occ app:list</span><br><br>Warning: Failed to <span class="hljs-built_in">set</span> memory <span class="hljs-built_in">limit</span> to 0 bytes (Current memory usage is 2097152 bytes) <span class="hljs-keyword">in</span> Unknown on line 0<br>The current PHP memory <span class="hljs-built_in">limit</span> is below the recommended value of 512MB.<br>Enabled:<br>  - activity: 2.19.0<br>  - admin_audit: 1.17.0<br>  - bruteforcesettings: 2.7.0<br>  - circles: 27.0.1<br>  - cloud_federation_api: 1.10.0<br>  - comments: 1.17.0<br>  - contactsinteraction: 1.8.0<br>  - dashboard: 7.7.0<br>  - dav: 1.27.0<br>  - federatedfilesharing: 1.17.0<br>  - federation: 1.17.0<br>  - files: 1.22.0<br>  - files_external: 1.19.0<br>  - files_pdfviewer: 2.8.0<br>  - files_reminders: 1.0.0<br>  - files_rightclick: 1.6.0<br>  - files_sharing: 1.19.0<br>  - files_trashbin: 1.17.0<br>  - files_versions: 1.20.0<br>  - firstrunwizard: 2.16.0<br>  - logreader: 2.12.0<br>  - lookup_server_connector: 1.15.0<br>  - nextcloud-aio: 0.4.0<br>  - nextcloud_announcements: 1.16.0<br>  - notifications: 2.15.0<br>  - notify_push: 0.6.5<br>  - oauth2: 1.15.1<br>  - password_policy: 1.17.0<br>  - photos: 2.3.0<br>  - privacy: 1.11.0<br>  - provisioning_api: 1.17.0<br>  - recommendations: 1.6.0<br>  - related_resources: 1.2.0<br>  - richdocuments: 8.2.3<br>  - serverinfo: 1.17.0<br>  - settings: 1.9.0<br>  - sharebymail: 1.17.0<br>  - spreed: 17.1.3<br>  - support: 1.10.0<br>  - survey_client: 1.15.0<br>  - systemtags: 1.17.0<br>  - text: 3.8.0<br>  - theming: 2.2.0<br>  - twofactor_backupcodes: 1.16.0<br>  - user_status: 1.7.0<br>  - viewer: 2.1.0<br>  - weather_status: 1.7.0<br>  - workflowengine: 2.9.0<br>Disabled:<br>  - encryption: 2.15.0<br>  - suspicious_login: 5.0.0<br>  - twofactor_totp: 9.0.0<br>  - user_ldap: 1.17.0<br>01fb977d257d:/var/www/html<span class="hljs-comment"># sudo -u www-data php occ app:list | grep external</span><br>The current PHP memory <span class="hljs-built_in">limit</span> is below the recommended value of 512MB.<br>  - files_external: 1.19.0<br>01fb977d257d:/var/www/html<span class="hljs-comment"># sudo -u www-data php occ app:disable files_external</span><br><br>Warning: Failed to <span class="hljs-built_in">set</span> memory <span class="hljs-built_in">limit</span> to 0 bytes (Current memory usage is 2097152 bytes) <span class="hljs-keyword">in</span> Unknown on line 0<br>The current PHP memory <span class="hljs-built_in">limit</span> is below the recommended value of 512MB.<br>files_external 1.19.0 disabled<br></code></pre></td></tr></table></figure><p>关闭<code>files_external</code>解决问题。</p>]]></content>
    
    
    <categories>
      
      <category>linux运维</category>
      
      <category>未分类</category>
      
    </categories>
    
    
    <tags>
      
      <tag>linux</tag>
      
      <tag>NextCloud</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>DHCP服务器重新配置</title>
    <link href="/post/20231203002600.html"/>
    <url>/post/20231203002600.html</url>
    
    <content type="html"><![CDATA[<h2 id="理论分析"><a href="#理论分析" class="headerlink" title="理论分析"></a>理论分析</h2><p>因为家里的服务器是ipv6的链接，但我这个<code>Android</code>手机，刷的新系统却没有v6。这就比较尴尬了，域名直接访问不到局域网的主机。不过问题不大，可以通过<code>DNS劫持</code>，直接劫持到请求，解析到局域网的主机即可。但每次还得手动指定dns服务器，有点麻烦。于是想起了我那个AP的openwrt，刚好把它配成<code>DHCP服务器</code>即可，由它分配地址，指定自己为<code>DNS服务器</code>。之后配置域名来访问服务倒也方便。</p><h2 id="实践"><a href="#实践" class="headerlink" title="实践"></a>实践</h2><h4 id="1-DNS劫持："><a href="#1-DNS劫持：" class="headerlink" title="1. DNS劫持："></a>1. DNS劫持：</h4><p>在openwrt管理界面的 <code>网络--主机名映射</code><br><img src="https://raw.githubusercontent.com/Destiny-End/images/master/Pasted%20image%2020231203160226.png" alt="DNS劫持配置"></p><p>来配置DNS劫持，之后再打开DHCP。理论是这样子的</p><h4 id="2-DHCP配置"><a href="#2-DHCP配置" class="headerlink" title="2. DHCP配置"></a>2. DHCP配置</h4><p>在<code>网络--接口</code>里，找到入网的接口。因为我是光猫做主路由，两个<code>红米AC2100</code>直接当AP，通过<code>LAN-LAN</code>方式接到光猫上的，因此我需要在LAN口配置DHCP。<br><img src="https://raw.githubusercontent.com/Destiny-End/images/master/202312301246602.png" alt="Lan接口"></p><p>但是吧，即使打开了<code>DHCP服务</code>，我的<code>Android手机</code>还是卡在了<code>获取IP地址</code>的步骤。</p><h4 id="调试"><a href="#调试" class="headerlink" title="调试"></a>调试</h4><h5 id="1-发现问题"><a href="#1-发现问题" class="headerlink" title="1. 发现问题"></a>1. 发现问题</h5><p>我打算用WireShark捕获DHCP报文，看看是哪一步有问题。捕获到的报文如下：<br><img src="https://raw.githubusercontent.com/Destiny-End/images/master/202312301246421.png" alt="截获的报文"></p><p>可以看出来，Android手机疯狂Request，想要申请IP地址，但是没有服务器回应它。看来是路由器的锅了。连上去查查</p><div class="note note-success">            <p>Dnsmasq是一个轻量级的网络服务软件，旨在提供DNS解析和DHCP服务。它通常用于家庭路由器、小型网络和嵌入式设备上。<br>以下是Dnsmasq的两个主要功能：</p><ol><li>DNS解析：Dnsmasq充当本地DNS服务器，负责将域名解析为IP地址。当你在浏览器中输入网址时，Dnsmasq会接收到DNS查询请求，并根据配置文件中的规则返回相应的IP地址。它还支持DNS缓存，可以提高网络访问速度。</li><li>DHCP服务：Dnsmasq可以作为DHCP服务器分配IP地址和其他网络配置信息给连接到网络的设备。当设备连接到网络时，它会向Dnsmasq发送DHCP请求，Dnsmasq会为该设备分配一个可用的IP地址，并提供其他必要的网络设置，如网关和DNS服务器。<br>Dnsmasq的优点是它的小巧和易于配置。它占用的系统资源较少，适用于资源有限的设备。它还具有可扩展性，可以通过配置文件进行自定义设置，如添加静态IP地址映射、定义域名别名等。<br>在OpenWrt等一些路由器固件中，Dnsmasq通常用作默认的DNS解析器和DHCP服务器，提供基本的网络服务功能。</li></ol>          </div><div class="note note-warning">            <p>DHCP原理<br><img src="https://raw.githubusercontent.com/Destiny-End/images/master/202312301247552.png" alt="DHCP原理"></p><p>DHCP请求IP地址的过程如下：<br>1）主机发送DHCPDISCOVER广播包在网络上寻找DHCP服务器；<br>2）DHCP服务器向主机发送DHCPOFFER单播数据包，包含IP地址、MAC地址、域名信息以及地址租期；<br>3）主机发送DHCPREQUEST广播包，正式向服务器请求分配已提供的IP地址；<br>4）DHCP服务器向主机发送DHCPACK单播包，确认主机的请求<br>需要说明的是：DHCP客户端可以接收到多个DHCP服务器的DHCPOFFER数据包，然后可能接受任何一个DHCPOFFER数据包，但客户端通常只接受收到的第一个DHCPOFFER数据包。另外，DHCP服务器DHCPOFFER中指定［1］ 的地址不一定为最终分配的地址，通常情况下，DHCP服务器会保留该地址直到客户端发出正式请求。<br>正式请求DHCP服务器分配地址DHCPREQUEST采用广播包，是为了让其它所有发送DHCPOFFER数据包的DHCP服务器也能够接收到该数据包，然后释放已经OFFER（预分配）给客户端的IP地址。<br>如果发送给DHCP客户端的地址已经被其他DHCP客户端使用，客户端会向服务器发送DHCPDECLINE信息包拒绝接受已经分配的地址信息。<br>在协商过程中，如果DHCP客户端发送的REQUEST消息中的地址信息不正确，如客户端已经迁移到新的子网或者租约已经过期，DHCP服务器会发送DHCPNAK消息给DHCP客户 端，让客户端重新发起地址请求过程。<br>注意，通信过程中，<strong>客户端</strong>源地址都是<code>0.0.0.0</code>，目的地址都是<code>255.255.255.255</code>，<strong>服务器</strong>源地址是服务器地址，目的地址是<code>255.255.255.255</code>。全是广播报文。</p>          </div><h5 id="2-尝试解决"><a href="#2-尝试解决" class="headerlink" title="2. 尝试解决"></a>2. 尝试解决</h5><p>……此处省略大量openwrt的尝试<br>结果就是<code>Dnsmasq</code>不知道为什么，配置正确但就是启动不了。最后还是通过我的服务器启动了DHCP服务。算是曲线救国了吧。方法如下：</p><p>在 Ubuntu 上，你可以使用 <code>isc-dhcp-server</code> 软件包来启用和配置 DHCP 服务器。以下是在 Ubuntu 上开启 DHCP 服务器的步骤：</p><ol><li><p>确保系统已经连接到网络，并且具有适当的网络配置（例如静态IP地址）。DHCP 服务器需要一个可用的网络接口来监听并为客户端提供 IP 地址。</p></li><li><p>打开终端，使用管理员权限运行以下命令来安装 <code>isc-dhcp-server</code> 软件包：</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">sudo apt <span class="hljs-keyword">update</span><br>sudo apt install isc-dhcp-<span class="hljs-keyword">server</span><br></code></pre></td></tr></table></figure></li><li><p>安装完成后，编辑 <code>/etc/dhcp/dhcpd.conf</code> 文件，该文件包含 DHCP 服务器的配置。使用你喜欢的文本编辑器打开文件：</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">sudo nano <span class="hljs-regexp">/etc/</span>dhcp/dhcpd.conf<br></code></pre></td></tr></table></figure></li><li><p>在配置文件中，根据你的网络需求，设置适当的 DHCP 选项，例如 IP 地址池范围、子网掩码、网关等。以下是一个简单的示例配置文件：</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs nginx"><span class="hljs-attribute">subnet</span> <span class="hljs-number">192.168.1.0</span> netmask <span class="hljs-number">255.255.255.0</span> &#123;<br>    <span class="hljs-attribute">range</span> <span class="hljs-number">192.168.1.100</span> <span class="hljs-number">192.168.1.200</span>;<br>    <span class="hljs-attribute">option</span> routers <span class="hljs-number">192.168.1.1</span>;<br>    <span class="hljs-attribute">option</span> domain-name-servers <span class="hljs-number">8.8.8.8</span>, <span class="hljs-number">8.8.4.4</span>;<br>&#125;<br></code></pre></td></tr></table></figure></li><li><p>保存并关闭文件。确保配置文件中的语法正确，没有任何错误。</p></li><li><p>编辑 <code>/etc/default/isc-dhcp-server</code> 文件，设置 DHCP 服务器监听的网络接口。将 <code>INTERFACESv4</code> 设置为你要用于 DHCP 的网络接口，例如 <code>eth0</code>：</p><figure class="highlight abnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs abnf"><span class="hljs-attribute">INTERFACESv4</span><span class="hljs-operator">=</span><span class="hljs-string">&quot;eth0&quot;</span><br></code></pre></td></tr></table></figure></li><li><p>保存并关闭文件。</p></li><li><p>启动 DHCP 服务器服务：</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">sudo systemctl <span class="hljs-keyword">start</span> isc-dhcp-<span class="hljs-keyword">server</span><br></code></pre></td></tr></table></figure></li><li><p>验证 DHCP 服务器是否已经启动，没有错误：</p><figure class="highlight axapta"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs axapta">sudo systemctl status isc-dhcp-<span class="hljs-keyword">server</span><br></code></pre></td></tr></table></figure><p>如果一切正常，你应该看到类似 “active (running)” 的消息。</p></li><li><p>(可选) 如果你希望 DHCP 服务器在系统启动时自动启动，执行以下命令以启用服务：</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">sudo systemctl <span class="hljs-keyword">enable</span> isc-dhcp-<span class="hljs-keyword">server</span><br></code></pre></td></tr></table></figure><p>现在，你的 Ubuntu 系统上的 DHCP 服务器已经启动并可以为连接到指定网络接口的客户端提供 IP 地址和其他网络配置。请确保你的网络中没有其他冲突的 DHCP 服务器，以避免干扰和配置冲突。</p></li></ol><h5 id="抓包结果"><a href="#抓包结果" class="headerlink" title="抓包结果"></a>抓包结果</h5><p>网卡开不了混杂…抓不到哎</p><h4 id="总结评价"><a href="#总结评价" class="headerlink" title="总结评价"></a>总结评价</h4><p>X86平台真好使。这个服务器除了功耗大了点，其它跑什么服务都不是大问题。那OpenWRT出问题都不知道该如何调试。</p>]]></content>
    
    
    <categories>
      
      <category>linux运维</category>
      
      <category>DHCP服务</category>
      
    </categories>
    
    
    <tags>
      
      <tag>linux</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Linux配置代理</title>
    <link href="/post/20231202231200.html"/>
    <url>/post/20231202231200.html</url>
    
    <content type="html"><![CDATA[<p>在Linux系统中设置代理可以通过设置环境变量或者使用特定的命令行工具来实现。下面是两种常见的设置代理的方法：</p><h2 id="方法一：设置环境变量"><a href="#方法一：设置环境变量" class="headerlink" title="方法一：设置环境变量"></a>方法一：设置环境变量</h2><ol><li>打开终端。</li><li>输入以下命令来设置HTTP代理： <figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-built_in">export</span> <span class="hljs-attribute">http_proxy</span>=http://&lt;代理服务器地址&gt;:&lt;代理服务器端口&gt;<br></code></pre></td></tr></table></figure> 替换 <code>&lt;代理服务器地址&gt;</code> 和 <code>&lt;代理服务器端口&gt;</code> 为你实际使用的代理服务器的地址和端口号。</li><li>输入以下命令来设置HTTPS代理： <figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-built_in">export</span> <span class="hljs-attribute">https_proxy</span>=https://&lt;代理服务器地址&gt;:&lt;代理服务器端口&gt;<br></code></pre></td></tr></table></figure> 同样替换 <code>&lt;代理服务器地址&gt;</code> 和 <code>&lt;代理服务器端口&gt;</code> 为你实际使用的代理服务器的地址和端口号。</li><li>如果代理服务器需要用户名和密码进行身份验证，你可以将其添加到代理地址中，例如：     <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs xml">export http_proxy=http://<span class="hljs-tag">&lt;<span class="hljs-name">用户名</span>&gt;</span>:<span class="hljs-tag">&lt;<span class="hljs-name">密码</span>&gt;</span>@<span class="hljs-tag">&lt;<span class="hljs-name">代理服务器地址</span>&gt;</span>:<span class="hljs-tag">&lt;<span class="hljs-name">代理服务器端口</span>&gt;</span><br>export https_proxy=https://<span class="hljs-tag">&lt;<span class="hljs-name">用户名</span>&gt;</span>:<span class="hljs-tag">&lt;<span class="hljs-name">密码</span>&gt;</span>@<span class="hljs-tag">&lt;<span class="hljs-name">代理服务器地址</span>&gt;</span>:<span class="hljs-tag">&lt;<span class="hljs-name">代理服务器端口</span>&gt;</span><br><br></code></pre></td></tr></table></figure> 替换 <code>&lt;用户名&gt;</code>、<code>&lt;密码&gt;</code>、<code>&lt;代理服务器地址&gt;</code> 和 <code>&lt;代理服务器端口&gt;</code> 为你实际使用的代理服务器的相关信息。</li><li>验证代理设置是否生效，可以使用 <code>echo</code> 命令检查环境变量的值： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">echo</span> <span class="hljs-variable">$http_proxy</span><br><span class="hljs-built_in">echo</span> <span class="hljs-variable">$https_proxy</span><br></code></pre></td></tr></table></figure><pre><code class="hljs">如果输出显示了正确的代理设置，那么代表设置成功。</code></pre></li></ol><h2 id="方法二：使用命令行工具（如-curl-或-wget）"><a href="#方法二：使用命令行工具（如-curl-或-wget）" class="headerlink" title="方法二：使用命令行工具（如 curl 或 wget）"></a>方法二：使用命令行工具（如 <code>curl</code> 或 <code>wget</code>）</h2><ol><li>打开终端。</li><li>使用 <code>curl</code> 命令或 <code>wget</code> 命令时添加 <code>-x</code> 或 <code>--proxy</code> 参数来指定代理服务器的地址和端口号，例如： <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs xml">curl -x http://<span class="hljs-tag">&lt;<span class="hljs-name">代理服务器地址</span>&gt;</span>:<span class="hljs-tag">&lt;<span class="hljs-name">代理服务器端口</span>&gt;</span> <span class="hljs-tag">&lt;<span class="hljs-name">目标网址</span>&gt;</span><br><br>wget -x http://<span class="hljs-tag">&lt;<span class="hljs-name">代理服务器地址</span>&gt;</span>:<span class="hljs-tag">&lt;<span class="hljs-name">代理服务器端口</span>&gt;</span> <span class="hljs-tag">&lt;<span class="hljs-name">目标网址</span>&gt;</span><br><br></code></pre></td></tr></table></figure> 替换 <code>&lt;代理服务器地址&gt;</code>、<code>&lt;代理服务器端口&gt;</code> 和 <code>&lt;目标网址&gt;</code> 为你实际使用的代理服务器的地址、端口号和目标网址。</li></ol><p>这些方法可以帮助你在Linux系统中设置代理。请注意，这些设置是临时的，仅在当前会话中有效。如果你需要永久设置代理，可以将上述配置添加到相应的配置文件中，<br>如 <code>~/.bashrc</code> 或 <code>/etc/profile</code>，以便在每次登录时自动加载代理设置。</p>]]></content>
    
    
    <categories>
      
      <category>linux运维</category>
      
      <category>环境配置</category>
      
    </categories>
    
    
    <tags>
      
      <tag>linux</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Docker ipv6挂了</title>
    <link href="/post/20231202203205.html"/>
    <url>/post/20231202203205.html</url>
    
    <content type="html"><![CDATA[<p>重启了下服务器，实体机屏幕上就报Docker起不来。查查日志吧</p><h2 id="找原因"><a href="#找原因" class="headerlink" title="找原因"></a>找原因</h2><p>首先试图手动启动<code>docker</code>，如下：</p><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs livecodeserver">sudo systemctl <span class="hljs-built_in">start</span> docker.service <br>Job <span class="hljs-keyword">for</span> docker.service failed because <span class="hljs-keyword">the</span> control <span class="hljs-built_in">process</span> exited <span class="hljs-keyword">with</span> error code.<br>See <span class="hljs-string">&quot;systemctl status docker.service&quot;</span> <span class="hljs-keyword">and</span> <span class="hljs-string">&quot;journalctl -xeu docker.service&quot;</span> <span class="hljs-keyword">for</span> details.<br></code></pre></td></tr></table></figure><p>那再试试<code>journalctl -xeu docker.service</code></p><figure class="highlight oxygene"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs oxygene">#  sudo journalctl -xeu docker.service<br><br>░░ A start job <span class="hljs-keyword">for</span> <span class="hljs-keyword">unit</span> docker.service <span class="hljs-keyword">has</span> finished <span class="hljs-keyword">with</span> a failure.<br>░░ <br>░░ The job identifier <span class="hljs-keyword">is</span> <span class="hljs-number">3443</span> <span class="hljs-keyword">and</span> the job <span class="hljs-keyword">result</span> <span class="hljs-keyword">is</span> failed.<br>Dec <span class="hljs-number">02</span> <span class="hljs-number">20</span>:<span class="hljs-number">28</span>:<span class="hljs-number">57</span> nasserver systemd[<span class="hljs-number">1</span>]: docker.service: Start request repeated too quickly.<br>Dec <span class="hljs-number">02</span> <span class="hljs-number">20</span>:<span class="hljs-number">28</span>:<span class="hljs-number">57</span> nasserver systemd[<span class="hljs-number">1</span>]: docker.service: Failed <span class="hljs-keyword">with</span> <span class="hljs-keyword">result</span> <span class="hljs-string">&#x27;exit-code&#x27;</span>.<br>░░ Subject: <span class="hljs-keyword">Unit</span> failed<br>░░ Defined-<span class="hljs-keyword">By</span>: systemd<br>░░ Support: http:<span class="hljs-comment">//www.ubuntu.com/support</span><br>░░ <br>░░ The <span class="hljs-keyword">unit</span> docker.service <span class="hljs-keyword">has</span> entered the <span class="hljs-string">&#x27;failed&#x27;</span> state <span class="hljs-keyword">with</span> <span class="hljs-keyword">result</span> <span class="hljs-string">&#x27;exit-code&#x27;</span>.<br>Dec <span class="hljs-number">02</span> <span class="hljs-number">20</span>:<span class="hljs-number">28</span>:<span class="hljs-number">57</span> nasserver systemd[<span class="hljs-number">1</span>]: Failed <span class="hljs-keyword">to</span> start docker.service - Docker Application Container Engine.<br>░░ Subject: A start job <span class="hljs-keyword">for</span> <span class="hljs-keyword">unit</span> docker.service <span class="hljs-keyword">has</span> failed<br>░░ Defined-<span class="hljs-keyword">By</span>: systemd<br>░░ Support: http:<span class="hljs-comment">//www.ubuntu.com/support</span><br>░░ <br>░░ A start job <span class="hljs-keyword">for</span> <span class="hljs-keyword">unit</span> docker.service <span class="hljs-keyword">has</span> finished <span class="hljs-keyword">with</span> a failure.<br>░░ <br>░░ The job identifier <span class="hljs-keyword">is</span> <span class="hljs-number">3631</span> <span class="hljs-keyword">and</span> the job <span class="hljs-keyword">result</span> <span class="hljs-keyword">is</span> failed.<br>...skipping...<br>░░ <br>░░ The job identifier <span class="hljs-keyword">is</span> <span class="hljs-number">3443</span> <span class="hljs-keyword">and</span> the job <span class="hljs-keyword">result</span> <span class="hljs-keyword">is</span> failed.<br>Dec <span class="hljs-number">02</span> <span class="hljs-number">20</span>:<span class="hljs-number">28</span>:<span class="hljs-number">57</span> nasserver systemd[<span class="hljs-number">1</span>]: docker.service: Start request repeated too quickly.<br>Dec <span class="hljs-number">02</span> <span class="hljs-number">20</span>:<span class="hljs-number">28</span>:<span class="hljs-number">57</span> nasserver systemd[<span class="hljs-number">1</span>]: docker.service: Failed <span class="hljs-keyword">with</span> <span class="hljs-keyword">result</span> <span class="hljs-string">&#x27;exit-code&#x27;</span>.<br>░░ Subject: <span class="hljs-keyword">Unit</span> failed<br>░░ Defined-<span class="hljs-keyword">By</span>: systemd<br>░░ Support: http:<span class="hljs-comment">//www.ubuntu.com/support</span><br>░░ <br>░░ The <span class="hljs-keyword">unit</span> docker.service <span class="hljs-keyword">has</span> entered the <span class="hljs-string">&#x27;failed&#x27;</span> state <span class="hljs-keyword">with</span> <span class="hljs-keyword">result</span> <span class="hljs-string">&#x27;exit-code&#x27;</span>.<br>Dec <span class="hljs-number">02</span> <span class="hljs-number">20</span>:<span class="hljs-number">28</span>:<span class="hljs-number">57</span> nasserver systemd[<span class="hljs-number">1</span>]: Failed <span class="hljs-keyword">to</span> start docker.service - Docker Application Container Engine.<br>░░ Subject: A start job <span class="hljs-keyword">for</span> <span class="hljs-keyword">unit</span> docker.service <span class="hljs-keyword">has</span> failed<br>░░ Defined-<span class="hljs-keyword">By</span>: systemd<br>░░ Support: http:<span class="hljs-comment">//www.ubuntu.com/support</span><br>░░ <br>░░ A start job <span class="hljs-keyword">for</span> <span class="hljs-keyword">unit</span> docker.service <span class="hljs-keyword">has</span> finished <span class="hljs-keyword">with</span> a failure.<br>░░ <br>░░ The job identifier <span class="hljs-keyword">is</span> <span class="hljs-number">3631</span> <span class="hljs-keyword">and</span> the job <span class="hljs-keyword">result</span> <span class="hljs-keyword">is</span> failed.<br></code></pre></td></tr></table></figure><p>没啥用，看不出来啥有问题。那再试试<code>dockerd</code>：</p><figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs gradle">$ dockerd<br>unable to configure the Docker daemon with <span class="hljs-keyword">file</span> <span class="hljs-regexp">/etc/</span>docker<span class="hljs-regexp">/daemon.json: the following directives don&#x27;t match any configuration option: ip6tab/</span>les<br></code></pre></td></tr></table></figure><p>这下挺明显了，<code>daemon</code>配的<code>ipv6</code>好像有问题。<br>查了下<code>/etc/docker/daemon.json</code>：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;registry-mirrors&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>        <span class="hljs-string">&quot;https://dockerproxy.com&quot;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-string">&quot;https://hub-mirror.c.163.com&quot;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-string">&quot;https://mirror.baidubce.com&quot;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-string">&quot;https://ccr.ccs.tencentyun.com&quot;</span><br>    <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;ipv6&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">true</span></span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;fixed-cidr-v6&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;fd12:3456:789a:1::/64&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;experimental&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">true</span></span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;ip6tab/les&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">true</span></span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><p>是有这个选项，之前配<code>nextcloud_aio</code>的时候文档让我加的。不管了，先试试关闭。</p><h2 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h2><p>还真启动了。<code>dockerd</code>命令输出如下：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">dockerd</span>                          <br><span class="hljs-attribute">INFO</span>[<span class="hljs-number">2023</span>-<span class="hljs-number">12</span>-<span class="hljs-number">02</span>T20:<span class="hljs-number">43</span>:<span class="hljs-number">21</span>.<span class="hljs-number">026752504</span>+<span class="hljs-number">08</span>:<span class="hljs-number">00</span>] Starting up                                  <br><span class="hljs-attribute">WARN</span>[<span class="hljs-number">2023</span>-<span class="hljs-number">12</span>-<span class="hljs-number">02</span>T20:<span class="hljs-number">43</span>:<span class="hljs-number">21</span>.<span class="hljs-number">026829181</span>+<span class="hljs-number">08</span>:<span class="hljs-number">00</span>] Running experimental build                   <br><span class="hljs-attribute">dockerd</span> needs to be started with root privileges. To run dockerd in rootless mode as an unprivileged user, see https://docs.docker.com/go/rootless/<br></code></pre></td></tr></table></figure><p>那<code>nextcloud</code>会不会有啥问题呢。但那应该是另一篇记录了HHH</p>]]></content>
    
    
    <categories>
      
      <category>Docker</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Docker</tag>
      
      <tag>ipv6</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>记一次诡异的DHCPv6问题</title>
    <link href="/post/20231202004420.html"/>
    <url>/post/20231202004420.html</url>
    
    <content type="html"><![CDATA[<h2 id="平台"><a href="#平台" class="headerlink" title="平台"></a>平台</h2><figure class="highlight avrasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs avrasm"><span class="hljs-symbol">os:</span>   ubuntu <span class="hljs-number">23.04</span> LTS<br>网卡： ac7260<br></code></pre></td></tr></table></figure><p>高版本的<code>Ubuntu LTS</code>好像取消了<code>ifconfig</code>命令，改成了用<code>netplan</code>来配置网络。不过也还好，熟悉了后配置很容易改。</p><h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p><code>netplan</code>配置文件如下：</p><figure class="highlight nestedtext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs nestedtext"><span class="hljs-comment"># This is the network config written by &#x27;subiquity&#x27;</span><br><span class="hljs-attribute">network</span><span class="hljs-punctuation">:</span><br>  <span class="hljs-attribute">version</span><span class="hljs-punctuation">:</span> <span class="hljs-string">2</span><br>  <span class="hljs-attribute">wifis</span><span class="hljs-punctuation">:</span><br>    <span class="hljs-attribute">wlp2s0</span><span class="hljs-punctuation">:</span><br>      <span class="hljs-attribute">access-points</span><span class="hljs-punctuation">:</span><br>        <span class="hljs-attribute">WifiName</span><span class="hljs-punctuation">:</span><br>          <span class="hljs-attribute">password</span><span class="hljs-punctuation">:</span> <span class="hljs-string">******</span><br>      <span class="hljs-attribute">addresses</span><span class="hljs-punctuation">:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">192.168.1.9/24</span><br>      <span class="hljs-attribute">nameservers</span><span class="hljs-punctuation">:</span><br>        <span class="hljs-attribute">addresses</span><span class="hljs-punctuation">:</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-string">223.5.5.5</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-string">114.114.114.114</span><br>        <span class="hljs-attribute">search</span><span class="hljs-punctuation">:</span> <span class="hljs-string">[]</span><br>      <span class="hljs-attribute">routes</span><span class="hljs-punctuation">:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">to: default</span><br>        <span class="hljs-attribute">via</span><span class="hljs-punctuation">:</span> <span class="hljs-string">192.168.1.1</span><br>      <span class="hljs-attribute">dhcp6</span><span class="hljs-punctuation">:</span> <span class="hljs-string">true</span><br>      <span class="hljs-attribute">wakeonlan</span><span class="hljs-punctuation">:</span> <span class="hljs-string">true</span><br>      <span class="hljs-attribute">accept-ra</span><span class="hljs-punctuation">:</span> <span class="hljs-string">true</span><br></code></pre></td></tr></table></figure><p>期望的效果是<code>ipv4</code>保持静态，<code>ipv6</code>保持dhcp获取状态，最后用个ddns脚本，将获取到的v6地址和域名绑定，达到发布到公网的目的。<br>但结果就是死活都获取不到<code>ipv6</code>地址。<br>P.S: 我在搞这个前其实换过一个网卡，之前那个wifi网卡是能正常获取到v6地址的。这个配置只是改了个网卡名，就获取不到了。。莫名其妙</p><h2 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h2><p>最后在一个论坛上找到了“能用”的命令，如下：<br><code>dhclient -6 -d wlp2s0</code><br>这个命令好像是先手动获取一遍v6，然后退出，v6地址还会保持。不知道重启or超时后会不会重新获取。。<br>很奇怪啊，论坛里的大佬说是因为MTU不合适而不能获取到的。挖个坑把，以后查查原因。</p><h4 id="参考"><a href="#参考" class="headerlink" title="参考:"></a>参考:</h4><ol><li>配置netplan: <a href="https://cloud.tencent.com/developer/article/1699857">https://cloud.tencent.com/developer/article/1699857</a></li><li>解决dhcp: <a href="https://forum.suse.org.cn/t/linux-global-ipv6/3927/20">https://forum.suse.org.cn/t/linux-global-ipv6/3927/20</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>linux运维</category>
      
      <category>DHCP服务</category>
      
    </categories>
    
    
    <tags>
      
      <tag>linux</tag>
      
      <tag>ipv6</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>linux下硬盘状况查看</title>
    <link href="/post/20231128232255.html"/>
    <url>/post/20231128232255.html</url>
    
    <content type="html"><![CDATA[<h1 id="找到了两种方法"><a href="#找到了两种方法" class="headerlink" title="找到了两种方法"></a>找到了两种方法</h1><h2 id="第一种是smart-control法"><a href="#第一种是smart-control法" class="headerlink" title="第一种是smart control法"></a>第一种是smart control法</h2><p>现在的硬盘基本都有这个自带的功能，命令：<br><code>sudo smartctl -H /dev/sda5 -a</code><br>其中’-a’可以输出具体的信息，要不然只会输出是否pass。<br>硬盘的基本信息：</p><figure class="highlight tap"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><code class="hljs tap">=== START OF INFORMATION SECTION ===<br>Model Family:     Seagate Barracuda 7200.14 (AF)<br>Device Model:     ST500DM002-1BC142<br>Serial Number:    5VMYZABG<br>LU WWN Device Id:<span class="hljs-number"> 5 </span>000c50 03d511520<br>Firmware Version: JC4B<br>User Capacity:    500,107,862,016 bytes [500 GB]<br>Sector Size:     <span class="hljs-number"> 512 </span>bytes logical/physical<br>Rotation Rate:   <span class="hljs-number"> 7200 </span>rpm<br>Device is:        In smartctl database 7.3/5319<br>ATA Version is:   ATA8-ACS T13/1699-D revision 4<br>SATA Version is:  SATA 3.0, 6.0 Gb/s (current: 3.0 Gb/s)<br>Local Time is:    Tue Nov<span class="hljs-number"> 28 </span>15:15:30<span class="hljs-number"> 2023 </span>UTC<br>SMART support is: Available - device has SMART capability.<br>SMART support is: Enabled<br><br>=== START OF READ SMART DATA SECTION ===<br>SMART overall-health self-assessment test result: PASSED<br><br>...<br><br>Vendor Specific SMART Attributes with Thresholds:<br>ID<span class="hljs-comment"># ATTRIBUTE_NAME          FLAG     VALUE WORST THRESH TYPE      UPDATED  WHEN_FAILED RAW_VALUE</span><br> <span class="hljs-number"> 1 </span>Raw_Read_Error_Rate     0x000f  <span class="hljs-number"> 112 </span> <span class="hljs-number"> 096 </span> <span class="hljs-number"> 006 </span>   Pre-fail  Always       -       45226076<br> <span class="hljs-number"> 3 </span>Spin_Up_Time            0x0003  <span class="hljs-number"> 100 </span> <span class="hljs-number"> 100 </span> <span class="hljs-number"> 000 </span>   Pre-fail  Always       -       0<br> <span class="hljs-number"> 4 </span>Start_Stop_Count        0x0032  <span class="hljs-number"> 095 </span> <span class="hljs-number"> 095 </span> <span class="hljs-number"> 020 </span>   Old_age   Always       -       6110<br> <span class="hljs-number"> 5 </span>Reallocated_Sector_Ct   0x0033  <span class="hljs-number"> 100 </span> <span class="hljs-number"> 100 </span> <span class="hljs-number"> 036 </span>   Pre-fail  Always       -       0<br> <span class="hljs-number"> 7 </span>Seek_Error_Rate         0x000f  <span class="hljs-number"> 086 </span> <span class="hljs-number"> 060 </span> <span class="hljs-number"> 030 </span>   Pre-fail  Always       -       408482396<br> <span class="hljs-number"> 9 </span>Power_On_Hours          0x0032  <span class="hljs-number"> 080 </span> <span class="hljs-number"> 080 </span> <span class="hljs-number"> 000 </span>   Old_age   Always       -       17715<br><span class="hljs-number"> 10 </span>Spin_Retry_Count        0x0013  <span class="hljs-number"> 100 </span> <span class="hljs-number"> 100 </span> <span class="hljs-number"> 097 </span>   Pre-fail  Always       -       0<br><span class="hljs-number"> 12 </span>Power_Cycle_Count       0x0032  <span class="hljs-number"> 095 </span> <span class="hljs-number"> 095 </span> <span class="hljs-number"> 020 </span>   Old_age   Always       -       5528<br>183 Runtime_Bad_Block       0x0032  <span class="hljs-number"> 100 </span> <span class="hljs-number"> 100 </span> <span class="hljs-number"> 000 </span>   Old_age   Always       -       0<br>184 End-to-End_Error        0x0032  <span class="hljs-number"> 100 </span> <span class="hljs-number"> 100 </span> <span class="hljs-number"> 099 </span>   Old_age   Always       -       0<br>187 Reported_Uncorrect      0x0032  <span class="hljs-number"> 001 </span> <span class="hljs-number"> 001 </span> <span class="hljs-number"> 000 </span>   Old_age   Always       -       259<br>188 Command_Timeout         0x0032  <span class="hljs-number"> 100 </span> <span class="hljs-number"> 095 </span> <span class="hljs-number"> 000 </span>   Old_age   Always       -      <span class="hljs-number"> 2 </span>2 821<br>189 High_Fly_Writes         0x003a  <span class="hljs-number"> 100 </span> <span class="hljs-number"> 100 </span> <span class="hljs-number"> 000 </span>   Old_age   Always       -       0<br>190 Airflow_Temperature_Cel 0x0022  <span class="hljs-number"> 068 </span> <span class="hljs-number"> 053 </span> <span class="hljs-number"> 045 </span>   Old_age   Always       -      <span class="hljs-number"> 32 </span>(Min/Max 24/37)<br>194 Temperature_Celsius     0x0022  <span class="hljs-number"> 032 </span> <span class="hljs-number"> 047 </span> <span class="hljs-number"> 000 </span>   Old_age   Always       -      <span class="hljs-number"> 32 </span>(0<span class="hljs-number"> 7 </span>0<span class="hljs-number"> 0 </span>0)<br>195 Hardware_ECC_Recovered  0x001a  <span class="hljs-number"> 031 </span> <span class="hljs-number"> 022 </span> <span class="hljs-number"> 000 </span>   Old_age   Always       -       45226076<br>197 Current_Pending_Sector  0x0012  <span class="hljs-number"> 100 </span> <span class="hljs-number"> 100 </span> <span class="hljs-number"> 000 </span>   Old_age   Always       -       0<br>198 Offline_Uncorrectable   0x0010  <span class="hljs-number"> 100 </span> <span class="hljs-number"> 100 </span> <span class="hljs-number"> 000 </span>   Old_age   Offline      -       0<br>199 UDMA_CRC_Error_Count    0x003e  <span class="hljs-number"> 200 </span> <span class="hljs-number"> 200 </span> <span class="hljs-number"> 000 </span>   Old_age   Always       -       0<br>240 Head_Flying_Hours       0x0000  <span class="hljs-number"> 100 </span> <span class="hljs-number"> 253 </span> <span class="hljs-number"> 000 </span>   Old_age   Offline      -       32920h+36m+34.032s<br>241 Total_LBAs_Written      0x0000  <span class="hljs-number"> 100 </span> <span class="hljs-number"> 253 </span> <span class="hljs-number"> 000 </span>   Old_age   Offline      -       2741956613<br>242 Total_LBAs_Read         0x0000  <span class="hljs-number"> 100 </span> <span class="hljs-number"> 253 </span> <span class="hljs-number"> 000 </span>   Old_age   Offline      -       2978174219<br></code></pre></td></tr></table></figure><p>看着倒是没什么问题。很老了，希望不会坏</p><h2 id="查坏道"><a href="#查坏道" class="headerlink" title="查坏道"></a>查坏道</h2><p>机械硬盘运行时不可避免会出现坏道，当坏道较多的时候就尽快更换硬盘吧。命令：<br><code>sudo badblocks -v /dev/sda5 &gt; bad_5.txt</code><br>结果</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">Checking</span> blocks <span class="hljs-number">0</span> to <span class="hljs-number">73408985</span><br><span class="hljs-attribute">Checking</span> for bad blocks (read-only test): <br><span class="hljs-attribute">done</span>                                                 <br><span class="hljs-attribute">Pass</span> completed, <span class="hljs-number">0</span> bad blocks found. (<span class="hljs-number">0</span>/<span class="hljs-number">0</span>/<span class="hljs-number">0</span> errors)<br></code></pre></td></tr></table></figure><p>还可以，好像没什么问题</p>]]></content>
    
    
    <categories>
      
      <category>linux运维</category>
      
    </categories>
    
    
    <tags>
      
      <tag>linux</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Anaconda命令</title>
    <link href="/post/20231126125907.html"/>
    <url>/post/20231126125907.html</url>
    
    <content type="html"><![CDATA[<p>1、查看已有的虚拟环境</p><p>conda env list</p><p>2、切换到想要的虚拟环境，这里我切换到my_test</p><p>conda activate my_test</p><p>3、在当前环境里安装ipykernel</p><p>conda install ipykernel</p>]]></content>
    
    
    <categories>
      
      <category>Anaconda</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>HA探究篇-mDNS分析</title>
    <link href="/post/20230724174319.html"/>
    <url>/post/20230724174319.html</url>
    
    <content type="html"><![CDATA[<h2 id="起因"><a href="#起因" class="headerlink" title="起因"></a>起因</h2><p>在配置好<code>HomeAssistant</code>后，我发现在管理界面，它只需要在浏览器输入<code>http://homeassistant:8123</code> 就可以访问到HA的管理界面。根据之前折腾路由器的经验，这域名应该在路由器中的DNS记录了才可被解析呀，身为一个局域网设备，它是怎么能将自己的DNS解析发布出来的呢？它又不可能直接修改路由器中的DNS表。于是我抓了下局域网的包，分析下这个协议的工作过程。</p><h2 id="抓包"><a href="#抓包" class="headerlink" title="抓包"></a>抓包</h2><div class="note note-warning">            <blockquote><p>我的主机在192.168.1.10，HA服务器在192.168.1.123    </p></blockquote>          </div>    <table><thead><tr><th align="center">“No.”</th><th align="center">“Time”</th><th align="center">“Source”</th><th align="center">“Destination”</th><th align="center">“Protocol”</th><th align="center">“Length”</th><th align="center">“Info”</th><th align="center"></th></tr></thead><tbody><tr><td align="center">“198”</td><td align="center">“3.678602”</td><td align="center">“192.168.1.10”</td><td align="center">“223.5.5.5”</td><td align="center">“DNS”</td><td align="center">“86”</td><td align="center">“Standard query 0x2131 HTTPS _8123._https.homeassistant”</td><td align="center"></td></tr><tr><td align="center">“199”</td><td align="center">“3.678611”</td><td align="center">“192.168.1.10”</td><td align="center">“223.5.5.5”</td><td align="center">“DNS”</td><td align="center">“86”</td><td align="center">“Standard query 0x2131 HTTPS _8123._https.homeassistant”</td><td align="center"></td></tr><tr><td align="center">“200”</td><td align="center">“3.679403”</td><td align="center">“192.168.1.10”</td><td align="center">“192.168.1.255”</td><td align="center">“NBNS”</td><td align="center">“92”</td><td align="center">“Name query NB HOMEASSISTANT&lt;00&gt;”</td><td align="center"></td></tr><tr><td align="center">“201”</td><td align="center">“3.679410”</td><td align="center">“192.168.1.10”</td><td align="center">“192.168.1.255”</td><td align="center">“NBNS”</td><td align="center">“92”</td><td align="center">“Name query NB HOMEASSISTANT&lt;00&gt;”</td><td align="center"></td></tr><tr><td align="center">“202”</td><td align="center">“3.681246”</td><td align="center">“192.168.1.10”</td><td align="center">“224.0.0.251”</td><td align="center">“MDNS”</td><td align="center">“79”</td><td align="center">“Standard query 0x0000 A homeassistant.local</td><td align="center">“QM” question”</td></tr><tr><td align="center">“203”</td><td align="center">“3.681254”</td><td align="center">“192.168.1.10”</td><td align="center">“224.0.0.251”</td><td align="center">“MDNS”</td><td align="center">“79”</td><td align="center">“Standard query 0x0000 A homeassistant.local</td><td align="center">“QM” question”</td></tr><tr><td align="center">“204”</td><td align="center">“3.681703”</td><td align="center">“192.168.1.123”</td><td align="center">“224.0.0.251”</td><td align="center">“MDNS”</td><td align="center">“89”</td><td align="center">“Standard query response 0x0000 A, cache flush 192.168.1.123”</td><td align="center"></td></tr><tr><td align="center">“205”</td><td align="center">“3.681711”</td><td align="center">“192.168.1.123”</td><td align="center">“224.0.0.251”</td><td align="center">“MDNS”</td><td align="center">“89”</td><td align="center">“Standard query response 0x0000 A, cache flush 192.168.1.123”</td><td align="center"></td></tr><tr><td align="center">“212”</td><td align="center">“3.684134”</td><td align="center">“192.168.1.10”</td><td align="center">“224.0.0.252”</td><td align="center">“LLMNR”</td><td align="center">“73”</td><td align="center">“Standard query 0x64d7 A homeassistant”</td><td align="center"></td></tr><tr><td align="center">“213”</td><td align="center">“3.684138”</td><td align="center">“192.168.1.10”</td><td align="center">“224.0.0.252”</td><td align="center">“LLMNR”</td><td align="center">“73”</td><td align="center">“Standard query 0x64d7 A homeassistant”</td><td align="center"></td></tr><tr><td align="center">“234”</td><td align="center">“3.685123”</td><td align="center">“192.168.1.123”</td><td align="center">“192.168.1.10”</td><td align="center">“LLMNR”</td><td align="center">“89”</td><td align="center">“Standard query response 0x64d7 A homeassistant A 192.168.1.123”</td><td align="center"></td></tr><tr><td align="center">“235”</td><td align="center">“3.685127”</td><td align="center">“192.168.1.123”</td><td align="center">“192.168.1.10”</td><td align="center">“LLMNR”</td><td align="center">“89”</td><td align="center">“Standard query response 0x64d7 A homeassistant A 192.168.1.123”</td><td align="center"></td></tr></tbody></table><h2 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h2><p>可以看到，当我的主机输入<code>http://homeassistant:8123</code>地址时，电脑自动给<code>223.5.5.5</code>(这是阿里DNS的地址)、<code>192.168.1.255</code>、<code>224.0.0.251</code>和<code>224.0.0.252</code>，这四个地址发送数据包，让它们试图解析这个域名。<br>其中的前两个地址不是关心的重点。一个是公共DNS，一个是NBNS（NetBIOS Name Service）。重点看第三个地址，注意到它的协议是mDNS。  </p><h3 id="mDNS"><a href="#mDNS" class="headerlink" title="mDNS"></a>mDNS</h3><p>根据查到的资料：</p><div class="note note-primary">            <p>mDNS（Multicast DNS）是一种基于组播的协议，用于在局域网内解析本地主机名和 IP 地址之间的映射关系。mDNS 协议是 Zero Configuration Networking（Zeroconf）技术的一部分，它允许设备在不需要任何配置的情况下自动发现和连接到网络上的其他设备。  </p><blockquote><p>mDNS 协议的工作原理如下：</p></blockquote><ol><li>主机发送查询请求：当主机需要解析另一个主机的主机名时，它将向组播地址 224.0.0.251 发送一个查询请求。查询请求中包含了需要解析的主机名和查询请求的 ID。  </li><li>局域网内的所有主机都收到查询请求：局域网内的所有主机都会收到查询请求，但只有那些已经注册了与查询请求匹配的主机名的主机才会作出响应。  </li><li>主机作出响应：如果一个主机已经注册了与查询请求匹配的主机名，它将向查询请求的源主机发送一个响应。响应中包含了主机名、IP 地址和查询请求的 ID。  </li><li>源主机收到响应：当源主机收到响应时，它将使用响应中包含的 IP 地址来建立与目标主机的连接。</li></ol><p>需要注意的是，mDNS 协议只能在同一局域网内使用，因为它使用的是组播地址和局域网广播。另外，mDNS 协议不需要任何中央服务器或域名系统的支持，因此它非常适合用于小型网络或临时网络，例如家庭网络、会议室网络或 Wi-Fi 热点。</p>          </div><p>可以明确知道，HA正是用了mDNS协议，实现了域名解析。而我的计算机查找域名的过程，是从公共DNS出发，再查找本地NBNS，之后查找mDNS，最后查找LLMNR。这和我的网络配置相符合，我自定义了DNS服务器，使它指向<code>223.5.5.5</code>，所以它跳过了查找本地DNS服务器的过程，而是直接向阿里DNS发送请求。</p><h3 id="本地数据包分析"><a href="#本地数据包分析" class="headerlink" title="本地数据包分析"></a>本地数据包分析</h3><p><img src="https://raw.githubusercontent.com/Destiny-End/images/master/202312301251428.png" alt="host请求"></p><p>回到mDNS，如上图，主机向组播地址<code>224.0.0.251</code>，这个mDNS协议组播地址发出DNS请求，问：“<code>homeassistant.local</code>在哪个地址呀？”<br><img src="https://raw.githubusercontent.com/Destiny-End/images/master/202312301251345.png" alt="HA回应"></p><p>之后，HA的服务器便回复了：“<code>homeassistant.local</code>在地址<code>192.168.1.123</code>”<br>这样，便完成了一次域名解析过程。而我的主机也会将这个地址记录下来，直到DNS刷新或者是DNS记录值过期。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>其实mDNS和DNS还是很相似的，都是向某个地址发请求，等待回应，保存DNS解析记录。不过由于mDNS用的是组播地址，它便可以不需要服务器就可完成解析。只要服务端存活，服务端收到来自组播的信息，就会发出回应。这样做的好处很明显了，可以在配置完成后，在局域网内输入域名，即可自动获取到服务器的IP，免去了人工查找服务端IP地址的过程。  </p><p>最后来段ChatGPT总结的优缺点吧。  </p><div class="note note-success">            <p>多播 DNS（mDNS）协议是一种在局域网（LAN）中进行 DNS 解析和服务发现的协议。以下是 mDNS 协议的优点和缺点：</p><blockquote><p>优点：<br>简化网络配置：mDNS 协议可以让设备自动发现和连接其他设备，无需手动配置 DNS 服务器或 DHCP 服务器。这使得网络更加易于部署和管理，并且可以减少网络故障的可能性。<br>提高网络可靠性：mDNS 协议使用多播地址来广播 DNS 查询和回复消息，这可以减少网络负载并提高网络响应速度。此外，mDNS 协议在没有 DNS 服务器的情况下仍然可以工作，因此即使网络中出现故障，设备和服务也可以继续通信。<br>支持零配置网络：mDNS 协议是支持零配置网络（Zero Configuration Networking，Zeroconf）的重要组成部分。Zeroconf 技术可以帮助设备自动配置网络，并使其可以在没有中央服务器的情况下发现和连接其他设备。  </p></blockquote><blockquote><p>缺点：<br>安全性问题：mDNS 协议的广播特性可以使网络中的任何设备都可以看到其他设备和服务。这可能会导致安全隐患，例如未经授权的设备可以访问网络上的其他设备和服务。<br>可扩展性问题：由于 mDNS 协议使用广播消息，因此在大型网络中使用可能会导致网络负载过高，从而降低网络性能和可扩展性。<br>兼容性问题：不是所有的设备和服务都支持 mDNS 协议。这可能会导致在某些情况下，设备和服务无法相互通信或无法正确工作。</p></blockquote>          </div><p>不难看出，它的优势很明显，可以简化网络配置，简化网络结构，自然提高了稳定性。劣势则是兼容性和安全性问题，很容易受到中间人攻击，劫持DNS来截获一些私密信息。但在有一定安全性的局域网内，mDNS对HA则是很合适了。我还注意到它还支持LLMNR协议，可以说开发组的考虑很周到了。</p>]]></content>
    
    
    <categories>
      
      <category>linux运维</category>
      
    </categories>
    
    
    <tags>
      
      <tag>路由器</tag>
      
      <tag>HA</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>github工作流自动完成hexo部署</title>
    <link href="/post/20230723115242.html"/>
    <url>/post/20230723115242.html</url>
    
    <content type="html"><![CDATA[<h2 id="github工作流自动完成hexo部署"><a href="#github工作流自动完成hexo部署" class="headerlink" title="github工作流自动完成hexo部署"></a>github工作流自动完成hexo部署</h2><div class="note note-warning">            <p>你应该先确保本地可以正常生成hexo，并且可以正常部署！</p>          </div><h3 id="1-在hexo项目-github-workflows-目录下创建任意名称的-yml文件"><a href="#1-在hexo项目-github-workflows-目录下创建任意名称的-yml文件" class="headerlink" title="1. 在hexo项目\.github\workflows\目录下创建任意名称的.yml文件"></a>1. 在<code>hexo项目\.github\workflows\</code>目录下创建任意名称的<code>.yml</code>文件</h3><h3 id="2-将下列yml内容复制到你的文件中，并修改env中的内容为你的配置"><a href="#2-将下列yml内容复制到你的文件中，并修改env中的内容为你的配置" class="headerlink" title="2. 将下列yml内容复制到你的文件中，并修改env中的内容为你的配置"></a>2. 将下列yml内容复制到你的文件中，并修改<code>env</code>中的内容为你的配置</h3><div class="note note-danger">            <p>官网给出的yml文件，好像并没有考虑到使用主题的情况。我用的fluid主题，在checkout时无法正常签出，导致后续<code>hexo g</code>命令报错<code>no layout</code>。这里给出的解决方案是使用<strong>子模块</strong>，即git中的<code>submodule</code>。将资源文件全部整合到<code>hexo的source文件目录</code>中，配置文件放在hexo项目根目录中。  <strong>不要直接修改主题中的任何文件！！</strong>  </p>          </div>  <h3 id="3-配置GitHub项目密钥"><a href="#3-配置GitHub项目密钥" class="headerlink" title="3. 配置GitHub项目密钥"></a>3. 配置GitHub项目密钥</h3><div align=center>    <img src="https://raw.githubusercontent.com/Destiny-End/images/master/202312301252513.png" alt="密钥存放位置" width="50%"/>    <br>secrets存放位置</div>   比如我存放的名称就叫`HEXO_DEPLOY_KEY`,于是下方就填写`$`。  <h3 id="4-尝试push，并查看GitHub-Action中的日志。如果成功则会显示绿色，如果是红色就要查看日志慢慢排查咯"><a href="#4-尝试push，并查看GitHub-Action中的日志。如果成功则会显示绿色，如果是红色就要查看日志慢慢排查咯" class="headerlink" title="4. 尝试push，并查看GitHub-Action中的日志。如果成功则会显示绿色，如果是红色就要查看日志慢慢排查咯~"></a>4. 尝试push，并查看<code>GitHub-Action</code>中的日志。如果成功则会显示绿色，如果是红色就要查看日志慢慢排查咯~</h3><h3 id="源代码"><a href="#源代码" class="headerlink" title="源代码"></a>源代码</h3><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs yml"><span class="hljs-comment"># PATH:`网站目录\.github\workflows\autogen.yml`</span><br><span class="hljs-attr">name:</span> <span class="hljs-string">deploying</span> <span class="hljs-string">Hexo</span> <span class="hljs-string">project</span> <span class="hljs-string">to</span> <span class="hljs-string">GitHub</span> <span class="hljs-string">pages</span><br><span class="hljs-attr">on:</span><br>  <span class="hljs-attr">push:</span><br>    <span class="hljs-attr">branches:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">master</span> <span class="hljs-comment"># master 分支有 push 行为时就触发这个 action</span><br>  <br><span class="hljs-attr">jobs:</span><br>  <span class="hljs-attr">build-and-deploy:</span><br>    <span class="hljs-attr">runs-on:</span> <span class="hljs-string">ubuntu-latest</span><br>    <span class="hljs-attr">steps:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">Checkout</span> <span class="hljs-string">code</span><br>        <span class="hljs-attr">uses:</span> <span class="hljs-string">actions/checkout@v2</span><br>        <span class="hljs-attr">with:</span><br>          <span class="hljs-attr">submodules:</span> <span class="hljs-string">&#x27;true&#x27;</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">Build</span> <span class="hljs-string">and</span> <span class="hljs-string">Deploy</span><br>        <span class="hljs-attr">uses:</span> <span class="hljs-string">theme-keep/hexo-deploy-github-pages-action@master</span> <span class="hljs-comment"># 使用专门部署 Hexo 到 GitHub pages 的 action</span><br>        <span class="hljs-attr">env:</span><br>          <span class="hljs-attr">PERSONAL_TOKEN:</span> <span class="hljs-string">$&#123;&#123;</span> <span class="hljs-string">secrets.HEXO_DEPLOY_KEY</span> <span class="hljs-string">&#125;&#125;</span> <span class="hljs-comment"># secret 名</span><br>          <span class="hljs-attr">PUBLISH_REPOSITORY:</span> <span class="hljs-string">Destiny-End/Destiny-End.github.io</span> <span class="hljs-comment"># 公共仓库，格式：GitHub 用户名/仓库名</span><br>          <span class="hljs-attr">BRANCH:</span> <span class="hljs-string">main</span> <span class="hljs-comment"># 分支，我使用的是main分支</span><br>          <span class="hljs-attr">PUBLISH_DIR:</span> <span class="hljs-string">./public</span> <span class="hljs-comment"># 部署 public 目录下的文件</span><br></code></pre></td></tr></table></figure><blockquote><p>env填写方式:</p><table><thead><tr><th>Key</th><th>Value Information</th><th>Type</th><th>Default</th><th>Required</th></tr></thead><tbody><tr><td><code>PERSONAL_TOKEN</code></td><td>Depending on the repository permissions you may need to provide the action with a GitHub Personal Access Token in order to deploy. You can <a href="https://help.github.com/en/articles/creating-a-personal-access-token-for-the-command-line">learn more about how to generate one here</a>. <strong>This should be stored as a secret</strong>.</td><td><code>secrets</code></td><td></td><td><strong>Yes</strong></td></tr><tr><td><code>PUBLISH_REPOSITORY</code></td><td>The repository the action should deploy to. for example <code>theme-keep/site</code></td><td><code>env</code></td><td></td><td><strong>Yes</strong></td></tr><tr><td><code>BRANCH</code></td><td>The branch the action should deploy to. for example <code>master</code></td><td><code>env</code></td><td><code>gh-pages</code></td><td><strong>Yes</strong></td></tr><tr><td><code>PUBLISH_DIR</code></td><td>The folder the action should deploy. for example <code>./public</code></td><td><code>env</code></td><td><code>./public</code></td><td>No</td></tr><tr><td><code>CNAME</code></td><td>The domain name of your GitHub Pages specified in a CNAME</td><td><code>env</code></td><td></td><td>No</td></tr></tbody></table></blockquote>]]></content>
    
    
    
    <tags>
      
      <tag>Github-Workflows</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>python之批量修改文件名</title>
    <link href="/post/20230723101753.html"/>
    <url>/post/20230723101753.html</url>
    
    <content type="html"><![CDATA[<h2 id="功能介绍"><a href="#功能介绍" class="headerlink" title="功能介绍"></a>功能介绍</h2><p>该代码循环遍历root_dir内部的所有子目录，匹配文件名中包含【*】的内容，并将其删除。（公众号的文件有这东西）  </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs Python"><span class="hljs-comment">#!/usr/bin/env python3</span><br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> re<br><br><span class="hljs-comment"># 请替换为你的顶级目录</span><br><br>root_dir = <span class="hljs-string">&#x27;G:\\BaiduNetdiskDownload\\&#x27;</span>   <br><br><span class="hljs-comment"># 正则表达式用于匹配括号及其内容</span><br><br>regex = re.<span class="hljs-built_in">compile</span>(<span class="hljs-string">r&#x27;【.*?】&#x27;</span>)<br><br><span class="hljs-keyword">for</span> folder_name, subfolders, filenames <span class="hljs-keyword">in</span> os.walk(root_dir):<br>    <span class="hljs-keyword">for</span> filename <span class="hljs-keyword">in</span> filenames:<br>        original_filename = os.path.join(folder_name, filename)<br><br>        <span class="hljs-comment"># 使用正则表达式删除所有括号及其内容</span><br>        new_filename = regex.sub(<span class="hljs-string">&#x27;&#x27;</span>, filename).strip()<br><br>        <span class="hljs-comment"># 创建新的完整文件路径</span><br>        new_filename = os.path.join(folder_name, new_filename)<br><br>        <span class="hljs-comment"># 重命名文件</span><br>        os.rename(original_filename, new_filename)<br><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;当前工作目录: <span class="hljs-subst">&#123;folder_name&#125;</span>&#x27;</span>)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;修改的源文件名: <span class="hljs-subst">&#123;original_filename&#125;</span>&#x27;</span>)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;修改后的文件名: <span class="hljs-subst">&#123;new_filename&#125;</span>\n&#x27;</span>)<br></code></pre></td></tr></table></figure>]]></content>
    
    
    
    <tags>
      
      <tag>python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>英一刷题笔记-2014</title>
    <link href="/post/20230722003317.html"/>
    <url>/post/20230722003317.html</url>
    
    <content type="html"><![CDATA[<h1 id="英一-2014"><a href="#英一-2014" class="headerlink" title="英一 2014"></a>英一 2014</h1><h2 id="一、完型填空"><a href="#一、完型填空" class="headerlink" title="一、完型填空"></a>一、完型填空</h2><p>感觉挺顺畅的，但还是错了四个 (T.T)</p><h3 id="错题整理"><a href="#错题整理" class="headerlink" title="错题整理"></a>错题整理</h3><ol start="2"><li><p>As the brain ( <del>D</del> ), we refer to these occurrences as “senior moments”  </p><table>  <tr> <td>A. improves</td> <td>B. fades</td> <td>C. recovers</td> <td>D. collapses</td></tr></table>   答案：B  解释：fades 的变暗、变淡是广义的，包含：笑容、视野、光线、声音、颜色、记忆等。</li><li><p>To a certain extend, our ability to (excel) in making the connections that drive intelligence is inherited. (<del>B</del>), because these connections are made through effort and practice….   </p><table>  <tr><td>A. However</td><td>B. Moreover</td><td>C. Otherwise</td><td>D. Therefore</td></tr></table>  答案：A  解释：上文提到inherited，下文又说这种关系可以通过努力和锻炼达到，故是对比关系，选A.</li><li><p>The program keeps tracks of your progress and provides detailed feedback (<del>C</del>) your performance and improvement.</p><table>  <tr><td>A. on</td><td>B. to</td><td>C. for</td><td>D. with</td></tr></table>  答案：A 解释：空格处需表明Feedback和your performance and improvement之间的关系，on表示在...方面。</li><li><p>(接17) Most importantly, it (<del>C</del>) modifies and enhances the games you play to (build) on the strengths you are developing. </p><table>  <tr><td>A. habitually</td><td>B. constantly</td><td>C. irregularly</td><td>D. unusually</td></tr></table>  答案：B  解释：应该是持续的改进你玩的游戏，来加强你大脑的发展...</li></ol>]]></content>
    
    
    <categories>
      
      <category>学习</category>
      
      <category>英语</category>
      
    </categories>
    
    
    <tags>
      
      <tag>英一</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>红米AC2100，光猫加路由器实现WiFi5G全屋漫游</title>
    <link href="/post/20230721233317.html"/>
    <url>/post/20230721233317.html</url>
    
    <content type="html"><![CDATA[<h1 id="红米AC2100-WiFi5G全屋漫游"><a href="#红米AC2100-WiFi5G全屋漫游" class="headerlink" title="红米AC2100 WiFi5G全屋漫游"></a>红米AC2100 WiFi5G全屋漫游</h1><p>由于家里户型是长条形，导致客厅的WIFI信号完全没法传到卧室来。于是给卧室又装了个无线路由器。但使用时从客厅到卧室这条路线上，WIFI总会断开，再重新连上，这就导致我<del>看直播</del>学习十分不顺畅。于是就萌生了将WIFI进行组网漫游的想法。经查阅，WIFI组网用的是<strong>802.11kvr</strong>协议，红米AC2100的固件，其中一个正好有该协议，那就查询下怎么组吧。</p><p>注：我用的是openwrt-lienol-5.4.219-ramips-mt7621-xiaomi_redmi-router-ac2100这个ROM，其余ROM不保证有效。</p><h2 id="1-网络拓扑图"><a href="#1-网络拓扑图" class="headerlink" title="1.网络拓扑图"></a>1.网络拓扑图</h2><p>由于家里弱电箱空间实在小，无法塞下软路由，我也就没搞。通过光猫进行拨号以及DHCP分配地址，充当主路由。两只AC2100当AP，提供无线接入服务，以及跑一些小服务（见其余文章）。拓扑图如下：</p><p><img src="https://raw.githubusercontent.com/Destiny-End/images/master/202312301248067.png" alt="拓扑图"></p><p>: 应该挺直观易懂的吧（</p><div class="note note-warning">            <p>要点就是将路由器的LAN口与光猫的LAN口进行连接，因为我们需要两台路由器在同一局域网内。</p>          </div><h2 id="2-设置不加MESH的组网"><a href="#2-设置不加MESH的组网" class="headerlink" title="2.设置不加MESH的组网"></a>2.设置不加MESH的组网</h2><p>根据上面的示意图，设置光猫及路由器</p><h3 id="光猫"><a href="#光猫" class="headerlink" title="光猫"></a>光猫</h3><p>配置光猫为DHCP开启，拨号运维小哥应该已经配置好了。<br>DHCP设置地址池为192.168.1.0，子网掩码24(255.255.255.0)，设置分配范围为192.168.1.100-192.168.1.254(1-99用来固定ip或者自行分配用)</p><h3 id="路由器"><a href="#路由器" class="headerlink" title="路由器"></a>路由器</h3><p>路由器上就比较复杂，在接入光猫之前，先将路由器的br-lan接口的地址设置为192.168.1.2(或者自己定)，将路由器DHCP进行关闭。保存应用后会发现管理界面打不开了（</p><p>将电脑的ip改为192.168.1.10，子网掩码24，网关写192.168.1.2，再访问<a href="http://192.168.1.2/">http://192.168.1.2</a> ，哎~管理界面又粗来了。这样就完成了一个AP的设置，另一台同样这么设置，不过记得ip地址改为不冲突的另一个就好。我就直接使用192.168.1.2和192.168.1.3了。</p><h3 id="WIFI"><a href="#WIFI" class="headerlink" title="WIFI"></a>WIFI</h3><p>路由器的WIFI部分，先设置不加mesh的，将wifi的ssid设置成一样的，密码的协议和key也要一样，但信道要不同（防止干扰）。保存重启，这样就完成了基本的漫游。但你在测试的时候会发现，它从一个wifi过渡到另一个wifi时，会断开一次再重新连一次。很不爽</p><h2 id="3-配置mesh"><a href="#3-配置mesh" class="headerlink" title="3.配置mesh"></a>3.配置mesh</h2><p>在有同样的ssid和key的情况下，找到如下图的界面<br><img src="https://raw.githubusercontent.com/Destiny-End/images/master/202312301249676.png" alt="开启kvr"></p><p>将802.11 k、v、r全部开启，后面还有一些参数，按下面的教程填写：</p><h3 id="NASID"><a href="#NASID" class="headerlink" title="NASID"></a>NASID</h3><p><img src="https://raw.githubusercontent.com/Destiny-End/images/master/202312301249258.png" alt="ac_3.png"></p><p>这个配置成wifi的bssid去掉冒号，具体在无线信息界面会显示。<br>例如我这里是  BSSID: 28:D1:27:D6:8B:73，于是NASID就设为28D127D68B73。<br>如图，将NASID后面的两个选项设置为开启。</p><h3 id="R0KH-R1KH列表"><a href="#R0KH-R1KH列表" class="headerlink" title="R0KH&#x2F;R1KH列表"></a>R0KH&#x2F;R1KH列表</h3><p><img src="https://raw.githubusercontent.com/Destiny-End/images/master/202312301249716.png" alt=" R0KH/R1KH"></p><p>这里就用刚才的 BSSID,NASID,随机128位密钥即可。Linux下输入<code>openssl rand -hex 16</code>命令即可生成该密钥。注意之后配置中需要使用同一密钥，这里记成RandKey<br>例如，我的第一条就是<br><code>28:D1:27:D6:8B:73,28D127D68B73,313f4db90244e45ea0ce511db64821f9</code><br>bssid，bssid去掉冒号，RandKey。<br>把它分别添加到两个路由器的R0KH和R1KH中，就完成了第一台的配置。<br>第二台跟第一台操作一样，记得将RandKey保持不变就行。</p><p> 这样，就完成了全屋WIFI漫游。记得拿wifi测试工具测试下效果~</p>]]></content>
    
    
    <categories>
      
      <category>硬件</category>
      
      <category>wifi</category>
      
    </categories>
    
    
    <tags>
      
      <tag>路由器</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
